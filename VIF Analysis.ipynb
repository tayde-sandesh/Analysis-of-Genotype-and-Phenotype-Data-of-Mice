{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fa2ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial VIF Values:\n",
      "    Feature           VIF\n",
      "0        X1  8.188363e+14\n",
      "1        X2  7.505999e+14\n",
      "2        X5  3.002400e+14\n",
      "3       X23  5.298353e+14\n",
      "4      X123  6.928615e+14\n",
      "..      ...           ...\n",
      "195   X1974  6.433714e+14\n",
      "196   X1977  5.629500e+14\n",
      "197   X1982  9.007199e+14\n",
      "198   X1989  4.740631e+14\n",
      "199   X1997  3.105931e+14\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "Removing feature: X1211 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1704 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1405 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1741 (VIF: 2251799813685248.0)\n",
      "Removing feature: X757 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1005 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1562 (VIF: 2251799813685248.0)\n",
      "Removing feature: X238 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1733 (VIF: 1801439850948198.5)\n",
      "Removing feature: X381 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1350 (VIF: 1801439850948198.5)\n",
      "Removing feature: X430 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1022 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1666 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1611 (VIF: 2251799813685248.0)\n",
      "Removing feature: X290 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1366 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1 (VIF: 1801439850948198.5)\n",
      "Removing feature: X140 (VIF: 1501199875790165.2)\n",
      "Removing feature: X575 (VIF: 1801439850948198.5)\n",
      "Removing feature: X786 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1098 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1233 (VIF: 1501199875790165.2)\n",
      "Removing feature: X812 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1409 (VIF: 1501199875790165.2)\n",
      "Removing feature: X472 (VIF: 1286742750677284.5)\n",
      "Removing feature: X881 (VIF: 1501199875790165.2)\n",
      "Removing feature: X937 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1628 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1496 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1778 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1412 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1133 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1237 (VIF: 1286742750677284.5)\n",
      "Removing feature: X782 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1046 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1250 (VIF: 1125899906842624.0)\n",
      "Removing feature: X968 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1804 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1539 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1382 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1749 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1916 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1927 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1158 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1249 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1824 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1528 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1241 (VIF: 1286742750677284.5)\n",
      "Removing feature: X918 (VIF: 1125899906842624.0)\n",
      "Removing feature: X305 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1801 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1259 (VIF: 900719925474099.2)\n",
      "Removing feature: X1614 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1461 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1307 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1557 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1069 (VIF: 900719925474099.2)\n",
      "Removing feature: X1188 (VIF: 1125899906842624.0)\n",
      "Removing feature: X878 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1092 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1634 (VIF: 900719925474099.2)\n",
      "Removing feature: X1437 (VIF: 900719925474099.2)\n",
      "Removing feature: X1032 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1464 (VIF: 750599937895082.6)\n",
      "Removing feature: X1521 (VIF: 750599937895082.6)\n",
      "Removing feature: X1195 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1882 (VIF: 1000799917193443.5)\n",
      "Removing feature: X714 (VIF: 818836295885544.8)\n",
      "Removing feature: X1470 (VIF: 900719925474099.2)\n",
      "Removing feature: X1833 (VIF: 818836295885544.8)\n",
      "Removing feature: X1446 (VIF: 750599937895082.6)\n",
      "Removing feature: X1042 (VIF: 818836295885544.8)\n",
      "Removing feature: X1609 (VIF: 692861481133922.5)\n",
      "Removing feature: X1745 (VIF: 643371375338642.2)\n",
      "Removing feature: X1436 (VIF: 692861481133922.5)\n",
      "Removing feature: X1255 (VIF: 643371375338642.2)\n",
      "Removing feature: X1318 (VIF: 600479950316066.1)\n",
      "Removing feature: X2 (VIF: 692861481133922.5)\n",
      "Removing feature: X1639 (VIF: 643371375338642.2)\n",
      "Removing feature: X886 (VIF: 692861481133922.5)\n",
      "Removing feature: X1772 (VIF: 500399958596721.75)\n",
      "Removing feature: X1623 (VIF: 643371375338642.2)\n",
      "Removing feature: X1505 (VIF: 643371375338642.2)\n",
      "Removing feature: X1889 (VIF: 500399958596721.75)\n",
      "Removing feature: X1462 (VIF: 562949953421312.0)\n",
      "Removing feature: X273 (VIF: 600479950316066.1)\n",
      "Removing feature: X1800 (VIF: 600479950316066.1)\n",
      "Removing feature: X899 (VIF: 562949953421312.0)\n",
      "Removing feature: X1264 (VIF: 375299968947541.3)\n",
      "Removing feature: X1810 (VIF: 692861481133922.5)\n",
      "Removing feature: X559 (VIF: 562949953421312.0)\n",
      "Removing feature: X1874 (VIF: 562949953421312.0)\n",
      "Removing feature: X1570 (VIF: 500399958596721.75)\n",
      "Removing feature: X1974 (VIF: 529835250278881.9)\n",
      "Removing feature: X926 (VIF: 391617358901782.25)\n",
      "Removing feature: X1434 (VIF: 450359962737049.6)\n",
      "Removing feature: X1460 (VIF: 428914250225761.5)\n",
      "Removing feature: X1200 (VIF: 474063118670578.5)\n",
      "Removing feature: X999 (VIF: 474063118670578.5)\n",
      "Removing feature: X1354 (VIF: 500399958596721.75)\n",
      "Removing feature: X1312 (VIF: 409418147942772.4)\n",
      "Removing feature: X931 (VIF: 375299968947541.3)\n",
      "Removing feature: X830 (VIF: 409418147942772.4)\n",
      "Removing feature: X1377 (VIF: 391617358901782.25)\n",
      "Removing feature: X1864 (VIF: 300239975158033.06)\n",
      "Removing feature: X1731 (VIF: 391617358901782.25)\n",
      "Removing feature: X1228 (VIF: 333599972397814.5)\n",
      "Removing feature: X1135 (VIF: 300239975158033.06)\n",
      "Removing feature: X543 (VIF: 300239975158033.06)\n",
      "Removing feature: X1481 (VIF: 310593077749689.4)\n",
      "Removing feature: X1314 (VIF: 333599972397814.5)\n",
      "Removing feature: X1017 (VIF: 290554814669064.25)\n",
      "Removing feature: X1982 (VIF: 391617358901782.25)\n",
      "Removing feature: X1610 (VIF: 250199979298360.88)\n",
      "Removing feature: X1157 (VIF: 230953827044640.8)\n",
      "Removing feature: X1026 (VIF: 237031559335289.25)\n",
      "Removing feature: X1087 (VIF: 214457125112880.75)\n",
      "Removing feature: X1542 (VIF: 169947155749830.03)\n",
      "Removing feature: X252 (VIF: 176611750092960.62)\n",
      "Removing feature: X1738 (VIF: 152664394148152.4)\n",
      "Removing feature: X233 (VIF: 163767259177108.94)\n",
      "Removing feature: X1698 (VIF: 169947155749830.03)\n",
      "Removing feature: X1963 (VIF: 230953827044640.8)\n",
      "Removing feature: X1407 (VIF: 187649984473770.66)\n",
      "Removing feature: X1103 (VIF: 147659004176081.84)\n",
      "Removing feature: X1904 (VIF: 142971416741920.5)\n",
      "Removing feature: X1012 (VIF: 138572296226784.5)\n",
      "Removing feature: X1727 (VIF: 140737488355328.0)\n",
      "Removing feature: X1494 (VIF: 116976613697934.97)\n",
      "Removing feature: X1591 (VIF: 147659004176081.84)\n",
      "Removing feature: X1490 (VIF: 118515779667644.62)\n",
      "Removing feature: X1977 (VIF: 142971416741920.5)\n",
      "Removing feature: X1198 (VIF: 85782850045152.31)\n",
      "Removing feature: X1533 (VIF: 115476913522320.4)\n",
      "Removing feature: X1920 (VIF: 84179432287298.98)\n",
      "Removing feature: X1820 (VIF: 77648269437422.34)\n",
      "Removing feature: X1730 (VIF: 80421421917330.28)\n",
      "Removing feature: X1671 (VIF: 50888131382717.47)\n",
      "Removing feature: X1536 (VIF: 44152937523240.16)\n",
      "Removing feature: X1551 (VIF: 50602243004162.875)\n",
      "Removing feature: X339 (VIF: 58488306848967.484)\n",
      "Removing feature: X863 (VIF: 39332747837296.91)\n",
      "Removing feature: X1888 (VIF: 28147497671065.6)\n",
      "Removing feature: X1420 (VIF: 38166098537038.1)\n",
      "Removing feature: X23 (VIF: 18843513085232.2)\n",
      "Removing feature: X562 (VIF: 17422048848628.611)\n",
      "Removing feature: X1997 (VIF: 16055613644814.602)\n",
      "Removing feature: X1795 (VIF: 15998577717124.32)\n",
      "Removing feature: X1067 (VIF: 15370647192390.771)\n",
      "Removing feature: X5 (VIF: inf)\n",
      "Removing feature: X1248 (VIF: 1833.5168404782735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X922 (VIF: 111.87842902513107)\n",
      "Removing feature: X1304 (VIF: 65.56928980728149)\n",
      "Removing feature: X715 (VIF: 22.852639445231873)\n",
      "Removing feature: X123 (VIF: 18.743405537830913)\n",
      "Final VIF Values:\n",
      "   Feature       VIF\n",
      "0     X142  5.093085\n",
      "1     X272  2.891568\n",
      "2     X360  7.303266\n",
      "3     X453  6.182611\n",
      "4     X561  5.948733\n",
      "5     X564  7.201366\n",
      "6     X597  6.480216\n",
      "7     X671  6.611825\n",
      "8     X728  4.461438\n",
      "9     X776  5.641143\n",
      "10    X785  8.461722\n",
      "11    X827  6.209064\n",
      "12    X873  5.893840\n",
      "13    X875  4.404976\n",
      "14    X889  6.607837\n",
      "15    X905  7.136305\n",
      "16    X982  4.089656\n",
      "17   X1011  9.538619\n",
      "18   X1043  5.382247\n",
      "19   X1044  6.544717\n",
      "20   X1055  6.466959\n",
      "21   X1061  7.333300\n",
      "22   X1124  7.964637\n",
      "23   X1183  8.318664\n",
      "24   X1243  5.433006\n",
      "25   X1244  3.448002\n",
      "26   X1266  6.923495\n",
      "27   X1440  6.662039\n",
      "28   X1455  3.758081\n",
      "29   X1571  3.972570\n",
      "30   X1572  8.091970\n",
      "31   X1600  3.251969\n",
      "32   X1638  4.881819\n",
      "33   X1673  5.522429\n",
      "34   X1717  6.806852\n",
      "35   X1766  5.983199\n",
      "36   X1805  4.195931\n",
      "37   X1871  4.912827\n",
      "38   X1877  5.052058\n",
      "39   X1905  8.844524\n",
      "40   X1909  7.793367\n",
      "41   X1918  3.683120\n",
      "42   X1930  6.610108\n",
      "43   X1989  3.438292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace 'genotype.csv' with the actual path to your file\n",
    "data = pd.read_csv(r\"C:\\Users\\Sandesh\\Desktop\\New folder\\Dataset_rfe.csv\")  \n",
    "\n",
    "# Replace 'Phenotype' with the name of the target column if necessary\n",
    "X = data.drop(columns=[\"Phenotype\"])  # Independent variables\n",
    "y = pd.read_csv(r\"C:\\Users\\Sandesh\\Desktop\\New folder\\phenotype.csv\")\n",
    "X_standardized = X\n",
    "\n",
    "\n",
    "# Step 3: Define a function to calculate VIF\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Step 4: Calculate initial VIF\n",
    "vif_df = calculate_vif(X_standardized)\n",
    "print(\"Initial VIF Values:\")\n",
    "print(vif_df)\n",
    "\n",
    "# Step 5: Remove features with high VIF iteratively\n",
    "threshold = 10\n",
    "while vif_df[\"VIF\"].max() > threshold:\n",
    "    feature_to_remove = vif_df.loc[vif_df[\"VIF\"].idxmax(), \"Feature\"]\n",
    "    print(f\"Removing feature: {feature_to_remove} (VIF: {vif_df['VIF'].max()})\")\n",
    "    X_standardized = X_standardized.drop(columns=[feature_to_remove])\n",
    "    vif_df = calculate_vif(X_standardized)\n",
    "\n",
    "print(\"Final VIF Values:\")\n",
    "print(vif_df)\n",
    "\n",
    "# X_standardized now contains features with acceptable multicollinearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "002e883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X142</th>\n",
       "      <th>X272</th>\n",
       "      <th>X360</th>\n",
       "      <th>X453</th>\n",
       "      <th>X561</th>\n",
       "      <th>X564</th>\n",
       "      <th>X597</th>\n",
       "      <th>X671</th>\n",
       "      <th>X728</th>\n",
       "      <th>X776</th>\n",
       "      <th>...</th>\n",
       "      <th>X1717</th>\n",
       "      <th>X1766</th>\n",
       "      <th>X1805</th>\n",
       "      <th>X1871</th>\n",
       "      <th>X1877</th>\n",
       "      <th>X1905</th>\n",
       "      <th>X1909</th>\n",
       "      <th>X1918</th>\n",
       "      <th>X1930</th>\n",
       "      <th>X1989</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.249409</td>\n",
       "      <td>1.568163</td>\n",
       "      <td>1.125810</td>\n",
       "      <td>0.711784</td>\n",
       "      <td>1.271865</td>\n",
       "      <td>0.840418</td>\n",
       "      <td>-0.263967</td>\n",
       "      <td>-0.349348</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>0.655466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986518</td>\n",
       "      <td>-0.838144</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>-2.129890</td>\n",
       "      <td>-0.361329</td>\n",
       "      <td>-0.487599</td>\n",
       "      <td>0.532695</td>\n",
       "      <td>1.423379</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>-0.602507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.870702</td>\n",
       "      <td>0.158488</td>\n",
       "      <td>-0.936967</td>\n",
       "      <td>-1.603290</td>\n",
       "      <td>-1.071022</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>-1.384969</td>\n",
       "      <td>-0.802604</td>\n",
       "      <td>-1.654007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966563</td>\n",
       "      <td>-0.993953</td>\n",
       "      <td>0.124873</td>\n",
       "      <td>1.272922</td>\n",
       "      <td>2.797161</td>\n",
       "      <td>0.591919</td>\n",
       "      <td>1.512906</td>\n",
       "      <td>-0.850299</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>-0.885349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417953</td>\n",
       "      <td>-0.552798</td>\n",
       "      <td>0.646078</td>\n",
       "      <td>-1.250691</td>\n",
       "      <td>-0.288352</td>\n",
       "      <td>0.709452</td>\n",
       "      <td>-0.624321</td>\n",
       "      <td>-1.788471</td>\n",
       "      <td>0.341925</td>\n",
       "      <td>-0.359369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143718</td>\n",
       "      <td>0.673208</td>\n",
       "      <td>-1.068068</td>\n",
       "      <td>-0.163226</td>\n",
       "      <td>0.565365</td>\n",
       "      <td>-0.720831</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-1.620022</td>\n",
       "      <td>-0.775336</td>\n",
       "      <td>-0.314378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016771</td>\n",
       "      <td>-2.048618</td>\n",
       "      <td>-0.216376</td>\n",
       "      <td>1.151214</td>\n",
       "      <td>-2.132672</td>\n",
       "      <td>2.013973</td>\n",
       "      <td>-0.423597</td>\n",
       "      <td>0.346573</td>\n",
       "      <td>-2.335538</td>\n",
       "      <td>0.137511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545146</td>\n",
       "      <td>-1.231386</td>\n",
       "      <td>0.789447</td>\n",
       "      <td>0.707267</td>\n",
       "      <td>1.010862</td>\n",
       "      <td>-0.606913</td>\n",
       "      <td>1.290897</td>\n",
       "      <td>0.757219</td>\n",
       "      <td>0.738596</td>\n",
       "      <td>0.591696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.843358</td>\n",
       "      <td>-0.352327</td>\n",
       "      <td>0.179798</td>\n",
       "      <td>-0.868005</td>\n",
       "      <td>2.155207</td>\n",
       "      <td>0.443271</td>\n",
       "      <td>-1.555152</td>\n",
       "      <td>-1.114805</td>\n",
       "      <td>-0.720515</td>\n",
       "      <td>-1.049472</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.076962</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>-1.020345</td>\n",
       "      <td>0.619546</td>\n",
       "      <td>1.870858</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.819591</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>-0.566678</td>\n",
       "      <td>1.785798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.264955</td>\n",
       "      <td>0.682733</td>\n",
       "      <td>-0.302484</td>\n",
       "      <td>-0.971136</td>\n",
       "      <td>-0.824829</td>\n",
       "      <td>0.987670</td>\n",
       "      <td>0.996937</td>\n",
       "      <td>-0.667064</td>\n",
       "      <td>0.815016</td>\n",
       "      <td>1.056478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360295</td>\n",
       "      <td>-0.434452</td>\n",
       "      <td>0.527155</td>\n",
       "      <td>1.026248</td>\n",
       "      <td>-0.217184</td>\n",
       "      <td>0.783978</td>\n",
       "      <td>1.206786</td>\n",
       "      <td>1.348671</td>\n",
       "      <td>0.291350</td>\n",
       "      <td>-0.807512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.870010</td>\n",
       "      <td>0.714208</td>\n",
       "      <td>-0.674424</td>\n",
       "      <td>0.872967</td>\n",
       "      <td>0.720581</td>\n",
       "      <td>0.481076</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>-1.934803</td>\n",
       "      <td>0.419677</td>\n",
       "      <td>-1.620618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126896</td>\n",
       "      <td>-0.538900</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.971775</td>\n",
       "      <td>1.242384</td>\n",
       "      <td>1.135165</td>\n",
       "      <td>0.543484</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>0.157062</td>\n",
       "      <td>-0.968501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.484004</td>\n",
       "      <td>-0.570079</td>\n",
       "      <td>0.156395</td>\n",
       "      <td>1.026807</td>\n",
       "      <td>-2.314570</td>\n",
       "      <td>0.915716</td>\n",
       "      <td>1.157932</td>\n",
       "      <td>1.173063</td>\n",
       "      <td>1.140964</td>\n",
       "      <td>0.577900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>0.383593</td>\n",
       "      <td>-1.371423</td>\n",
       "      <td>1.949728</td>\n",
       "      <td>0.327946</td>\n",
       "      <td>-0.507633</td>\n",
       "      <td>0.438548</td>\n",
       "      <td>1.003838</td>\n",
       "      <td>-0.286521</td>\n",
       "      <td>-0.809103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.505378</td>\n",
       "      <td>1.519541</td>\n",
       "      <td>-0.893808</td>\n",
       "      <td>-0.044584</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.533965</td>\n",
       "      <td>0.462832</td>\n",
       "      <td>-0.036990</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>-1.587063</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.072214</td>\n",
       "      <td>0.027022</td>\n",
       "      <td>0.336844</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-1.106138</td>\n",
       "      <td>0.840831</td>\n",
       "      <td>1.578551</td>\n",
       "      <td>-0.505517</td>\n",
       "      <td>-3.042619</td>\n",
       "      <td>0.553487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.612856</td>\n",
       "      <td>0.515833</td>\n",
       "      <td>-0.651477</td>\n",
       "      <td>0.905342</td>\n",
       "      <td>-0.617212</td>\n",
       "      <td>1.019360</td>\n",
       "      <td>1.396665</td>\n",
       "      <td>-0.550788</td>\n",
       "      <td>-1.385569</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.196830</td>\n",
       "      <td>0.403029</td>\n",
       "      <td>-0.088789</td>\n",
       "      <td>1.821891</td>\n",
       "      <td>-0.295737</td>\n",
       "      <td>0.919460</td>\n",
       "      <td>-0.962120</td>\n",
       "      <td>-0.124618</td>\n",
       "      <td>0.189774</td>\n",
       "      <td>-0.356320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.334818</td>\n",
       "      <td>0.035217</td>\n",
       "      <td>0.150259</td>\n",
       "      <td>0.939482</td>\n",
       "      <td>-1.209807</td>\n",
       "      <td>-0.783941</td>\n",
       "      <td>0.590884</td>\n",
       "      <td>-2.743786</td>\n",
       "      <td>0.584231</td>\n",
       "      <td>-2.269297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743865</td>\n",
       "      <td>0.382781</td>\n",
       "      <td>0.143922</td>\n",
       "      <td>-0.763061</td>\n",
       "      <td>-1.707292</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.475092</td>\n",
       "      <td>-0.920464</td>\n",
       "      <td>-0.838316</td>\n",
       "      <td>-0.679007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.033005</td>\n",
       "      <td>-0.182215</td>\n",
       "      <td>0.167737</td>\n",
       "      <td>0.320292</td>\n",
       "      <td>-0.241685</td>\n",
       "      <td>-0.428893</td>\n",
       "      <td>1.040453</td>\n",
       "      <td>-0.488217</td>\n",
       "      <td>0.935167</td>\n",
       "      <td>-0.401473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181355</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.781259</td>\n",
       "      <td>0.569627</td>\n",
       "      <td>0.174203</td>\n",
       "      <td>0.840668</td>\n",
       "      <td>0.891634</td>\n",
       "      <td>1.039288</td>\n",
       "      <td>0.704507</td>\n",
       "      <td>-0.051820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.195364</td>\n",
       "      <td>-0.522029</td>\n",
       "      <td>-1.354569</td>\n",
       "      <td>0.169509</td>\n",
       "      <td>0.316084</td>\n",
       "      <td>-0.407314</td>\n",
       "      <td>1.346015</td>\n",
       "      <td>1.076358</td>\n",
       "      <td>1.270729</td>\n",
       "      <td>-0.549957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.854030</td>\n",
       "      <td>-2.232684</td>\n",
       "      <td>-0.114081</td>\n",
       "      <td>0.139858</td>\n",
       "      <td>-0.675113</td>\n",
       "      <td>-1.433497</td>\n",
       "      <td>1.620152</td>\n",
       "      <td>0.794146</td>\n",
       "      <td>-0.971084</td>\n",
       "      <td>0.401746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.250896</td>\n",
       "      <td>-0.375973</td>\n",
       "      <td>-1.223737</td>\n",
       "      <td>0.409868</td>\n",
       "      <td>-0.799912</td>\n",
       "      <td>-0.293606</td>\n",
       "      <td>-1.203276</td>\n",
       "      <td>-0.461073</td>\n",
       "      <td>0.133594</td>\n",
       "      <td>0.823369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156016</td>\n",
       "      <td>1.739863</td>\n",
       "      <td>-0.985799</td>\n",
       "      <td>0.166943</td>\n",
       "      <td>-0.297770</td>\n",
       "      <td>1.400469</td>\n",
       "      <td>-0.720094</td>\n",
       "      <td>-0.714174</td>\n",
       "      <td>1.242348</td>\n",
       "      <td>-0.103041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.613084</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>-1.359745</td>\n",
       "      <td>1.429431</td>\n",
       "      <td>1.347217</td>\n",
       "      <td>-0.537766</td>\n",
       "      <td>-0.196051</td>\n",
       "      <td>0.753592</td>\n",
       "      <td>1.811158</td>\n",
       "      <td>-1.021224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365666</td>\n",
       "      <td>1.459939</td>\n",
       "      <td>-0.683917</td>\n",
       "      <td>-0.624789</td>\n",
       "      <td>1.067460</td>\n",
       "      <td>0.810842</td>\n",
       "      <td>0.079006</td>\n",
       "      <td>1.739279</td>\n",
       "      <td>-1.102826</td>\n",
       "      <td>-0.286523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.517141</td>\n",
       "      <td>-0.045924</td>\n",
       "      <td>1.114496</td>\n",
       "      <td>0.237294</td>\n",
       "      <td>0.968009</td>\n",
       "      <td>-0.728454</td>\n",
       "      <td>1.443304</td>\n",
       "      <td>1.320900</td>\n",
       "      <td>-1.835049</td>\n",
       "      <td>0.852636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716854</td>\n",
       "      <td>0.501362</td>\n",
       "      <td>0.541683</td>\n",
       "      <td>1.004691</td>\n",
       "      <td>0.816479</td>\n",
       "      <td>0.516720</td>\n",
       "      <td>-1.859654</td>\n",
       "      <td>1.067264</td>\n",
       "      <td>-2.046410</td>\n",
       "      <td>0.090338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002356</td>\n",
       "      <td>1.424646</td>\n",
       "      <td>-1.353052</td>\n",
       "      <td>1.544073</td>\n",
       "      <td>-0.061376</td>\n",
       "      <td>-0.794775</td>\n",
       "      <td>0.532008</td>\n",
       "      <td>-0.421069</td>\n",
       "      <td>1.017708</td>\n",
       "      <td>-1.058350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346286</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>-0.447940</td>\n",
       "      <td>-1.285475</td>\n",
       "      <td>0.716438</td>\n",
       "      <td>-1.714357</td>\n",
       "      <td>-0.685598</td>\n",
       "      <td>-0.639155</td>\n",
       "      <td>-0.460880</td>\n",
       "      <td>-0.548257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.809946</td>\n",
       "      <td>-0.024967</td>\n",
       "      <td>0.648362</td>\n",
       "      <td>-1.158626</td>\n",
       "      <td>0.981462</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.918691</td>\n",
       "      <td>-0.732421</td>\n",
       "      <td>-1.105890</td>\n",
       "      <td>0.105844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376879</td>\n",
       "      <td>-0.215025</td>\n",
       "      <td>-0.022102</td>\n",
       "      <td>-0.236774</td>\n",
       "      <td>-0.359100</td>\n",
       "      <td>1.705418</td>\n",
       "      <td>-1.300816</td>\n",
       "      <td>-1.035269</td>\n",
       "      <td>-0.944274</td>\n",
       "      <td>-1.321088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.267925</td>\n",
       "      <td>-0.676707</td>\n",
       "      <td>0.215589</td>\n",
       "      <td>-1.305136</td>\n",
       "      <td>0.528556</td>\n",
       "      <td>-1.076244</td>\n",
       "      <td>-0.992120</td>\n",
       "      <td>0.698656</td>\n",
       "      <td>0.574112</td>\n",
       "      <td>-0.339096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046818</td>\n",
       "      <td>-0.011860</td>\n",
       "      <td>1.060225</td>\n",
       "      <td>-0.258866</td>\n",
       "      <td>0.609170</td>\n",
       "      <td>-0.392034</td>\n",
       "      <td>0.660524</td>\n",
       "      <td>-0.885924</td>\n",
       "      <td>0.055031</td>\n",
       "      <td>0.367228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.823746</td>\n",
       "      <td>-1.777197</td>\n",
       "      <td>1.490487</td>\n",
       "      <td>1.884350</td>\n",
       "      <td>-1.089531</td>\n",
       "      <td>0.607409</td>\n",
       "      <td>-0.105193</td>\n",
       "      <td>-0.025265</td>\n",
       "      <td>-0.211144</td>\n",
       "      <td>0.964546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105873</td>\n",
       "      <td>1.526963</td>\n",
       "      <td>3.026076</td>\n",
       "      <td>0.706599</td>\n",
       "      <td>-1.046273</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>0.379312</td>\n",
       "      <td>-0.588686</td>\n",
       "      <td>0.238336</td>\n",
       "      <td>-0.149405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.248959</td>\n",
       "      <td>1.100489</td>\n",
       "      <td>-0.111560</td>\n",
       "      <td>-0.602319</td>\n",
       "      <td>0.862675</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>0.285858</td>\n",
       "      <td>-0.261055</td>\n",
       "      <td>-0.034880</td>\n",
       "      <td>-0.008627</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.780722</td>\n",
       "      <td>-0.373496</td>\n",
       "      <td>-0.783879</td>\n",
       "      <td>-2.982338</td>\n",
       "      <td>1.588417</td>\n",
       "      <td>-0.521467</td>\n",
       "      <td>0.136156</td>\n",
       "      <td>-1.125725</td>\n",
       "      <td>0.924172</td>\n",
       "      <td>-1.594084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.690636</td>\n",
       "      <td>-0.267930</td>\n",
       "      <td>-1.378445</td>\n",
       "      <td>-0.367718</td>\n",
       "      <td>1.810063</td>\n",
       "      <td>-1.045596</td>\n",
       "      <td>-0.216239</td>\n",
       "      <td>-0.728920</td>\n",
       "      <td>0.161649</td>\n",
       "      <td>-0.692377</td>\n",
       "      <td>...</td>\n",
       "      <td>1.788568</td>\n",
       "      <td>0.371680</td>\n",
       "      <td>0.216951</td>\n",
       "      <td>-0.697507</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>-2.144401</td>\n",
       "      <td>1.314715</td>\n",
       "      <td>0.547558</td>\n",
       "      <td>-0.037767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.017720</td>\n",
       "      <td>-1.302508</td>\n",
       "      <td>0.469278</td>\n",
       "      <td>0.080457</td>\n",
       "      <td>-0.339516</td>\n",
       "      <td>2.702655</td>\n",
       "      <td>-0.847837</td>\n",
       "      <td>0.628781</td>\n",
       "      <td>0.051155</td>\n",
       "      <td>-0.452759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877788</td>\n",
       "      <td>-1.166637</td>\n",
       "      <td>-0.878166</td>\n",
       "      <td>1.057760</td>\n",
       "      <td>-1.736979</td>\n",
       "      <td>-1.730782</td>\n",
       "      <td>0.482344</td>\n",
       "      <td>-0.469469</td>\n",
       "      <td>0.643803</td>\n",
       "      <td>0.247301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.432093</td>\n",
       "      <td>-0.815070</td>\n",
       "      <td>1.654094</td>\n",
       "      <td>-0.079096</td>\n",
       "      <td>0.136901</td>\n",
       "      <td>-1.194686</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>-0.391983</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>-0.266621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>-0.827317</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>-0.540334</td>\n",
       "      <td>0.970482</td>\n",
       "      <td>-0.298262</td>\n",
       "      <td>-1.718431</td>\n",
       "      <td>0.895326</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.985495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.326345</td>\n",
       "      <td>2.360498</td>\n",
       "      <td>-0.028926</td>\n",
       "      <td>0.037641</td>\n",
       "      <td>-0.844809</td>\n",
       "      <td>1.200124</td>\n",
       "      <td>-0.719920</td>\n",
       "      <td>0.167232</td>\n",
       "      <td>0.723035</td>\n",
       "      <td>1.033524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241846</td>\n",
       "      <td>-1.380123</td>\n",
       "      <td>-0.708717</td>\n",
       "      <td>1.235421</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>-1.421818</td>\n",
       "      <td>-1.872257</td>\n",
       "      <td>-1.010318</td>\n",
       "      <td>0.417168</td>\n",
       "      <td>0.678652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.054602</td>\n",
       "      <td>-1.191695</td>\n",
       "      <td>0.422371</td>\n",
       "      <td>1.726401</td>\n",
       "      <td>-0.387097</td>\n",
       "      <td>0.817849</td>\n",
       "      <td>-0.142979</td>\n",
       "      <td>1.728085</td>\n",
       "      <td>0.269422</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699630</td>\n",
       "      <td>0.605107</td>\n",
       "      <td>0.263811</td>\n",
       "      <td>0.306097</td>\n",
       "      <td>-1.658897</td>\n",
       "      <td>-1.710104</td>\n",
       "      <td>0.363345</td>\n",
       "      <td>-0.995995</td>\n",
       "      <td>-0.400018</td>\n",
       "      <td>-0.557544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.272058</td>\n",
       "      <td>-0.621369</td>\n",
       "      <td>-0.639422</td>\n",
       "      <td>0.318882</td>\n",
       "      <td>-1.168663</td>\n",
       "      <td>-2.121348</td>\n",
       "      <td>-0.296696</td>\n",
       "      <td>0.244406</td>\n",
       "      <td>2.167375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371162</td>\n",
       "      <td>-1.072881</td>\n",
       "      <td>-1.508321</td>\n",
       "      <td>-0.510814</td>\n",
       "      <td>1.456227</td>\n",
       "      <td>0.174108</td>\n",
       "      <td>0.331242</td>\n",
       "      <td>0.323125</td>\n",
       "      <td>-0.609264</td>\n",
       "      <td>0.825213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.497782</td>\n",
       "      <td>-1.708829</td>\n",
       "      <td>-1.655251</td>\n",
       "      <td>-0.880199</td>\n",
       "      <td>-0.584995</td>\n",
       "      <td>0.508702</td>\n",
       "      <td>1.743673</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>-0.194697</td>\n",
       "      <td>-0.080779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585596</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>0.342858</td>\n",
       "      <td>-1.463495</td>\n",
       "      <td>-0.120760</td>\n",
       "      <td>1.338165</td>\n",
       "      <td>-0.777633</td>\n",
       "      <td>0.672435</td>\n",
       "      <td>1.594673</td>\n",
       "      <td>2.039983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.110488</td>\n",
       "      <td>-0.222707</td>\n",
       "      <td>-2.060066</td>\n",
       "      <td>-0.806188</td>\n",
       "      <td>1.257826</td>\n",
       "      <td>-0.357296</td>\n",
       "      <td>0.867260</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.263595</td>\n",
       "      <td>1.231784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239445</td>\n",
       "      <td>-0.627869</td>\n",
       "      <td>1.711837</td>\n",
       "      <td>-0.102761</td>\n",
       "      <td>-0.667358</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.709103</td>\n",
       "      <td>-0.385888</td>\n",
       "      <td>-0.579766</td>\n",
       "      <td>0.086509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.158744</td>\n",
       "      <td>0.298536</td>\n",
       "      <td>0.844679</td>\n",
       "      <td>0.889688</td>\n",
       "      <td>-0.702531</td>\n",
       "      <td>-0.628059</td>\n",
       "      <td>-1.634990</td>\n",
       "      <td>0.501256</td>\n",
       "      <td>1.608680</td>\n",
       "      <td>1.114172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.986816</td>\n",
       "      <td>-0.971565</td>\n",
       "      <td>0.565095</td>\n",
       "      <td>-0.198416</td>\n",
       "      <td>-1.121547</td>\n",
       "      <td>0.990794</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.205765</td>\n",
       "      <td>-0.845368</td>\n",
       "      <td>1.683156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.127842</td>\n",
       "      <td>-0.223727</td>\n",
       "      <td>1.292963</td>\n",
       "      <td>1.666215</td>\n",
       "      <td>-1.122716</td>\n",
       "      <td>0.804472</td>\n",
       "      <td>-1.498092</td>\n",
       "      <td>2.146565</td>\n",
       "      <td>0.022905</td>\n",
       "      <td>-1.423223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013935</td>\n",
       "      <td>1.790910</td>\n",
       "      <td>1.408362</td>\n",
       "      <td>1.117245</td>\n",
       "      <td>0.034506</td>\n",
       "      <td>-0.400991</td>\n",
       "      <td>0.222862</td>\n",
       "      <td>0.501602</td>\n",
       "      <td>0.404224</td>\n",
       "      <td>-0.081870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1.259069</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>-0.477530</td>\n",
       "      <td>0.202344</td>\n",
       "      <td>1.570171</td>\n",
       "      <td>-0.189702</td>\n",
       "      <td>-0.919962</td>\n",
       "      <td>0.467825</td>\n",
       "      <td>-0.301439</td>\n",
       "      <td>0.320218</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.722558</td>\n",
       "      <td>-0.819341</td>\n",
       "      <td>1.184111</td>\n",
       "      <td>-2.014289</td>\n",
       "      <td>-0.664687</td>\n",
       "      <td>0.701390</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>-1.642118</td>\n",
       "      <td>-1.172437</td>\n",
       "      <td>-0.743402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-1.898590</td>\n",
       "      <td>-0.217424</td>\n",
       "      <td>-0.225589</td>\n",
       "      <td>-1.363810</td>\n",
       "      <td>-0.064851</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>-0.583451</td>\n",
       "      <td>0.065558</td>\n",
       "      <td>-0.982436</td>\n",
       "      <td>0.394963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.882324</td>\n",
       "      <td>-1.033133</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.205747</td>\n",
       "      <td>0.132158</td>\n",
       "      <td>-1.466099</td>\n",
       "      <td>-1.143877</td>\n",
       "      <td>0.844709</td>\n",
       "      <td>1.686469</td>\n",
       "      <td>-1.013554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.985112</td>\n",
       "      <td>0.852511</td>\n",
       "      <td>-0.352459</td>\n",
       "      <td>-1.043612</td>\n",
       "      <td>0.195197</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>1.592509</td>\n",
       "      <td>-0.175320</td>\n",
       "      <td>1.128746</td>\n",
       "      <td>1.555091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907464</td>\n",
       "      <td>-0.069603</td>\n",
       "      <td>-1.257553</td>\n",
       "      <td>-0.451738</td>\n",
       "      <td>0.537745</td>\n",
       "      <td>-0.510845</td>\n",
       "      <td>0.350730</td>\n",
       "      <td>-0.424155</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>1.303558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.395270</td>\n",
       "      <td>-0.070299</td>\n",
       "      <td>0.467713</td>\n",
       "      <td>0.301241</td>\n",
       "      <td>1.096270</td>\n",
       "      <td>-0.336152</td>\n",
       "      <td>0.410360</td>\n",
       "      <td>-0.078326</td>\n",
       "      <td>1.102683</td>\n",
       "      <td>-0.318526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866784</td>\n",
       "      <td>1.353233</td>\n",
       "      <td>-1.230553</td>\n",
       "      <td>0.336590</td>\n",
       "      <td>-0.561704</td>\n",
       "      <td>0.805024</td>\n",
       "      <td>-0.583254</td>\n",
       "      <td>-0.538699</td>\n",
       "      <td>0.634445</td>\n",
       "      <td>-0.892469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1.023366</td>\n",
       "      <td>1.496629</td>\n",
       "      <td>1.951467</td>\n",
       "      <td>-0.425810</td>\n",
       "      <td>0.524413</td>\n",
       "      <td>0.615106</td>\n",
       "      <td>-1.665859</td>\n",
       "      <td>0.421766</td>\n",
       "      <td>-0.302420</td>\n",
       "      <td>0.819240</td>\n",
       "      <td>...</td>\n",
       "      <td>1.504213</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>-1.489723</td>\n",
       "      <td>-0.321739</td>\n",
       "      <td>0.625750</td>\n",
       "      <td>1.461683</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>-0.312387</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>-0.202681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1.270295</td>\n",
       "      <td>0.687305</td>\n",
       "      <td>1.579835</td>\n",
       "      <td>-1.230045</td>\n",
       "      <td>-0.638149</td>\n",
       "      <td>0.872061</td>\n",
       "      <td>-0.008952</td>\n",
       "      <td>-0.161988</td>\n",
       "      <td>-0.230398</td>\n",
       "      <td>-1.214473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335162</td>\n",
       "      <td>-0.273891</td>\n",
       "      <td>-0.697389</td>\n",
       "      <td>1.513069</td>\n",
       "      <td>0.348401</td>\n",
       "      <td>-2.850355</td>\n",
       "      <td>1.487198</td>\n",
       "      <td>-1.710007</td>\n",
       "      <td>2.348089</td>\n",
       "      <td>-2.495564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.087223</td>\n",
       "      <td>-0.090587</td>\n",
       "      <td>1.588481</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>-0.567855</td>\n",
       "      <td>0.663795</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>-0.552266</td>\n",
       "      <td>-1.593218</td>\n",
       "      <td>0.824117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508641</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>-0.346858</td>\n",
       "      <td>-0.501963</td>\n",
       "      <td>0.902805</td>\n",
       "      <td>-0.157644</td>\n",
       "      <td>-1.667233</td>\n",
       "      <td>0.275262</td>\n",
       "      <td>-0.221413</td>\n",
       "      <td>1.813337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.398359</td>\n",
       "      <td>1.024212</td>\n",
       "      <td>-0.108988</td>\n",
       "      <td>-1.550813</td>\n",
       "      <td>1.226812</td>\n",
       "      <td>-0.412912</td>\n",
       "      <td>-1.915350</td>\n",
       "      <td>0.426108</td>\n",
       "      <td>1.681192</td>\n",
       "      <td>-1.166154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005434</td>\n",
       "      <td>1.629311</td>\n",
       "      <td>-1.176197</td>\n",
       "      <td>-0.591605</td>\n",
       "      <td>-0.694447</td>\n",
       "      <td>0.730301</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>-2.219312</td>\n",
       "      <td>-1.199850</td>\n",
       "      <td>0.459782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.333437</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>1.467497</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.703106</td>\n",
       "      <td>-0.519059</td>\n",
       "      <td>0.310175</td>\n",
       "      <td>0.119748</td>\n",
       "      <td>-0.161598</td>\n",
       "      <td>-0.876056</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.042839</td>\n",
       "      <td>0.899216</td>\n",
       "      <td>1.519704</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>-0.488798</td>\n",
       "      <td>0.291851</td>\n",
       "      <td>-0.470426</td>\n",
       "      <td>0.725394</td>\n",
       "      <td>0.074109</td>\n",
       "      <td>-0.188974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.514634</td>\n",
       "      <td>0.304896</td>\n",
       "      <td>-0.866290</td>\n",
       "      <td>-1.273266</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.495347</td>\n",
       "      <td>0.720226</td>\n",
       "      <td>0.455031</td>\n",
       "      <td>-0.757009</td>\n",
       "      <td>-0.256344</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.342346</td>\n",
       "      <td>-0.651101</td>\n",
       "      <td>-0.616337</td>\n",
       "      <td>0.476464</td>\n",
       "      <td>-0.749842</td>\n",
       "      <td>0.342244</td>\n",
       "      <td>0.102890</td>\n",
       "      <td>0.650991</td>\n",
       "      <td>-0.452231</td>\n",
       "      <td>-0.455583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.817331</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.502178</td>\n",
       "      <td>1.947396</td>\n",
       "      <td>-0.310997</td>\n",
       "      <td>0.509029</td>\n",
       "      <td>1.198297</td>\n",
       "      <td>1.539972</td>\n",
       "      <td>0.086388</td>\n",
       "      <td>0.327618</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621656</td>\n",
       "      <td>1.319393</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.697358</td>\n",
       "      <td>-0.084753</td>\n",
       "      <td>0.072605</td>\n",
       "      <td>0.459061</td>\n",
       "      <td>1.514347</td>\n",
       "      <td>1.542219</td>\n",
       "      <td>0.773944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.110656</td>\n",
       "      <td>-2.792998</td>\n",
       "      <td>-0.579520</td>\n",
       "      <td>0.571606</td>\n",
       "      <td>-0.677073</td>\n",
       "      <td>0.456899</td>\n",
       "      <td>1.058304</td>\n",
       "      <td>1.856614</td>\n",
       "      <td>-0.210600</td>\n",
       "      <td>1.532213</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.402324</td>\n",
       "      <td>-1.128573</td>\n",
       "      <td>1.055114</td>\n",
       "      <td>0.805017</td>\n",
       "      <td>1.320698</td>\n",
       "      <td>0.215481</td>\n",
       "      <td>-0.198156</td>\n",
       "      <td>1.776437</td>\n",
       "      <td>-1.854268</td>\n",
       "      <td>0.380418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-1.249598</td>\n",
       "      <td>-0.456199</td>\n",
       "      <td>0.063644</td>\n",
       "      <td>0.290465</td>\n",
       "      <td>1.310384</td>\n",
       "      <td>-1.783478</td>\n",
       "      <td>-1.208766</td>\n",
       "      <td>0.410358</td>\n",
       "      <td>1.619502</td>\n",
       "      <td>-1.044319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>1.289047</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.614925</td>\n",
       "      <td>-0.345523</td>\n",
       "      <td>0.460148</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.750189</td>\n",
       "      <td>0.429070</td>\n",
       "      <td>2.348878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.807665</td>\n",
       "      <td>-1.380233</td>\n",
       "      <td>1.355370</td>\n",
       "      <td>-0.501201</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>-2.280535</td>\n",
       "      <td>0.077679</td>\n",
       "      <td>1.222137</td>\n",
       "      <td>0.143248</td>\n",
       "      <td>1.332544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193462</td>\n",
       "      <td>-2.622905</td>\n",
       "      <td>-1.940834</td>\n",
       "      <td>-0.485053</td>\n",
       "      <td>-1.976481</td>\n",
       "      <td>-0.844589</td>\n",
       "      <td>-1.017864</td>\n",
       "      <td>1.170823</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.227163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.113043</td>\n",
       "      <td>0.019437</td>\n",
       "      <td>-0.474806</td>\n",
       "      <td>0.517467</td>\n",
       "      <td>0.528099</td>\n",
       "      <td>-1.589552</td>\n",
       "      <td>-1.122806</td>\n",
       "      <td>1.139549</td>\n",
       "      <td>-2.252890</td>\n",
       "      <td>0.555787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063558</td>\n",
       "      <td>0.646992</td>\n",
       "      <td>1.446065</td>\n",
       "      <td>-1.384222</td>\n",
       "      <td>0.743467</td>\n",
       "      <td>-0.712448</td>\n",
       "      <td>-0.913097</td>\n",
       "      <td>-1.109096</td>\n",
       "      <td>-0.784516</td>\n",
       "      <td>1.263594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.563555</td>\n",
       "      <td>0.124859</td>\n",
       "      <td>0.899784</td>\n",
       "      <td>-0.576478</td>\n",
       "      <td>-1.767024</td>\n",
       "      <td>-0.710012</td>\n",
       "      <td>-0.462963</td>\n",
       "      <td>-0.428359</td>\n",
       "      <td>-0.847018</td>\n",
       "      <td>-0.812698</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.365054</td>\n",
       "      <td>-0.450793</td>\n",
       "      <td>-0.677795</td>\n",
       "      <td>0.408830</td>\n",
       "      <td>-0.428587</td>\n",
       "      <td>0.453427</td>\n",
       "      <td>1.948004</td>\n",
       "      <td>0.965837</td>\n",
       "      <td>0.709082</td>\n",
       "      <td>-1.514835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.876491</td>\n",
       "      <td>0.379460</td>\n",
       "      <td>0.842800</td>\n",
       "      <td>-0.131901</td>\n",
       "      <td>-1.436596</td>\n",
       "      <td>-0.111519</td>\n",
       "      <td>0.202112</td>\n",
       "      <td>-1.200294</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>1.728909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507345</td>\n",
       "      <td>-0.444546</td>\n",
       "      <td>-0.023700</td>\n",
       "      <td>-0.064766</td>\n",
       "      <td>-1.220138</td>\n",
       "      <td>-1.191618</td>\n",
       "      <td>-1.252607</td>\n",
       "      <td>-0.144561</td>\n",
       "      <td>-0.297459</td>\n",
       "      <td>-1.693445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.106189</td>\n",
       "      <td>0.250564</td>\n",
       "      <td>-0.755103</td>\n",
       "      <td>-1.996310</td>\n",
       "      <td>-0.052435</td>\n",
       "      <td>-1.739802</td>\n",
       "      <td>-0.104535</td>\n",
       "      <td>-2.018652</td>\n",
       "      <td>-2.291933</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291221</td>\n",
       "      <td>0.227128</td>\n",
       "      <td>-0.987092</td>\n",
       "      <td>1.263341</td>\n",
       "      <td>-0.487931</td>\n",
       "      <td>0.744031</td>\n",
       "      <td>-0.224342</td>\n",
       "      <td>0.475669</td>\n",
       "      <td>0.754459</td>\n",
       "      <td>0.394249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.371989</td>\n",
       "      <td>2.050487</td>\n",
       "      <td>-1.630269</td>\n",
       "      <td>-0.268340</td>\n",
       "      <td>-0.273032</td>\n",
       "      <td>-1.655492</td>\n",
       "      <td>1.444483</td>\n",
       "      <td>-0.035196</td>\n",
       "      <td>-0.308336</td>\n",
       "      <td>-0.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>0.188480</td>\n",
       "      <td>0.358954</td>\n",
       "      <td>-0.049431</td>\n",
       "      <td>-1.289793</td>\n",
       "      <td>1.611939</td>\n",
       "      <td>0.694420</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>1.451116</td>\n",
       "      <td>0.507385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X142      X272      X360      X453      X561      X564      X597  \\\n",
       "0   1.249409  1.568163  1.125810  0.711784  1.271865  0.840418 -0.263967   \n",
       "1   1.870702  0.158488 -0.936967 -1.603290 -1.071022  0.498423  0.094053   \n",
       "2  -0.417953 -0.552798  0.646078 -1.250691 -0.288352  0.709452 -0.624321   \n",
       "3   0.016771 -2.048618 -0.216376  1.151214 -2.132672  2.013973 -0.423597   \n",
       "4   1.843358 -0.352327  0.179798 -0.868005  2.155207  0.443271 -1.555152   \n",
       "5  -0.264955  0.682733 -0.302484 -0.971136 -0.824829  0.987670  0.996937   \n",
       "6  -0.870010  0.714208 -0.674424  0.872967  0.720581  0.481076  0.555276   \n",
       "7   0.484004 -0.570079  0.156395  1.026807 -2.314570  0.915716  1.157932   \n",
       "8   2.505378  1.519541 -0.893808 -0.044584  0.020360  0.533965  0.462832   \n",
       "9  -0.612856  0.515833 -0.651477  0.905342 -0.617212  1.019360  1.396665   \n",
       "10 -0.334818  0.035217  0.150259  0.939482 -1.209807 -0.783941  0.590884   \n",
       "11  0.033005 -0.182215  0.167737  0.320292 -0.241685 -0.428893  1.040453   \n",
       "12  0.195364 -0.522029 -1.354569  0.169509  0.316084 -0.407314  1.346015   \n",
       "13 -0.250896 -0.375973 -1.223737  0.409868 -0.799912 -0.293606 -1.203276   \n",
       "14  0.613084  0.229977 -1.359745  1.429431  1.347217 -0.537766 -0.196051   \n",
       "15 -0.517141 -0.045924  1.114496  0.237294  0.968009 -0.728454  1.443304   \n",
       "16  0.002356  1.424646 -1.353052  1.544073 -0.061376 -0.794775  0.532008   \n",
       "17  0.809946 -0.024967  0.648362 -1.158626  0.981462  0.028324  0.918691   \n",
       "18  0.267925 -0.676707  0.215589 -1.305136  0.528556 -1.076244 -0.992120   \n",
       "19  0.823746 -1.777197  1.490487  1.884350 -1.089531  0.607409 -0.105193   \n",
       "20 -1.248959  1.100489 -0.111560 -0.602319  0.862675  0.825528  0.285858   \n",
       "21 -0.690636 -0.267930 -1.378445 -0.367718  1.810063 -1.045596 -0.216239   \n",
       "22 -0.017720 -1.302508  0.469278  0.080457 -0.339516  2.702655 -0.847837   \n",
       "23 -1.432093 -0.815070  1.654094 -0.079096  0.136901 -1.194686  0.001592   \n",
       "24  0.326345  2.360498 -0.028926  0.037641 -0.844809  1.200124 -0.719920   \n",
       "25  1.054602 -1.191695  0.422371  1.726401 -0.387097  0.817849 -0.142979   \n",
       "26  0.005735  0.272058 -0.621369 -0.639422  0.318882 -1.168663 -2.121348   \n",
       "27 -1.497782 -1.708829 -1.655251 -0.880199 -0.584995  0.508702  1.743673   \n",
       "28 -0.110488 -0.222707 -2.060066 -0.806188  1.257826 -0.357296  0.867260   \n",
       "29 -1.158744  0.298536  0.844679  0.889688 -0.702531 -0.628059 -1.634990   \n",
       "30 -0.127842 -0.223727  1.292963  1.666215 -1.122716  0.804472 -1.498092   \n",
       "31 -1.259069  0.008372 -0.477530  0.202344  1.570171 -0.189702 -0.919962   \n",
       "32 -1.898590 -0.217424 -0.225589 -1.363810 -0.064851  1.185185 -0.583451   \n",
       "33  0.985112  0.852511 -0.352459 -1.043612  0.195197  0.037696  1.592509   \n",
       "34  0.395270 -0.070299  0.467713  0.301241  1.096270 -0.336152  0.410360   \n",
       "35 -1.023366  1.496629  1.951467 -0.425810  0.524413  0.615106 -1.665859   \n",
       "36 -1.270295  0.687305  1.579835 -1.230045 -0.638149  0.872061 -0.008952   \n",
       "37 -1.087223 -0.090587  1.588481  0.523956 -0.567855  0.663795  0.090148   \n",
       "38 -0.398359  1.024212 -0.108988 -1.550813  1.226812 -0.412912 -1.915350   \n",
       "39  1.333437  0.035408  1.467497  0.580702  0.703106 -0.519059  0.310175   \n",
       "40  0.514634  0.304896 -0.866290 -1.273266  0.080080  0.495347  0.720226   \n",
       "41 -0.817331 -0.245489 -0.502178  1.947396 -0.310997  0.509029  1.198297   \n",
       "42  1.110656 -2.792998 -0.579520  0.571606 -0.677073  0.456899  1.058304   \n",
       "43 -1.249598 -0.456199  0.063644  0.290465  1.310384 -1.783478 -1.208766   \n",
       "44  1.807665 -1.380233  1.355370 -0.501201  0.490424 -2.280535  0.077679   \n",
       "45 -0.113043  0.019437 -0.474806  0.517467  0.528099 -1.589552 -1.122806   \n",
       "46  1.563555  0.124859  0.899784 -0.576478 -1.767024 -0.710012 -0.462963   \n",
       "47 -0.876491  0.379460  0.842800 -0.131901 -1.436596 -0.111519  0.202112   \n",
       "48  0.106189  0.250564 -0.755103 -1.996310 -0.052435 -1.739802 -0.104535   \n",
       "49 -0.371989  2.050487 -1.630269 -0.268340 -0.273032 -1.655492  1.444483   \n",
       "\n",
       "        X671      X728      X776  ...     X1717     X1766     X1805     X1871  \\\n",
       "0  -0.349348  0.386363  0.655466  ... -0.986518 -0.838144  0.823788 -2.129890   \n",
       "1  -1.384969 -0.802604 -1.654007  ... -0.966563 -0.993953  0.124873  1.272922   \n",
       "2  -1.788471  0.341925 -0.359369  ...  0.143718  0.673208 -1.068068 -0.163226   \n",
       "3   0.346573 -2.335538  0.137511  ...  0.545146 -1.231386  0.789447  0.707267   \n",
       "4  -1.114805 -0.720515 -1.049472  ... -1.076962  0.016623 -1.020345  0.619546   \n",
       "5  -0.667064  0.815016  1.056478  ...  0.360295 -0.434452  0.527155  1.026248   \n",
       "6  -1.934803  0.419677 -1.620618  ... -0.126896 -0.538900 -0.158716 -0.971775   \n",
       "7   1.173063  1.140964  0.577900  ...  0.101090  0.383593 -1.371423  1.949728   \n",
       "8  -0.036990  0.011283 -1.587063  ... -1.072214  0.027022  0.336844 -0.013892   \n",
       "9  -0.550788 -1.385569  0.484651  ...  1.196830  0.403029 -0.088789  1.821891   \n",
       "10 -2.743786  0.584231 -2.269297  ...  0.743865  0.382781  0.143922 -0.763061   \n",
       "11 -0.488217  0.935167 -0.401473  ... -0.181355  0.880600  0.781259  0.569627   \n",
       "12  1.076358  1.270729 -0.549957  ... -0.854030 -2.232684 -0.114081  0.139858   \n",
       "13 -0.461073  0.133594  0.823369  ...  1.156016  1.739863 -0.985799  0.166943   \n",
       "14  0.753592  1.811158 -1.021224  ...  0.365666  1.459939 -0.683917 -0.624789   \n",
       "15  1.320900 -1.835049  0.852636  ...  0.716854  0.501362  0.541683  1.004691   \n",
       "16 -0.421069  1.017708 -1.058350  ...  1.346286  0.081973 -0.447940 -1.285475   \n",
       "17 -0.732421 -1.105890  0.105844  ...  0.376879 -0.215025 -0.022102 -0.236774   \n",
       "18  0.698656  0.574112 -0.339096  ... -0.046818 -0.011860  1.060225 -0.258866   \n",
       "19 -0.025265 -0.211144  0.964546  ...  0.105873  1.526963  3.026076  0.706599   \n",
       "20 -0.261055 -0.034880 -0.008627  ... -1.780722 -0.373496 -0.783879 -2.982338   \n",
       "21 -0.728920  0.161649 -0.692377  ...  1.788568  0.371680  0.216951 -0.697507   \n",
       "22  0.628781  0.051155 -0.452759  ...  0.877788 -1.166637 -0.878166  1.057760   \n",
       "23 -0.391983  0.119430 -0.266621  ...  0.928726 -0.827317  0.938144 -0.540334   \n",
       "24  0.167232  0.723035  1.033524  ...  0.241846 -1.380123 -0.708717  1.235421   \n",
       "25  1.728085  0.269422  0.203551  ...  0.699630  0.605107  0.263811  0.306097   \n",
       "26 -0.296696  0.244406  2.167375  ...  1.371162 -1.072881 -1.508321 -0.510814   \n",
       "27  0.337662 -0.194697 -0.080779  ... -0.585596  0.795886  0.342858 -1.463495   \n",
       "28  0.024734  0.263595  1.231784  ...  0.239445 -0.627869  1.711837 -0.102761   \n",
       "29  0.501256  1.608680  1.114172  ...  1.986816 -0.971565  0.565095 -0.198416   \n",
       "30  2.146565  0.022905 -1.423223  ... -0.013935  1.790910  1.408362  1.117245   \n",
       "31  0.467825 -0.301439  0.320218  ... -1.722558 -0.819341  1.184111 -2.014289   \n",
       "32  0.065558 -0.982436  0.394963  ... -0.882324 -1.033133  0.930715  0.205747   \n",
       "33 -0.175320  1.128746  1.555091  ...  0.907464 -0.069603 -1.257553 -0.451738   \n",
       "34 -0.078326  1.102683 -0.318526  ...  0.866784  1.353233 -1.230553  0.336590   \n",
       "35  0.421766 -0.302420  0.819240  ...  1.504213  0.304143 -1.489723 -0.321739   \n",
       "36 -0.161988 -0.230398 -1.214473  ... -0.335162 -0.273891 -0.697389  1.513069   \n",
       "37 -0.552266 -1.593218  0.824117  ... -0.508641  0.912698 -0.346858 -0.501963   \n",
       "38  0.426108  1.681192 -1.166154  ... -0.005434  1.629311 -1.176197 -0.591605   \n",
       "39  0.119748 -0.161598 -0.876056  ... -1.042839  0.899216  1.519704  0.014886   \n",
       "40  0.455031 -0.757009 -0.256344  ... -1.342346 -0.651101 -0.616337  0.476464   \n",
       "41  1.539972  0.086388  0.327618  ... -1.621656  1.319393  0.167300  0.697358   \n",
       "42  1.856614 -0.210600  1.532213  ... -1.402324 -1.128573  1.055114  0.805017   \n",
       "43  0.410358  1.619502 -1.044319  ...  0.868667  1.289047  0.020000 -0.614925   \n",
       "44  1.222137  0.143248  1.332544  ... -1.193462 -2.622905 -1.940834 -0.485053   \n",
       "45  1.139549 -2.252890  0.555787  ... -0.063558  0.646992  1.446065 -1.384222   \n",
       "46 -0.428359 -0.847018 -0.812698  ... -2.365054 -0.450793 -0.677795  0.408830   \n",
       "47 -1.200294  0.197218  1.728909  ...  0.507345 -0.444546 -0.023700 -0.064766   \n",
       "48 -2.018652 -2.291933  0.018298  ... -0.291221  0.227128 -0.987092  1.263341   \n",
       "49 -0.035196 -0.308336 -0.294922  ...  0.521217  0.188480  0.358954 -0.049431   \n",
       "\n",
       "       X1877     X1905     X1909     X1918     X1930     X1989  \n",
       "0  -0.361329 -0.487599  0.532695  1.423379  0.141332 -0.602507  \n",
       "1   2.797161  0.591919  1.512906 -0.850299  0.274113 -0.885349  \n",
       "2   0.565365 -0.720831 -0.021718 -1.620022 -0.775336 -0.314378  \n",
       "3   1.010862 -0.606913  1.290897  0.757219  0.738596  0.591696  \n",
       "4   1.870858 -0.754453  0.819591  0.101769 -0.566678  1.785798  \n",
       "5  -0.217184  0.783978  1.206786  1.348671  0.291350 -0.807512  \n",
       "6   1.242384  1.135165  0.543484 -1.157614  0.157062 -0.968501  \n",
       "7   0.327946 -0.507633  0.438548  1.003838 -0.286521 -0.809103  \n",
       "8  -1.106138  0.840831  1.578551 -0.505517 -3.042619  0.553487  \n",
       "9  -0.295737  0.919460 -0.962120 -0.124618  0.189774 -0.356320  \n",
       "10 -1.707292  0.128111  0.475092 -0.920464 -0.838316 -0.679007  \n",
       "11  0.174203  0.840668  0.891634  1.039288  0.704507 -0.051820  \n",
       "12 -0.675113 -1.433497  1.620152  0.794146 -0.971084  0.401746  \n",
       "13 -0.297770  1.400469 -0.720094 -0.714174  1.242348 -0.103041  \n",
       "14  1.067460  0.810842  0.079006  1.739279 -1.102826 -0.286523  \n",
       "15  0.816479  0.516720 -1.859654  1.067264 -2.046410  0.090338  \n",
       "16  0.716438 -1.714357 -0.685598 -0.639155 -0.460880 -0.548257  \n",
       "17 -0.359100  1.705418 -1.300816 -1.035269 -0.944274 -1.321088  \n",
       "18  0.609170 -0.392034  0.660524 -0.885924  0.055031  0.367228  \n",
       "19 -1.046273 -0.265196  0.379312 -0.588686  0.238336 -0.149405  \n",
       "20  1.588417 -0.521467  0.136156 -1.125725  0.924172 -1.594084  \n",
       "21  0.181541 -0.004667 -2.144401  1.314715  0.547558 -0.037767  \n",
       "22 -1.736979 -1.730782  0.482344 -0.469469  0.643803  0.247301  \n",
       "23  0.970482 -0.298262 -1.718431  0.895326  0.810715  0.985495  \n",
       "24  0.323636 -1.421818 -1.872257 -1.010318  0.417168  0.678652  \n",
       "25 -1.658897 -1.710104  0.363345 -0.995995 -0.400018 -0.557544  \n",
       "26  1.456227  0.174108  0.331242  0.323125 -0.609264  0.825213  \n",
       "27 -0.120760  1.338165 -0.777633  0.672435  1.594673  2.039983  \n",
       "28 -0.667358  0.637427  0.709103 -0.385888 -0.579766  0.086509  \n",
       "29 -1.121547  0.990794 -0.903352  0.205765 -0.845368  1.683156  \n",
       "30  0.034506 -0.400991  0.222862  0.501602  0.404224 -0.081870  \n",
       "31 -0.664687  0.701390  0.174419 -1.642118 -1.172437 -0.743402  \n",
       "32  0.132158 -1.466099 -1.143877  0.844709  1.686469 -1.013554  \n",
       "33  0.537745 -0.510845  0.350730 -0.424155 -0.014714  1.303558  \n",
       "34 -0.561704  0.805024 -0.583254 -0.538699  0.634445 -0.892469  \n",
       "35  0.625750  1.461683  0.888196 -0.312387  0.537177 -0.202681  \n",
       "36  0.348401 -2.850355  1.487198 -1.710007  2.348089 -2.495564  \n",
       "37  0.902805 -0.157644 -1.667233  0.275262 -0.221413  1.813337  \n",
       "38 -0.694447  0.730301  0.052774 -2.219312 -1.199850  0.459782  \n",
       "39 -0.488798  0.291851 -0.470426  0.725394  0.074109 -0.188974  \n",
       "40 -0.749842  0.342244  0.102890  0.650991 -0.452231 -0.455583  \n",
       "41 -0.084753  0.072605  0.459061  1.514347  1.542219  0.773944  \n",
       "42  1.320698  0.215481 -0.198156  1.776437 -1.854268  0.380418  \n",
       "43 -0.345523  0.460148  0.005009 -0.750189  0.429070  2.348878  \n",
       "44 -1.976481 -0.844589 -1.017864  1.170823 -0.074751 -0.227163  \n",
       "45  0.743467 -0.712448 -0.913097 -1.109096 -0.784516  1.263594  \n",
       "46 -0.428587  0.453427  1.948004  0.965837  0.709082 -1.514835  \n",
       "47 -1.220138 -1.191618 -1.252607 -0.144561 -0.297459 -1.693445  \n",
       "48 -0.487931  0.744031 -0.224342  0.475669  0.754459  0.394249  \n",
       "49 -1.289793  1.611939  0.694420  0.292373  1.451116  0.507385  \n",
       "\n",
       "[50 rows x 44 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_standardized\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4422378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f8a6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3480eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1baae4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Without Hyperparameter Tuning\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af5e16ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.5992428811395732\n",
      "Root_Mean_squared_error (Test) = 0.774107796847166\n",
      "R2_score (Test) = 0.5355878550460363\n",
      "Mean_squared_error (Train) = 0.007255017400607279\n",
      "Root_Mean_squared_error (Train) = 0.0851763899247161\n",
      "R2_score (Train) = 0.9918706030506397\n"
     ]
    }
   ],
   "source": [
    "# testing data evaluation \n",
    "y_predict_test  = ridge.predict(X_test)\n",
    "\n",
    "Mean_squared_error = mean_squared_error(y_test,y_predict_test)\n",
    "print('Mean_squared_error (Test) =',Mean_squared_error)\n",
    "\n",
    "Root_Mean_squared_error = np.sqrt(Mean_squared_error)\n",
    "print('Root_Mean_squared_error (Test) =',Root_Mean_squared_error)\n",
    "\n",
    "R2_score = r2_score(y_test,y_predict_test)\n",
    "print('R2_score (Test) =',R2_score)\n",
    "\n",
    "\n",
    "# training data evaluation \n",
    "y_predict_train = ridge.predict(X_train)\n",
    "\n",
    "Mean_squared_error = mean_squared_error(y_train,y_predict_train)\n",
    "print('Mean_squared_error (Train) =',Mean_squared_error)\n",
    "\n",
    "Root_Mean_squared_error = np.sqrt(Mean_squared_error)\n",
    "print('Root_Mean_squared_error (Train) =',Root_Mean_squared_error)\n",
    "\n",
    "R2_score = r2_score(y_train,y_predict_train)\n",
    "print('R2_score (Train) =',R2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a10c1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning for Ridge Regression\n",
    "ridge = Ridge()\n",
    "params = {\"alpha\": np.logspace(-3, 3, 50)}  # Searching across a range of alpha values\n",
    "ridge_cv = GridSearchCV(ridge, param_grid=params, cv=5, scoring=\"r2\")\n",
    "ridge_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52daf6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 19.306977288832496\n"
     ]
    }
   ],
   "source": [
    "# Best model from GridSearchCV\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "print(\"Best Alpha:\", ridge_cv.best_params_[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e737e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.4298979346236863\n",
      "Root_Mean_squared_error (Test) = 0.655666023691701\n",
      "R2_score (Test) = 0.6668298811490372\n",
      "Mean_squared_error (Train) = 0.05790645330691358\n",
      "Root_Mean_squared_error (Train) = 0.2406375974508422\n",
      "R2_score (Train) = 0.935114622216882\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "y_predict_test = ridge_best.predict(X_test)\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = ridge_best.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f5924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934bd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7364cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8a9738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianRidge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianRidge</label><div class=\"sk-toggleable__content\"><pre>BayesianRidge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian Ridge Regression\n",
    "bayesian_ridge = BayesianRidge()\n",
    "bayesian_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6430014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.4056945596245111\n",
      "Root_Mean_squared_error (Test) = 0.6369415668838949\n",
      "R2_score (Test) = 0.6855874528320189\n",
      "Mean_squared_error (Train) = 0.04167143930517466\n",
      "Root_Mean_squared_error (Train) = 0.20413583542625402\n",
      "R2_score (Train) = 0.9533062909629157\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "y_predict_test = bayesian_ridge.predict(X_test)\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = bayesian_ridge.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625b968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57e3cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha_1': 1e-12, 'alpha_2': 0.01, 'lambda_1': 0.01, 'lambda_2': 1e-12, 'n_iter': 50}\n",
      "Best Score: 0.28592437859849723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_bayes.py:53: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.3 and will be removed in 1.5\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "bayesian_ridge = BayesianRidge()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'alpha_1': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'alpha_2': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'lambda_1': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'lambda_2': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'n_iter': [50, 100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Define scoring metric\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bayesian_ridge,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters and corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", -grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_predict_test = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "047f5691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.40622787675614364\n",
      "Root_Mean_squared_error (Test) = 0.6373600840624895\n",
      "R2_score (Test) = 0.6851741330232444\n",
      "Mean_squared_error (Train) = 0.04217323726303375\n",
      "Root_Mean_squared_error (Train) = 0.20536123602820897\n",
      "R2_score (Train) = 0.9527440159796092\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = best_model.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb0ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9bf36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abd7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39b4abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial VIF Values:\n",
      "    Feature           VIF\n",
      "0        X1  8.188363e+14\n",
      "1        X2  7.505999e+14\n",
      "2        X5  3.002400e+14\n",
      "3       X23  5.298353e+14\n",
      "4      X123  6.928615e+14\n",
      "..      ...           ...\n",
      "195   X1974  6.433714e+14\n",
      "196   X1977  5.629500e+14\n",
      "197   X1982  9.007199e+14\n",
      "198   X1989  4.740631e+14\n",
      "199   X1997  3.105931e+14\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "Removing feature: X1211 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1704 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1405 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1741 (VIF: 2251799813685248.0)\n",
      "Removing feature: X757 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1005 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1562 (VIF: 2251799813685248.0)\n",
      "Removing feature: X238 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1733 (VIF: 1801439850948198.5)\n",
      "Removing feature: X381 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1350 (VIF: 1801439850948198.5)\n",
      "Removing feature: X430 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1022 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1666 (VIF: 2251799813685248.0)\n",
      "Removing feature: X1611 (VIF: 2251799813685248.0)\n",
      "Removing feature: X290 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1366 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1 (VIF: 1801439850948198.5)\n",
      "Removing feature: X140 (VIF: 1501199875790165.2)\n",
      "Removing feature: X575 (VIF: 1801439850948198.5)\n",
      "Removing feature: X786 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1098 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1233 (VIF: 1501199875790165.2)\n",
      "Removing feature: X812 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1409 (VIF: 1501199875790165.2)\n",
      "Removing feature: X472 (VIF: 1286742750677284.5)\n",
      "Removing feature: X881 (VIF: 1501199875790165.2)\n",
      "Removing feature: X937 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1628 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1496 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1778 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1412 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1133 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1237 (VIF: 1286742750677284.5)\n",
      "Removing feature: X782 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1046 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1250 (VIF: 1125899906842624.0)\n",
      "Removing feature: X968 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1804 (VIF: 1501199875790165.2)\n",
      "Removing feature: X1539 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1382 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1749 (VIF: 1801439850948198.5)\n",
      "Removing feature: X1916 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1927 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1158 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1249 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1824 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1528 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1241 (VIF: 1286742750677284.5)\n",
      "Removing feature: X918 (VIF: 1125899906842624.0)\n",
      "Removing feature: X305 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1801 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1259 (VIF: 900719925474099.2)\n",
      "Removing feature: X1614 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1461 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1307 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1557 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1069 (VIF: 900719925474099.2)\n",
      "Removing feature: X1188 (VIF: 1125899906842624.0)\n",
      "Removing feature: X878 (VIF: 1000799917193443.5)\n",
      "Removing feature: X1092 (VIF: 1286742750677284.5)\n",
      "Removing feature: X1634 (VIF: 900719925474099.2)\n",
      "Removing feature: X1437 (VIF: 900719925474099.2)\n",
      "Removing feature: X1032 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1464 (VIF: 750599937895082.6)\n",
      "Removing feature: X1521 (VIF: 750599937895082.6)\n",
      "Removing feature: X1195 (VIF: 1125899906842624.0)\n",
      "Removing feature: X1882 (VIF: 1000799917193443.5)\n",
      "Removing feature: X714 (VIF: 818836295885544.8)\n",
      "Removing feature: X1470 (VIF: 900719925474099.2)\n",
      "Removing feature: X1833 (VIF: 818836295885544.8)\n",
      "Removing feature: X1446 (VIF: 750599937895082.6)\n",
      "Removing feature: X1042 (VIF: 818836295885544.8)\n",
      "Removing feature: X1609 (VIF: 692861481133922.5)\n",
      "Removing feature: X1745 (VIF: 643371375338642.2)\n",
      "Removing feature: X1436 (VIF: 692861481133922.5)\n",
      "Removing feature: X1255 (VIF: 643371375338642.2)\n",
      "Removing feature: X1318 (VIF: 600479950316066.1)\n",
      "Removing feature: X2 (VIF: 692861481133922.5)\n",
      "Removing feature: X1639 (VIF: 643371375338642.2)\n",
      "Removing feature: X886 (VIF: 692861481133922.5)\n",
      "Removing feature: X1772 (VIF: 500399958596721.75)\n",
      "Removing feature: X1623 (VIF: 643371375338642.2)\n",
      "Removing feature: X1505 (VIF: 643371375338642.2)\n",
      "Removing feature: X1889 (VIF: 500399958596721.75)\n",
      "Removing feature: X1462 (VIF: 562949953421312.0)\n",
      "Removing feature: X273 (VIF: 600479950316066.1)\n",
      "Removing feature: X1800 (VIF: 600479950316066.1)\n",
      "Removing feature: X899 (VIF: 562949953421312.0)\n",
      "Removing feature: X1264 (VIF: 375299968947541.3)\n",
      "Removing feature: X1810 (VIF: 692861481133922.5)\n",
      "Removing feature: X559 (VIF: 562949953421312.0)\n",
      "Removing feature: X1874 (VIF: 562949953421312.0)\n",
      "Removing feature: X1570 (VIF: 500399958596721.75)\n",
      "Removing feature: X1974 (VIF: 529835250278881.9)\n",
      "Removing feature: X926 (VIF: 391617358901782.25)\n",
      "Removing feature: X1434 (VIF: 450359962737049.6)\n",
      "Removing feature: X1460 (VIF: 428914250225761.5)\n",
      "Removing feature: X1200 (VIF: 474063118670578.5)\n",
      "Removing feature: X999 (VIF: 474063118670578.5)\n",
      "Removing feature: X1354 (VIF: 500399958596721.75)\n",
      "Removing feature: X1312 (VIF: 409418147942772.4)\n",
      "Removing feature: X931 (VIF: 375299968947541.3)\n",
      "Removing feature: X830 (VIF: 409418147942772.4)\n",
      "Removing feature: X1377 (VIF: 391617358901782.25)\n",
      "Removing feature: X1864 (VIF: 300239975158033.06)\n",
      "Removing feature: X1731 (VIF: 391617358901782.25)\n",
      "Removing feature: X1228 (VIF: 333599972397814.5)\n",
      "Removing feature: X1135 (VIF: 300239975158033.06)\n",
      "Removing feature: X543 (VIF: 300239975158033.06)\n",
      "Removing feature: X1481 (VIF: 310593077749689.4)\n",
      "Removing feature: X1314 (VIF: 333599972397814.5)\n",
      "Removing feature: X1017 (VIF: 290554814669064.25)\n",
      "Removing feature: X1982 (VIF: 391617358901782.25)\n",
      "Removing feature: X1610 (VIF: 250199979298360.88)\n",
      "Removing feature: X1157 (VIF: 230953827044640.8)\n",
      "Removing feature: X1026 (VIF: 237031559335289.25)\n",
      "Removing feature: X1087 (VIF: 214457125112880.75)\n",
      "Removing feature: X1542 (VIF: 169947155749830.03)\n",
      "Removing feature: X252 (VIF: 176611750092960.62)\n",
      "Removing feature: X1738 (VIF: 152664394148152.4)\n",
      "Removing feature: X233 (VIF: 163767259177108.94)\n",
      "Removing feature: X1698 (VIF: 169947155749830.03)\n",
      "Removing feature: X1963 (VIF: 230953827044640.8)\n",
      "Removing feature: X1407 (VIF: 187649984473770.66)\n",
      "Removing feature: X1103 (VIF: 147659004176081.84)\n",
      "Removing feature: X1904 (VIF: 142971416741920.5)\n",
      "Removing feature: X1012 (VIF: 138572296226784.5)\n",
      "Removing feature: X1727 (VIF: 140737488355328.0)\n",
      "Removing feature: X1494 (VIF: 116976613697934.97)\n",
      "Removing feature: X1591 (VIF: 147659004176081.84)\n",
      "Removing feature: X1490 (VIF: 118515779667644.62)\n",
      "Removing feature: X1977 (VIF: 142971416741920.5)\n",
      "Removing feature: X1198 (VIF: 85782850045152.31)\n",
      "Removing feature: X1533 (VIF: 115476913522320.4)\n",
      "Removing feature: X1920 (VIF: 84179432287298.98)\n",
      "Removing feature: X1820 (VIF: 77648269437422.34)\n",
      "Removing feature: X1730 (VIF: 80421421917330.28)\n",
      "Removing feature: X1671 (VIF: 50888131382717.47)\n",
      "Removing feature: X1536 (VIF: 44152937523240.16)\n",
      "Removing feature: X1551 (VIF: 50602243004162.875)\n",
      "Removing feature: X339 (VIF: 58488306848967.484)\n",
      "Removing feature: X863 (VIF: 39332747837296.91)\n",
      "Removing feature: X1888 (VIF: 28147497671065.6)\n",
      "Removing feature: X1420 (VIF: 38166098537038.1)\n",
      "Removing feature: X23 (VIF: 18843513085232.2)\n",
      "Removing feature: X562 (VIF: 17422048848628.611)\n",
      "Removing feature: X1997 (VIF: 16055613644814.602)\n",
      "Removing feature: X1795 (VIF: 15998577717124.32)\n",
      "Removing feature: X1067 (VIF: 15370647192390.771)\n",
      "Removing feature: X5 (VIF: inf)\n",
      "Removing feature: X1248 (VIF: 1833.5168404782735)\n",
      "Removing feature: X922 (VIF: 111.87842902513107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1304 (VIF: 65.56928980728149)\n",
      "Removing feature: X715 (VIF: 22.852639445231873)\n",
      "Removing feature: X123 (VIF: 18.743405537830913)\n",
      "Final VIF Values:\n",
      "   Feature       VIF\n",
      "0     X142  5.093085\n",
      "1     X272  2.891568\n",
      "2     X360  7.303266\n",
      "3     X453  6.182611\n",
      "4     X561  5.948733\n",
      "5     X564  7.201366\n",
      "6     X597  6.480216\n",
      "7     X671  6.611825\n",
      "8     X728  4.461438\n",
      "9     X776  5.641143\n",
      "10    X785  8.461722\n",
      "11    X827  6.209064\n",
      "12    X873  5.893840\n",
      "13    X875  4.404976\n",
      "14    X889  6.607837\n",
      "15    X905  7.136305\n",
      "16    X982  4.089656\n",
      "17   X1011  9.538619\n",
      "18   X1043  5.382247\n",
      "19   X1044  6.544717\n",
      "20   X1055  6.466959\n",
      "21   X1061  7.333300\n",
      "22   X1124  7.964637\n",
      "23   X1183  8.318664\n",
      "24   X1243  5.433006\n",
      "25   X1244  3.448002\n",
      "26   X1266  6.923495\n",
      "27   X1440  6.662039\n",
      "28   X1455  3.758081\n",
      "29   X1571  3.972570\n",
      "30   X1572  8.091970\n",
      "31   X1600  3.251969\n",
      "32   X1638  4.881819\n",
      "33   X1673  5.522429\n",
      "34   X1717  6.806852\n",
      "35   X1766  5.983199\n",
      "36   X1805  4.195931\n",
      "37   X1871  4.912827\n",
      "38   X1877  5.052058\n",
      "39   X1905  8.844524\n",
      "40   X1909  7.793367\n",
      "41   X1918  3.683120\n",
      "42   X1930  6.610108\n",
      "43   X1989  3.438292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "x = pd.read_csv(r\"C:\\Users\\Sandesh\\Desktop\\New folder\\Dataset_corr.csv\")  \n",
    "\n",
    "# Replace 'Phenotype' with the name of the target column if necessary\n",
    "X = data.drop(columns=[\"Phenotype\"])  # Independent variables\n",
    "y = pd.read_csv(r\"C:\\Users\\Sandesh\\Desktop\\New folder\\phenotype.csv\")\n",
    "X_standardized = X\n",
    "\n",
    "# Convert back to DataFrame for easier manipulation\n",
    "X_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "\n",
    "# Step 3: Define a function to calculate VIF\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Step 4: Calculate initial VIF\n",
    "vif_df = calculate_vif(X_standardized)\n",
    "print(\"Initial VIF Values:\")\n",
    "print(vif_df)\n",
    "\n",
    "# Step 5: Remove features with high VIF iteratively\n",
    "threshold = 10\n",
    "while vif_df[\"VIF\"].max() > threshold:\n",
    "    feature_to_remove = vif_df.loc[vif_df[\"VIF\"].idxmax(), \"Feature\"]\n",
    "    print(f\"Removing feature: {feature_to_remove} (VIF: {vif_df['VIF'].max()})\")\n",
    "    X_standardized = X_standardized.drop(columns=[feature_to_remove])\n",
    "    vif_df = calculate_vif(X_standardized)\n",
    "\n",
    "print(\"Final VIF Values:\")\n",
    "print(vif_df)\n",
    "\n",
    "# X_standardized now contains features with acceptable multicollinearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a923018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X142</th>\n",
       "      <th>X272</th>\n",
       "      <th>X360</th>\n",
       "      <th>X453</th>\n",
       "      <th>X561</th>\n",
       "      <th>X564</th>\n",
       "      <th>X597</th>\n",
       "      <th>X671</th>\n",
       "      <th>X728</th>\n",
       "      <th>X776</th>\n",
       "      <th>...</th>\n",
       "      <th>X1717</th>\n",
       "      <th>X1766</th>\n",
       "      <th>X1805</th>\n",
       "      <th>X1871</th>\n",
       "      <th>X1877</th>\n",
       "      <th>X1905</th>\n",
       "      <th>X1909</th>\n",
       "      <th>X1918</th>\n",
       "      <th>X1930</th>\n",
       "      <th>X1989</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.249409</td>\n",
       "      <td>1.568163</td>\n",
       "      <td>1.125810</td>\n",
       "      <td>0.711784</td>\n",
       "      <td>1.271865</td>\n",
       "      <td>0.840418</td>\n",
       "      <td>-0.263967</td>\n",
       "      <td>-0.349348</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>0.655466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986518</td>\n",
       "      <td>-0.838144</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>-2.129890</td>\n",
       "      <td>-0.361329</td>\n",
       "      <td>-0.487599</td>\n",
       "      <td>0.532695</td>\n",
       "      <td>1.423379</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>-0.602507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.870702</td>\n",
       "      <td>0.158488</td>\n",
       "      <td>-0.936967</td>\n",
       "      <td>-1.603290</td>\n",
       "      <td>-1.071022</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>-1.384969</td>\n",
       "      <td>-0.802604</td>\n",
       "      <td>-1.654007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966563</td>\n",
       "      <td>-0.993953</td>\n",
       "      <td>0.124873</td>\n",
       "      <td>1.272922</td>\n",
       "      <td>2.797161</td>\n",
       "      <td>0.591919</td>\n",
       "      <td>1.512906</td>\n",
       "      <td>-0.850299</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>-0.885349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417953</td>\n",
       "      <td>-0.552798</td>\n",
       "      <td>0.646078</td>\n",
       "      <td>-1.250691</td>\n",
       "      <td>-0.288352</td>\n",
       "      <td>0.709452</td>\n",
       "      <td>-0.624321</td>\n",
       "      <td>-1.788471</td>\n",
       "      <td>0.341925</td>\n",
       "      <td>-0.359369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143718</td>\n",
       "      <td>0.673208</td>\n",
       "      <td>-1.068068</td>\n",
       "      <td>-0.163226</td>\n",
       "      <td>0.565365</td>\n",
       "      <td>-0.720831</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-1.620022</td>\n",
       "      <td>-0.775336</td>\n",
       "      <td>-0.314378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016771</td>\n",
       "      <td>-2.048618</td>\n",
       "      <td>-0.216376</td>\n",
       "      <td>1.151214</td>\n",
       "      <td>-2.132672</td>\n",
       "      <td>2.013973</td>\n",
       "      <td>-0.423597</td>\n",
       "      <td>0.346573</td>\n",
       "      <td>-2.335538</td>\n",
       "      <td>0.137511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545146</td>\n",
       "      <td>-1.231386</td>\n",
       "      <td>0.789447</td>\n",
       "      <td>0.707267</td>\n",
       "      <td>1.010862</td>\n",
       "      <td>-0.606913</td>\n",
       "      <td>1.290897</td>\n",
       "      <td>0.757219</td>\n",
       "      <td>0.738596</td>\n",
       "      <td>0.591696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.843358</td>\n",
       "      <td>-0.352327</td>\n",
       "      <td>0.179798</td>\n",
       "      <td>-0.868005</td>\n",
       "      <td>2.155207</td>\n",
       "      <td>0.443271</td>\n",
       "      <td>-1.555152</td>\n",
       "      <td>-1.114805</td>\n",
       "      <td>-0.720515</td>\n",
       "      <td>-1.049472</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.076962</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>-1.020345</td>\n",
       "      <td>0.619546</td>\n",
       "      <td>1.870858</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.819591</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>-0.566678</td>\n",
       "      <td>1.785798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.264955</td>\n",
       "      <td>0.682733</td>\n",
       "      <td>-0.302484</td>\n",
       "      <td>-0.971136</td>\n",
       "      <td>-0.824829</td>\n",
       "      <td>0.987670</td>\n",
       "      <td>0.996937</td>\n",
       "      <td>-0.667064</td>\n",
       "      <td>0.815016</td>\n",
       "      <td>1.056478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360295</td>\n",
       "      <td>-0.434452</td>\n",
       "      <td>0.527155</td>\n",
       "      <td>1.026248</td>\n",
       "      <td>-0.217184</td>\n",
       "      <td>0.783978</td>\n",
       "      <td>1.206786</td>\n",
       "      <td>1.348671</td>\n",
       "      <td>0.291350</td>\n",
       "      <td>-0.807512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.870010</td>\n",
       "      <td>0.714208</td>\n",
       "      <td>-0.674424</td>\n",
       "      <td>0.872967</td>\n",
       "      <td>0.720581</td>\n",
       "      <td>0.481076</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>-1.934803</td>\n",
       "      <td>0.419677</td>\n",
       "      <td>-1.620618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126896</td>\n",
       "      <td>-0.538900</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.971775</td>\n",
       "      <td>1.242384</td>\n",
       "      <td>1.135165</td>\n",
       "      <td>0.543484</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>0.157062</td>\n",
       "      <td>-0.968501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.484004</td>\n",
       "      <td>-0.570079</td>\n",
       "      <td>0.156395</td>\n",
       "      <td>1.026807</td>\n",
       "      <td>-2.314570</td>\n",
       "      <td>0.915716</td>\n",
       "      <td>1.157932</td>\n",
       "      <td>1.173063</td>\n",
       "      <td>1.140964</td>\n",
       "      <td>0.577900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>0.383593</td>\n",
       "      <td>-1.371423</td>\n",
       "      <td>1.949728</td>\n",
       "      <td>0.327946</td>\n",
       "      <td>-0.507633</td>\n",
       "      <td>0.438548</td>\n",
       "      <td>1.003838</td>\n",
       "      <td>-0.286521</td>\n",
       "      <td>-0.809103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.505378</td>\n",
       "      <td>1.519541</td>\n",
       "      <td>-0.893808</td>\n",
       "      <td>-0.044584</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.533965</td>\n",
       "      <td>0.462832</td>\n",
       "      <td>-0.036990</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>-1.587063</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.072214</td>\n",
       "      <td>0.027022</td>\n",
       "      <td>0.336844</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-1.106138</td>\n",
       "      <td>0.840831</td>\n",
       "      <td>1.578551</td>\n",
       "      <td>-0.505517</td>\n",
       "      <td>-3.042619</td>\n",
       "      <td>0.553487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.612856</td>\n",
       "      <td>0.515833</td>\n",
       "      <td>-0.651477</td>\n",
       "      <td>0.905342</td>\n",
       "      <td>-0.617212</td>\n",
       "      <td>1.019360</td>\n",
       "      <td>1.396665</td>\n",
       "      <td>-0.550788</td>\n",
       "      <td>-1.385569</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.196830</td>\n",
       "      <td>0.403029</td>\n",
       "      <td>-0.088789</td>\n",
       "      <td>1.821891</td>\n",
       "      <td>-0.295737</td>\n",
       "      <td>0.919460</td>\n",
       "      <td>-0.962120</td>\n",
       "      <td>-0.124618</td>\n",
       "      <td>0.189774</td>\n",
       "      <td>-0.356320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.334818</td>\n",
       "      <td>0.035217</td>\n",
       "      <td>0.150259</td>\n",
       "      <td>0.939482</td>\n",
       "      <td>-1.209807</td>\n",
       "      <td>-0.783941</td>\n",
       "      <td>0.590884</td>\n",
       "      <td>-2.743786</td>\n",
       "      <td>0.584231</td>\n",
       "      <td>-2.269297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743865</td>\n",
       "      <td>0.382781</td>\n",
       "      <td>0.143922</td>\n",
       "      <td>-0.763061</td>\n",
       "      <td>-1.707292</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.475092</td>\n",
       "      <td>-0.920464</td>\n",
       "      <td>-0.838316</td>\n",
       "      <td>-0.679007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.033005</td>\n",
       "      <td>-0.182215</td>\n",
       "      <td>0.167737</td>\n",
       "      <td>0.320292</td>\n",
       "      <td>-0.241685</td>\n",
       "      <td>-0.428893</td>\n",
       "      <td>1.040453</td>\n",
       "      <td>-0.488217</td>\n",
       "      <td>0.935167</td>\n",
       "      <td>-0.401473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181355</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.781259</td>\n",
       "      <td>0.569627</td>\n",
       "      <td>0.174203</td>\n",
       "      <td>0.840668</td>\n",
       "      <td>0.891634</td>\n",
       "      <td>1.039288</td>\n",
       "      <td>0.704507</td>\n",
       "      <td>-0.051820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.195364</td>\n",
       "      <td>-0.522029</td>\n",
       "      <td>-1.354569</td>\n",
       "      <td>0.169509</td>\n",
       "      <td>0.316084</td>\n",
       "      <td>-0.407314</td>\n",
       "      <td>1.346015</td>\n",
       "      <td>1.076358</td>\n",
       "      <td>1.270729</td>\n",
       "      <td>-0.549957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.854030</td>\n",
       "      <td>-2.232684</td>\n",
       "      <td>-0.114081</td>\n",
       "      <td>0.139858</td>\n",
       "      <td>-0.675113</td>\n",
       "      <td>-1.433497</td>\n",
       "      <td>1.620152</td>\n",
       "      <td>0.794146</td>\n",
       "      <td>-0.971084</td>\n",
       "      <td>0.401746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.250896</td>\n",
       "      <td>-0.375973</td>\n",
       "      <td>-1.223737</td>\n",
       "      <td>0.409868</td>\n",
       "      <td>-0.799912</td>\n",
       "      <td>-0.293606</td>\n",
       "      <td>-1.203276</td>\n",
       "      <td>-0.461073</td>\n",
       "      <td>0.133594</td>\n",
       "      <td>0.823369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156016</td>\n",
       "      <td>1.739863</td>\n",
       "      <td>-0.985799</td>\n",
       "      <td>0.166943</td>\n",
       "      <td>-0.297770</td>\n",
       "      <td>1.400469</td>\n",
       "      <td>-0.720094</td>\n",
       "      <td>-0.714174</td>\n",
       "      <td>1.242348</td>\n",
       "      <td>-0.103041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.613084</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>-1.359745</td>\n",
       "      <td>1.429431</td>\n",
       "      <td>1.347217</td>\n",
       "      <td>-0.537766</td>\n",
       "      <td>-0.196051</td>\n",
       "      <td>0.753592</td>\n",
       "      <td>1.811158</td>\n",
       "      <td>-1.021224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365666</td>\n",
       "      <td>1.459939</td>\n",
       "      <td>-0.683917</td>\n",
       "      <td>-0.624789</td>\n",
       "      <td>1.067460</td>\n",
       "      <td>0.810842</td>\n",
       "      <td>0.079006</td>\n",
       "      <td>1.739279</td>\n",
       "      <td>-1.102826</td>\n",
       "      <td>-0.286523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.517141</td>\n",
       "      <td>-0.045924</td>\n",
       "      <td>1.114496</td>\n",
       "      <td>0.237294</td>\n",
       "      <td>0.968009</td>\n",
       "      <td>-0.728454</td>\n",
       "      <td>1.443304</td>\n",
       "      <td>1.320900</td>\n",
       "      <td>-1.835049</td>\n",
       "      <td>0.852636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716854</td>\n",
       "      <td>0.501362</td>\n",
       "      <td>0.541683</td>\n",
       "      <td>1.004691</td>\n",
       "      <td>0.816479</td>\n",
       "      <td>0.516720</td>\n",
       "      <td>-1.859654</td>\n",
       "      <td>1.067264</td>\n",
       "      <td>-2.046410</td>\n",
       "      <td>0.090338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002356</td>\n",
       "      <td>1.424646</td>\n",
       "      <td>-1.353052</td>\n",
       "      <td>1.544073</td>\n",
       "      <td>-0.061376</td>\n",
       "      <td>-0.794775</td>\n",
       "      <td>0.532008</td>\n",
       "      <td>-0.421069</td>\n",
       "      <td>1.017708</td>\n",
       "      <td>-1.058350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346286</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>-0.447940</td>\n",
       "      <td>-1.285475</td>\n",
       "      <td>0.716438</td>\n",
       "      <td>-1.714357</td>\n",
       "      <td>-0.685598</td>\n",
       "      <td>-0.639155</td>\n",
       "      <td>-0.460880</td>\n",
       "      <td>-0.548257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.809946</td>\n",
       "      <td>-0.024967</td>\n",
       "      <td>0.648362</td>\n",
       "      <td>-1.158626</td>\n",
       "      <td>0.981462</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.918691</td>\n",
       "      <td>-0.732421</td>\n",
       "      <td>-1.105890</td>\n",
       "      <td>0.105844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376879</td>\n",
       "      <td>-0.215025</td>\n",
       "      <td>-0.022102</td>\n",
       "      <td>-0.236774</td>\n",
       "      <td>-0.359100</td>\n",
       "      <td>1.705418</td>\n",
       "      <td>-1.300816</td>\n",
       "      <td>-1.035269</td>\n",
       "      <td>-0.944274</td>\n",
       "      <td>-1.321088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.267925</td>\n",
       "      <td>-0.676707</td>\n",
       "      <td>0.215589</td>\n",
       "      <td>-1.305136</td>\n",
       "      <td>0.528556</td>\n",
       "      <td>-1.076244</td>\n",
       "      <td>-0.992120</td>\n",
       "      <td>0.698656</td>\n",
       "      <td>0.574112</td>\n",
       "      <td>-0.339096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046818</td>\n",
       "      <td>-0.011860</td>\n",
       "      <td>1.060225</td>\n",
       "      <td>-0.258866</td>\n",
       "      <td>0.609170</td>\n",
       "      <td>-0.392034</td>\n",
       "      <td>0.660524</td>\n",
       "      <td>-0.885924</td>\n",
       "      <td>0.055031</td>\n",
       "      <td>0.367228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.823746</td>\n",
       "      <td>-1.777197</td>\n",
       "      <td>1.490487</td>\n",
       "      <td>1.884350</td>\n",
       "      <td>-1.089531</td>\n",
       "      <td>0.607409</td>\n",
       "      <td>-0.105193</td>\n",
       "      <td>-0.025265</td>\n",
       "      <td>-0.211144</td>\n",
       "      <td>0.964546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105873</td>\n",
       "      <td>1.526963</td>\n",
       "      <td>3.026076</td>\n",
       "      <td>0.706599</td>\n",
       "      <td>-1.046273</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>0.379312</td>\n",
       "      <td>-0.588686</td>\n",
       "      <td>0.238336</td>\n",
       "      <td>-0.149405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.248959</td>\n",
       "      <td>1.100489</td>\n",
       "      <td>-0.111560</td>\n",
       "      <td>-0.602319</td>\n",
       "      <td>0.862675</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>0.285858</td>\n",
       "      <td>-0.261055</td>\n",
       "      <td>-0.034880</td>\n",
       "      <td>-0.008627</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.780722</td>\n",
       "      <td>-0.373496</td>\n",
       "      <td>-0.783879</td>\n",
       "      <td>-2.982338</td>\n",
       "      <td>1.588417</td>\n",
       "      <td>-0.521467</td>\n",
       "      <td>0.136156</td>\n",
       "      <td>-1.125725</td>\n",
       "      <td>0.924172</td>\n",
       "      <td>-1.594084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.690636</td>\n",
       "      <td>-0.267930</td>\n",
       "      <td>-1.378445</td>\n",
       "      <td>-0.367718</td>\n",
       "      <td>1.810063</td>\n",
       "      <td>-1.045596</td>\n",
       "      <td>-0.216239</td>\n",
       "      <td>-0.728920</td>\n",
       "      <td>0.161649</td>\n",
       "      <td>-0.692377</td>\n",
       "      <td>...</td>\n",
       "      <td>1.788568</td>\n",
       "      <td>0.371680</td>\n",
       "      <td>0.216951</td>\n",
       "      <td>-0.697507</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>-2.144401</td>\n",
       "      <td>1.314715</td>\n",
       "      <td>0.547558</td>\n",
       "      <td>-0.037767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.017720</td>\n",
       "      <td>-1.302508</td>\n",
       "      <td>0.469278</td>\n",
       "      <td>0.080457</td>\n",
       "      <td>-0.339516</td>\n",
       "      <td>2.702655</td>\n",
       "      <td>-0.847837</td>\n",
       "      <td>0.628781</td>\n",
       "      <td>0.051155</td>\n",
       "      <td>-0.452759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877788</td>\n",
       "      <td>-1.166637</td>\n",
       "      <td>-0.878166</td>\n",
       "      <td>1.057760</td>\n",
       "      <td>-1.736979</td>\n",
       "      <td>-1.730782</td>\n",
       "      <td>0.482344</td>\n",
       "      <td>-0.469469</td>\n",
       "      <td>0.643803</td>\n",
       "      <td>0.247301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.432093</td>\n",
       "      <td>-0.815070</td>\n",
       "      <td>1.654094</td>\n",
       "      <td>-0.079096</td>\n",
       "      <td>0.136901</td>\n",
       "      <td>-1.194686</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>-0.391983</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>-0.266621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>-0.827317</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>-0.540334</td>\n",
       "      <td>0.970482</td>\n",
       "      <td>-0.298262</td>\n",
       "      <td>-1.718431</td>\n",
       "      <td>0.895326</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.985495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.326345</td>\n",
       "      <td>2.360498</td>\n",
       "      <td>-0.028926</td>\n",
       "      <td>0.037641</td>\n",
       "      <td>-0.844809</td>\n",
       "      <td>1.200124</td>\n",
       "      <td>-0.719920</td>\n",
       "      <td>0.167232</td>\n",
       "      <td>0.723035</td>\n",
       "      <td>1.033524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241846</td>\n",
       "      <td>-1.380123</td>\n",
       "      <td>-0.708717</td>\n",
       "      <td>1.235421</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>-1.421818</td>\n",
       "      <td>-1.872257</td>\n",
       "      <td>-1.010318</td>\n",
       "      <td>0.417168</td>\n",
       "      <td>0.678652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.054602</td>\n",
       "      <td>-1.191695</td>\n",
       "      <td>0.422371</td>\n",
       "      <td>1.726401</td>\n",
       "      <td>-0.387097</td>\n",
       "      <td>0.817849</td>\n",
       "      <td>-0.142979</td>\n",
       "      <td>1.728085</td>\n",
       "      <td>0.269422</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699630</td>\n",
       "      <td>0.605107</td>\n",
       "      <td>0.263811</td>\n",
       "      <td>0.306097</td>\n",
       "      <td>-1.658897</td>\n",
       "      <td>-1.710104</td>\n",
       "      <td>0.363345</td>\n",
       "      <td>-0.995995</td>\n",
       "      <td>-0.400018</td>\n",
       "      <td>-0.557544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.272058</td>\n",
       "      <td>-0.621369</td>\n",
       "      <td>-0.639422</td>\n",
       "      <td>0.318882</td>\n",
       "      <td>-1.168663</td>\n",
       "      <td>-2.121348</td>\n",
       "      <td>-0.296696</td>\n",
       "      <td>0.244406</td>\n",
       "      <td>2.167375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371162</td>\n",
       "      <td>-1.072881</td>\n",
       "      <td>-1.508321</td>\n",
       "      <td>-0.510814</td>\n",
       "      <td>1.456227</td>\n",
       "      <td>0.174108</td>\n",
       "      <td>0.331242</td>\n",
       "      <td>0.323125</td>\n",
       "      <td>-0.609264</td>\n",
       "      <td>0.825213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.497782</td>\n",
       "      <td>-1.708829</td>\n",
       "      <td>-1.655251</td>\n",
       "      <td>-0.880199</td>\n",
       "      <td>-0.584995</td>\n",
       "      <td>0.508702</td>\n",
       "      <td>1.743673</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>-0.194697</td>\n",
       "      <td>-0.080779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585596</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>0.342858</td>\n",
       "      <td>-1.463495</td>\n",
       "      <td>-0.120760</td>\n",
       "      <td>1.338165</td>\n",
       "      <td>-0.777633</td>\n",
       "      <td>0.672435</td>\n",
       "      <td>1.594673</td>\n",
       "      <td>2.039983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.110488</td>\n",
       "      <td>-0.222707</td>\n",
       "      <td>-2.060066</td>\n",
       "      <td>-0.806188</td>\n",
       "      <td>1.257826</td>\n",
       "      <td>-0.357296</td>\n",
       "      <td>0.867260</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.263595</td>\n",
       "      <td>1.231784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239445</td>\n",
       "      <td>-0.627869</td>\n",
       "      <td>1.711837</td>\n",
       "      <td>-0.102761</td>\n",
       "      <td>-0.667358</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.709103</td>\n",
       "      <td>-0.385888</td>\n",
       "      <td>-0.579766</td>\n",
       "      <td>0.086509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.158744</td>\n",
       "      <td>0.298536</td>\n",
       "      <td>0.844679</td>\n",
       "      <td>0.889688</td>\n",
       "      <td>-0.702531</td>\n",
       "      <td>-0.628059</td>\n",
       "      <td>-1.634990</td>\n",
       "      <td>0.501256</td>\n",
       "      <td>1.608680</td>\n",
       "      <td>1.114172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.986816</td>\n",
       "      <td>-0.971565</td>\n",
       "      <td>0.565095</td>\n",
       "      <td>-0.198416</td>\n",
       "      <td>-1.121547</td>\n",
       "      <td>0.990794</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.205765</td>\n",
       "      <td>-0.845368</td>\n",
       "      <td>1.683156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.127842</td>\n",
       "      <td>-0.223727</td>\n",
       "      <td>1.292963</td>\n",
       "      <td>1.666215</td>\n",
       "      <td>-1.122716</td>\n",
       "      <td>0.804472</td>\n",
       "      <td>-1.498092</td>\n",
       "      <td>2.146565</td>\n",
       "      <td>0.022905</td>\n",
       "      <td>-1.423223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013935</td>\n",
       "      <td>1.790910</td>\n",
       "      <td>1.408362</td>\n",
       "      <td>1.117245</td>\n",
       "      <td>0.034506</td>\n",
       "      <td>-0.400991</td>\n",
       "      <td>0.222862</td>\n",
       "      <td>0.501602</td>\n",
       "      <td>0.404224</td>\n",
       "      <td>-0.081870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1.259069</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>-0.477530</td>\n",
       "      <td>0.202344</td>\n",
       "      <td>1.570171</td>\n",
       "      <td>-0.189702</td>\n",
       "      <td>-0.919962</td>\n",
       "      <td>0.467825</td>\n",
       "      <td>-0.301439</td>\n",
       "      <td>0.320218</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.722558</td>\n",
       "      <td>-0.819341</td>\n",
       "      <td>1.184111</td>\n",
       "      <td>-2.014289</td>\n",
       "      <td>-0.664687</td>\n",
       "      <td>0.701390</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>-1.642118</td>\n",
       "      <td>-1.172437</td>\n",
       "      <td>-0.743402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-1.898590</td>\n",
       "      <td>-0.217424</td>\n",
       "      <td>-0.225589</td>\n",
       "      <td>-1.363810</td>\n",
       "      <td>-0.064851</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>-0.583451</td>\n",
       "      <td>0.065558</td>\n",
       "      <td>-0.982436</td>\n",
       "      <td>0.394963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.882324</td>\n",
       "      <td>-1.033133</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.205747</td>\n",
       "      <td>0.132158</td>\n",
       "      <td>-1.466099</td>\n",
       "      <td>-1.143877</td>\n",
       "      <td>0.844709</td>\n",
       "      <td>1.686469</td>\n",
       "      <td>-1.013554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.985112</td>\n",
       "      <td>0.852511</td>\n",
       "      <td>-0.352459</td>\n",
       "      <td>-1.043612</td>\n",
       "      <td>0.195197</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>1.592509</td>\n",
       "      <td>-0.175320</td>\n",
       "      <td>1.128746</td>\n",
       "      <td>1.555091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907464</td>\n",
       "      <td>-0.069603</td>\n",
       "      <td>-1.257553</td>\n",
       "      <td>-0.451738</td>\n",
       "      <td>0.537745</td>\n",
       "      <td>-0.510845</td>\n",
       "      <td>0.350730</td>\n",
       "      <td>-0.424155</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>1.303558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.395270</td>\n",
       "      <td>-0.070299</td>\n",
       "      <td>0.467713</td>\n",
       "      <td>0.301241</td>\n",
       "      <td>1.096270</td>\n",
       "      <td>-0.336152</td>\n",
       "      <td>0.410360</td>\n",
       "      <td>-0.078326</td>\n",
       "      <td>1.102683</td>\n",
       "      <td>-0.318526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866784</td>\n",
       "      <td>1.353233</td>\n",
       "      <td>-1.230553</td>\n",
       "      <td>0.336590</td>\n",
       "      <td>-0.561704</td>\n",
       "      <td>0.805024</td>\n",
       "      <td>-0.583254</td>\n",
       "      <td>-0.538699</td>\n",
       "      <td>0.634445</td>\n",
       "      <td>-0.892469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1.023366</td>\n",
       "      <td>1.496629</td>\n",
       "      <td>1.951467</td>\n",
       "      <td>-0.425810</td>\n",
       "      <td>0.524413</td>\n",
       "      <td>0.615106</td>\n",
       "      <td>-1.665859</td>\n",
       "      <td>0.421766</td>\n",
       "      <td>-0.302420</td>\n",
       "      <td>0.819240</td>\n",
       "      <td>...</td>\n",
       "      <td>1.504213</td>\n",
       "      <td>0.304143</td>\n",
       "      <td>-1.489723</td>\n",
       "      <td>-0.321739</td>\n",
       "      <td>0.625750</td>\n",
       "      <td>1.461683</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>-0.312387</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>-0.202681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1.270295</td>\n",
       "      <td>0.687305</td>\n",
       "      <td>1.579835</td>\n",
       "      <td>-1.230045</td>\n",
       "      <td>-0.638149</td>\n",
       "      <td>0.872061</td>\n",
       "      <td>-0.008952</td>\n",
       "      <td>-0.161988</td>\n",
       "      <td>-0.230398</td>\n",
       "      <td>-1.214473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335162</td>\n",
       "      <td>-0.273891</td>\n",
       "      <td>-0.697389</td>\n",
       "      <td>1.513069</td>\n",
       "      <td>0.348401</td>\n",
       "      <td>-2.850355</td>\n",
       "      <td>1.487198</td>\n",
       "      <td>-1.710007</td>\n",
       "      <td>2.348089</td>\n",
       "      <td>-2.495564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.087223</td>\n",
       "      <td>-0.090587</td>\n",
       "      <td>1.588481</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>-0.567855</td>\n",
       "      <td>0.663795</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>-0.552266</td>\n",
       "      <td>-1.593218</td>\n",
       "      <td>0.824117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508641</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>-0.346858</td>\n",
       "      <td>-0.501963</td>\n",
       "      <td>0.902805</td>\n",
       "      <td>-0.157644</td>\n",
       "      <td>-1.667233</td>\n",
       "      <td>0.275262</td>\n",
       "      <td>-0.221413</td>\n",
       "      <td>1.813337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.398359</td>\n",
       "      <td>1.024212</td>\n",
       "      <td>-0.108988</td>\n",
       "      <td>-1.550813</td>\n",
       "      <td>1.226812</td>\n",
       "      <td>-0.412912</td>\n",
       "      <td>-1.915350</td>\n",
       "      <td>0.426108</td>\n",
       "      <td>1.681192</td>\n",
       "      <td>-1.166154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005434</td>\n",
       "      <td>1.629311</td>\n",
       "      <td>-1.176197</td>\n",
       "      <td>-0.591605</td>\n",
       "      <td>-0.694447</td>\n",
       "      <td>0.730301</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>-2.219312</td>\n",
       "      <td>-1.199850</td>\n",
       "      <td>0.459782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.333437</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>1.467497</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.703106</td>\n",
       "      <td>-0.519059</td>\n",
       "      <td>0.310175</td>\n",
       "      <td>0.119748</td>\n",
       "      <td>-0.161598</td>\n",
       "      <td>-0.876056</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.042839</td>\n",
       "      <td>0.899216</td>\n",
       "      <td>1.519704</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>-0.488798</td>\n",
       "      <td>0.291851</td>\n",
       "      <td>-0.470426</td>\n",
       "      <td>0.725394</td>\n",
       "      <td>0.074109</td>\n",
       "      <td>-0.188974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.514634</td>\n",
       "      <td>0.304896</td>\n",
       "      <td>-0.866290</td>\n",
       "      <td>-1.273266</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.495347</td>\n",
       "      <td>0.720226</td>\n",
       "      <td>0.455031</td>\n",
       "      <td>-0.757009</td>\n",
       "      <td>-0.256344</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.342346</td>\n",
       "      <td>-0.651101</td>\n",
       "      <td>-0.616337</td>\n",
       "      <td>0.476464</td>\n",
       "      <td>-0.749842</td>\n",
       "      <td>0.342244</td>\n",
       "      <td>0.102890</td>\n",
       "      <td>0.650991</td>\n",
       "      <td>-0.452231</td>\n",
       "      <td>-0.455583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.817331</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.502178</td>\n",
       "      <td>1.947396</td>\n",
       "      <td>-0.310997</td>\n",
       "      <td>0.509029</td>\n",
       "      <td>1.198297</td>\n",
       "      <td>1.539972</td>\n",
       "      <td>0.086388</td>\n",
       "      <td>0.327618</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621656</td>\n",
       "      <td>1.319393</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.697358</td>\n",
       "      <td>-0.084753</td>\n",
       "      <td>0.072605</td>\n",
       "      <td>0.459061</td>\n",
       "      <td>1.514347</td>\n",
       "      <td>1.542219</td>\n",
       "      <td>0.773944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.110656</td>\n",
       "      <td>-2.792998</td>\n",
       "      <td>-0.579520</td>\n",
       "      <td>0.571606</td>\n",
       "      <td>-0.677073</td>\n",
       "      <td>0.456899</td>\n",
       "      <td>1.058304</td>\n",
       "      <td>1.856614</td>\n",
       "      <td>-0.210600</td>\n",
       "      <td>1.532213</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.402324</td>\n",
       "      <td>-1.128573</td>\n",
       "      <td>1.055114</td>\n",
       "      <td>0.805017</td>\n",
       "      <td>1.320698</td>\n",
       "      <td>0.215481</td>\n",
       "      <td>-0.198156</td>\n",
       "      <td>1.776437</td>\n",
       "      <td>-1.854268</td>\n",
       "      <td>0.380418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-1.249598</td>\n",
       "      <td>-0.456199</td>\n",
       "      <td>0.063644</td>\n",
       "      <td>0.290465</td>\n",
       "      <td>1.310384</td>\n",
       "      <td>-1.783478</td>\n",
       "      <td>-1.208766</td>\n",
       "      <td>0.410358</td>\n",
       "      <td>1.619502</td>\n",
       "      <td>-1.044319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>1.289047</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.614925</td>\n",
       "      <td>-0.345523</td>\n",
       "      <td>0.460148</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.750189</td>\n",
       "      <td>0.429070</td>\n",
       "      <td>2.348878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.807665</td>\n",
       "      <td>-1.380233</td>\n",
       "      <td>1.355370</td>\n",
       "      <td>-0.501201</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>-2.280535</td>\n",
       "      <td>0.077679</td>\n",
       "      <td>1.222137</td>\n",
       "      <td>0.143248</td>\n",
       "      <td>1.332544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193462</td>\n",
       "      <td>-2.622905</td>\n",
       "      <td>-1.940834</td>\n",
       "      <td>-0.485053</td>\n",
       "      <td>-1.976481</td>\n",
       "      <td>-0.844589</td>\n",
       "      <td>-1.017864</td>\n",
       "      <td>1.170823</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.227163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.113043</td>\n",
       "      <td>0.019437</td>\n",
       "      <td>-0.474806</td>\n",
       "      <td>0.517467</td>\n",
       "      <td>0.528099</td>\n",
       "      <td>-1.589552</td>\n",
       "      <td>-1.122806</td>\n",
       "      <td>1.139549</td>\n",
       "      <td>-2.252890</td>\n",
       "      <td>0.555787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063558</td>\n",
       "      <td>0.646992</td>\n",
       "      <td>1.446065</td>\n",
       "      <td>-1.384222</td>\n",
       "      <td>0.743467</td>\n",
       "      <td>-0.712448</td>\n",
       "      <td>-0.913097</td>\n",
       "      <td>-1.109096</td>\n",
       "      <td>-0.784516</td>\n",
       "      <td>1.263594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.563555</td>\n",
       "      <td>0.124859</td>\n",
       "      <td>0.899784</td>\n",
       "      <td>-0.576478</td>\n",
       "      <td>-1.767024</td>\n",
       "      <td>-0.710012</td>\n",
       "      <td>-0.462963</td>\n",
       "      <td>-0.428359</td>\n",
       "      <td>-0.847018</td>\n",
       "      <td>-0.812698</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.365054</td>\n",
       "      <td>-0.450793</td>\n",
       "      <td>-0.677795</td>\n",
       "      <td>0.408830</td>\n",
       "      <td>-0.428587</td>\n",
       "      <td>0.453427</td>\n",
       "      <td>1.948004</td>\n",
       "      <td>0.965837</td>\n",
       "      <td>0.709082</td>\n",
       "      <td>-1.514835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.876491</td>\n",
       "      <td>0.379460</td>\n",
       "      <td>0.842800</td>\n",
       "      <td>-0.131901</td>\n",
       "      <td>-1.436596</td>\n",
       "      <td>-0.111519</td>\n",
       "      <td>0.202112</td>\n",
       "      <td>-1.200294</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>1.728909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507345</td>\n",
       "      <td>-0.444546</td>\n",
       "      <td>-0.023700</td>\n",
       "      <td>-0.064766</td>\n",
       "      <td>-1.220138</td>\n",
       "      <td>-1.191618</td>\n",
       "      <td>-1.252607</td>\n",
       "      <td>-0.144561</td>\n",
       "      <td>-0.297459</td>\n",
       "      <td>-1.693445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.106189</td>\n",
       "      <td>0.250564</td>\n",
       "      <td>-0.755103</td>\n",
       "      <td>-1.996310</td>\n",
       "      <td>-0.052435</td>\n",
       "      <td>-1.739802</td>\n",
       "      <td>-0.104535</td>\n",
       "      <td>-2.018652</td>\n",
       "      <td>-2.291933</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291221</td>\n",
       "      <td>0.227128</td>\n",
       "      <td>-0.987092</td>\n",
       "      <td>1.263341</td>\n",
       "      <td>-0.487931</td>\n",
       "      <td>0.744031</td>\n",
       "      <td>-0.224342</td>\n",
       "      <td>0.475669</td>\n",
       "      <td>0.754459</td>\n",
       "      <td>0.394249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.371989</td>\n",
       "      <td>2.050487</td>\n",
       "      <td>-1.630269</td>\n",
       "      <td>-0.268340</td>\n",
       "      <td>-0.273032</td>\n",
       "      <td>-1.655492</td>\n",
       "      <td>1.444483</td>\n",
       "      <td>-0.035196</td>\n",
       "      <td>-0.308336</td>\n",
       "      <td>-0.294922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>0.188480</td>\n",
       "      <td>0.358954</td>\n",
       "      <td>-0.049431</td>\n",
       "      <td>-1.289793</td>\n",
       "      <td>1.611939</td>\n",
       "      <td>0.694420</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>1.451116</td>\n",
       "      <td>0.507385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X142      X272      X360      X453      X561      X564      X597  \\\n",
       "0   1.249409  1.568163  1.125810  0.711784  1.271865  0.840418 -0.263967   \n",
       "1   1.870702  0.158488 -0.936967 -1.603290 -1.071022  0.498423  0.094053   \n",
       "2  -0.417953 -0.552798  0.646078 -1.250691 -0.288352  0.709452 -0.624321   \n",
       "3   0.016771 -2.048618 -0.216376  1.151214 -2.132672  2.013973 -0.423597   \n",
       "4   1.843358 -0.352327  0.179798 -0.868005  2.155207  0.443271 -1.555152   \n",
       "5  -0.264955  0.682733 -0.302484 -0.971136 -0.824829  0.987670  0.996937   \n",
       "6  -0.870010  0.714208 -0.674424  0.872967  0.720581  0.481076  0.555276   \n",
       "7   0.484004 -0.570079  0.156395  1.026807 -2.314570  0.915716  1.157932   \n",
       "8   2.505378  1.519541 -0.893808 -0.044584  0.020360  0.533965  0.462832   \n",
       "9  -0.612856  0.515833 -0.651477  0.905342 -0.617212  1.019360  1.396665   \n",
       "10 -0.334818  0.035217  0.150259  0.939482 -1.209807 -0.783941  0.590884   \n",
       "11  0.033005 -0.182215  0.167737  0.320292 -0.241685 -0.428893  1.040453   \n",
       "12  0.195364 -0.522029 -1.354569  0.169509  0.316084 -0.407314  1.346015   \n",
       "13 -0.250896 -0.375973 -1.223737  0.409868 -0.799912 -0.293606 -1.203276   \n",
       "14  0.613084  0.229977 -1.359745  1.429431  1.347217 -0.537766 -0.196051   \n",
       "15 -0.517141 -0.045924  1.114496  0.237294  0.968009 -0.728454  1.443304   \n",
       "16  0.002356  1.424646 -1.353052  1.544073 -0.061376 -0.794775  0.532008   \n",
       "17  0.809946 -0.024967  0.648362 -1.158626  0.981462  0.028324  0.918691   \n",
       "18  0.267925 -0.676707  0.215589 -1.305136  0.528556 -1.076244 -0.992120   \n",
       "19  0.823746 -1.777197  1.490487  1.884350 -1.089531  0.607409 -0.105193   \n",
       "20 -1.248959  1.100489 -0.111560 -0.602319  0.862675  0.825528  0.285858   \n",
       "21 -0.690636 -0.267930 -1.378445 -0.367718  1.810063 -1.045596 -0.216239   \n",
       "22 -0.017720 -1.302508  0.469278  0.080457 -0.339516  2.702655 -0.847837   \n",
       "23 -1.432093 -0.815070  1.654094 -0.079096  0.136901 -1.194686  0.001592   \n",
       "24  0.326345  2.360498 -0.028926  0.037641 -0.844809  1.200124 -0.719920   \n",
       "25  1.054602 -1.191695  0.422371  1.726401 -0.387097  0.817849 -0.142979   \n",
       "26  0.005735  0.272058 -0.621369 -0.639422  0.318882 -1.168663 -2.121348   \n",
       "27 -1.497782 -1.708829 -1.655251 -0.880199 -0.584995  0.508702  1.743673   \n",
       "28 -0.110488 -0.222707 -2.060066 -0.806188  1.257826 -0.357296  0.867260   \n",
       "29 -1.158744  0.298536  0.844679  0.889688 -0.702531 -0.628059 -1.634990   \n",
       "30 -0.127842 -0.223727  1.292963  1.666215 -1.122716  0.804472 -1.498092   \n",
       "31 -1.259069  0.008372 -0.477530  0.202344  1.570171 -0.189702 -0.919962   \n",
       "32 -1.898590 -0.217424 -0.225589 -1.363810 -0.064851  1.185185 -0.583451   \n",
       "33  0.985112  0.852511 -0.352459 -1.043612  0.195197  0.037696  1.592509   \n",
       "34  0.395270 -0.070299  0.467713  0.301241  1.096270 -0.336152  0.410360   \n",
       "35 -1.023366  1.496629  1.951467 -0.425810  0.524413  0.615106 -1.665859   \n",
       "36 -1.270295  0.687305  1.579835 -1.230045 -0.638149  0.872061 -0.008952   \n",
       "37 -1.087223 -0.090587  1.588481  0.523956 -0.567855  0.663795  0.090148   \n",
       "38 -0.398359  1.024212 -0.108988 -1.550813  1.226812 -0.412912 -1.915350   \n",
       "39  1.333437  0.035408  1.467497  0.580702  0.703106 -0.519059  0.310175   \n",
       "40  0.514634  0.304896 -0.866290 -1.273266  0.080080  0.495347  0.720226   \n",
       "41 -0.817331 -0.245489 -0.502178  1.947396 -0.310997  0.509029  1.198297   \n",
       "42  1.110656 -2.792998 -0.579520  0.571606 -0.677073  0.456899  1.058304   \n",
       "43 -1.249598 -0.456199  0.063644  0.290465  1.310384 -1.783478 -1.208766   \n",
       "44  1.807665 -1.380233  1.355370 -0.501201  0.490424 -2.280535  0.077679   \n",
       "45 -0.113043  0.019437 -0.474806  0.517467  0.528099 -1.589552 -1.122806   \n",
       "46  1.563555  0.124859  0.899784 -0.576478 -1.767024 -0.710012 -0.462963   \n",
       "47 -0.876491  0.379460  0.842800 -0.131901 -1.436596 -0.111519  0.202112   \n",
       "48  0.106189  0.250564 -0.755103 -1.996310 -0.052435 -1.739802 -0.104535   \n",
       "49 -0.371989  2.050487 -1.630269 -0.268340 -0.273032 -1.655492  1.444483   \n",
       "\n",
       "        X671      X728      X776  ...     X1717     X1766     X1805     X1871  \\\n",
       "0  -0.349348  0.386363  0.655466  ... -0.986518 -0.838144  0.823788 -2.129890   \n",
       "1  -1.384969 -0.802604 -1.654007  ... -0.966563 -0.993953  0.124873  1.272922   \n",
       "2  -1.788471  0.341925 -0.359369  ...  0.143718  0.673208 -1.068068 -0.163226   \n",
       "3   0.346573 -2.335538  0.137511  ...  0.545146 -1.231386  0.789447  0.707267   \n",
       "4  -1.114805 -0.720515 -1.049472  ... -1.076962  0.016623 -1.020345  0.619546   \n",
       "5  -0.667064  0.815016  1.056478  ...  0.360295 -0.434452  0.527155  1.026248   \n",
       "6  -1.934803  0.419677 -1.620618  ... -0.126896 -0.538900 -0.158716 -0.971775   \n",
       "7   1.173063  1.140964  0.577900  ...  0.101090  0.383593 -1.371423  1.949728   \n",
       "8  -0.036990  0.011283 -1.587063  ... -1.072214  0.027022  0.336844 -0.013892   \n",
       "9  -0.550788 -1.385569  0.484651  ...  1.196830  0.403029 -0.088789  1.821891   \n",
       "10 -2.743786  0.584231 -2.269297  ...  0.743865  0.382781  0.143922 -0.763061   \n",
       "11 -0.488217  0.935167 -0.401473  ... -0.181355  0.880600  0.781259  0.569627   \n",
       "12  1.076358  1.270729 -0.549957  ... -0.854030 -2.232684 -0.114081  0.139858   \n",
       "13 -0.461073  0.133594  0.823369  ...  1.156016  1.739863 -0.985799  0.166943   \n",
       "14  0.753592  1.811158 -1.021224  ...  0.365666  1.459939 -0.683917 -0.624789   \n",
       "15  1.320900 -1.835049  0.852636  ...  0.716854  0.501362  0.541683  1.004691   \n",
       "16 -0.421069  1.017708 -1.058350  ...  1.346286  0.081973 -0.447940 -1.285475   \n",
       "17 -0.732421 -1.105890  0.105844  ...  0.376879 -0.215025 -0.022102 -0.236774   \n",
       "18  0.698656  0.574112 -0.339096  ... -0.046818 -0.011860  1.060225 -0.258866   \n",
       "19 -0.025265 -0.211144  0.964546  ...  0.105873  1.526963  3.026076  0.706599   \n",
       "20 -0.261055 -0.034880 -0.008627  ... -1.780722 -0.373496 -0.783879 -2.982338   \n",
       "21 -0.728920  0.161649 -0.692377  ...  1.788568  0.371680  0.216951 -0.697507   \n",
       "22  0.628781  0.051155 -0.452759  ...  0.877788 -1.166637 -0.878166  1.057760   \n",
       "23 -0.391983  0.119430 -0.266621  ...  0.928726 -0.827317  0.938144 -0.540334   \n",
       "24  0.167232  0.723035  1.033524  ...  0.241846 -1.380123 -0.708717  1.235421   \n",
       "25  1.728085  0.269422  0.203551  ...  0.699630  0.605107  0.263811  0.306097   \n",
       "26 -0.296696  0.244406  2.167375  ...  1.371162 -1.072881 -1.508321 -0.510814   \n",
       "27  0.337662 -0.194697 -0.080779  ... -0.585596  0.795886  0.342858 -1.463495   \n",
       "28  0.024734  0.263595  1.231784  ...  0.239445 -0.627869  1.711837 -0.102761   \n",
       "29  0.501256  1.608680  1.114172  ...  1.986816 -0.971565  0.565095 -0.198416   \n",
       "30  2.146565  0.022905 -1.423223  ... -0.013935  1.790910  1.408362  1.117245   \n",
       "31  0.467825 -0.301439  0.320218  ... -1.722558 -0.819341  1.184111 -2.014289   \n",
       "32  0.065558 -0.982436  0.394963  ... -0.882324 -1.033133  0.930715  0.205747   \n",
       "33 -0.175320  1.128746  1.555091  ...  0.907464 -0.069603 -1.257553 -0.451738   \n",
       "34 -0.078326  1.102683 -0.318526  ...  0.866784  1.353233 -1.230553  0.336590   \n",
       "35  0.421766 -0.302420  0.819240  ...  1.504213  0.304143 -1.489723 -0.321739   \n",
       "36 -0.161988 -0.230398 -1.214473  ... -0.335162 -0.273891 -0.697389  1.513069   \n",
       "37 -0.552266 -1.593218  0.824117  ... -0.508641  0.912698 -0.346858 -0.501963   \n",
       "38  0.426108  1.681192 -1.166154  ... -0.005434  1.629311 -1.176197 -0.591605   \n",
       "39  0.119748 -0.161598 -0.876056  ... -1.042839  0.899216  1.519704  0.014886   \n",
       "40  0.455031 -0.757009 -0.256344  ... -1.342346 -0.651101 -0.616337  0.476464   \n",
       "41  1.539972  0.086388  0.327618  ... -1.621656  1.319393  0.167300  0.697358   \n",
       "42  1.856614 -0.210600  1.532213  ... -1.402324 -1.128573  1.055114  0.805017   \n",
       "43  0.410358  1.619502 -1.044319  ...  0.868667  1.289047  0.020000 -0.614925   \n",
       "44  1.222137  0.143248  1.332544  ... -1.193462 -2.622905 -1.940834 -0.485053   \n",
       "45  1.139549 -2.252890  0.555787  ... -0.063558  0.646992  1.446065 -1.384222   \n",
       "46 -0.428359 -0.847018 -0.812698  ... -2.365054 -0.450793 -0.677795  0.408830   \n",
       "47 -1.200294  0.197218  1.728909  ...  0.507345 -0.444546 -0.023700 -0.064766   \n",
       "48 -2.018652 -2.291933  0.018298  ... -0.291221  0.227128 -0.987092  1.263341   \n",
       "49 -0.035196 -0.308336 -0.294922  ...  0.521217  0.188480  0.358954 -0.049431   \n",
       "\n",
       "       X1877     X1905     X1909     X1918     X1930     X1989  \n",
       "0  -0.361329 -0.487599  0.532695  1.423379  0.141332 -0.602507  \n",
       "1   2.797161  0.591919  1.512906 -0.850299  0.274113 -0.885349  \n",
       "2   0.565365 -0.720831 -0.021718 -1.620022 -0.775336 -0.314378  \n",
       "3   1.010862 -0.606913  1.290897  0.757219  0.738596  0.591696  \n",
       "4   1.870858 -0.754453  0.819591  0.101769 -0.566678  1.785798  \n",
       "5  -0.217184  0.783978  1.206786  1.348671  0.291350 -0.807512  \n",
       "6   1.242384  1.135165  0.543484 -1.157614  0.157062 -0.968501  \n",
       "7   0.327946 -0.507633  0.438548  1.003838 -0.286521 -0.809103  \n",
       "8  -1.106138  0.840831  1.578551 -0.505517 -3.042619  0.553487  \n",
       "9  -0.295737  0.919460 -0.962120 -0.124618  0.189774 -0.356320  \n",
       "10 -1.707292  0.128111  0.475092 -0.920464 -0.838316 -0.679007  \n",
       "11  0.174203  0.840668  0.891634  1.039288  0.704507 -0.051820  \n",
       "12 -0.675113 -1.433497  1.620152  0.794146 -0.971084  0.401746  \n",
       "13 -0.297770  1.400469 -0.720094 -0.714174  1.242348 -0.103041  \n",
       "14  1.067460  0.810842  0.079006  1.739279 -1.102826 -0.286523  \n",
       "15  0.816479  0.516720 -1.859654  1.067264 -2.046410  0.090338  \n",
       "16  0.716438 -1.714357 -0.685598 -0.639155 -0.460880 -0.548257  \n",
       "17 -0.359100  1.705418 -1.300816 -1.035269 -0.944274 -1.321088  \n",
       "18  0.609170 -0.392034  0.660524 -0.885924  0.055031  0.367228  \n",
       "19 -1.046273 -0.265196  0.379312 -0.588686  0.238336 -0.149405  \n",
       "20  1.588417 -0.521467  0.136156 -1.125725  0.924172 -1.594084  \n",
       "21  0.181541 -0.004667 -2.144401  1.314715  0.547558 -0.037767  \n",
       "22 -1.736979 -1.730782  0.482344 -0.469469  0.643803  0.247301  \n",
       "23  0.970482 -0.298262 -1.718431  0.895326  0.810715  0.985495  \n",
       "24  0.323636 -1.421818 -1.872257 -1.010318  0.417168  0.678652  \n",
       "25 -1.658897 -1.710104  0.363345 -0.995995 -0.400018 -0.557544  \n",
       "26  1.456227  0.174108  0.331242  0.323125 -0.609264  0.825213  \n",
       "27 -0.120760  1.338165 -0.777633  0.672435  1.594673  2.039983  \n",
       "28 -0.667358  0.637427  0.709103 -0.385888 -0.579766  0.086509  \n",
       "29 -1.121547  0.990794 -0.903352  0.205765 -0.845368  1.683156  \n",
       "30  0.034506 -0.400991  0.222862  0.501602  0.404224 -0.081870  \n",
       "31 -0.664687  0.701390  0.174419 -1.642118 -1.172437 -0.743402  \n",
       "32  0.132158 -1.466099 -1.143877  0.844709  1.686469 -1.013554  \n",
       "33  0.537745 -0.510845  0.350730 -0.424155 -0.014714  1.303558  \n",
       "34 -0.561704  0.805024 -0.583254 -0.538699  0.634445 -0.892469  \n",
       "35  0.625750  1.461683  0.888196 -0.312387  0.537177 -0.202681  \n",
       "36  0.348401 -2.850355  1.487198 -1.710007  2.348089 -2.495564  \n",
       "37  0.902805 -0.157644 -1.667233  0.275262 -0.221413  1.813337  \n",
       "38 -0.694447  0.730301  0.052774 -2.219312 -1.199850  0.459782  \n",
       "39 -0.488798  0.291851 -0.470426  0.725394  0.074109 -0.188974  \n",
       "40 -0.749842  0.342244  0.102890  0.650991 -0.452231 -0.455583  \n",
       "41 -0.084753  0.072605  0.459061  1.514347  1.542219  0.773944  \n",
       "42  1.320698  0.215481 -0.198156  1.776437 -1.854268  0.380418  \n",
       "43 -0.345523  0.460148  0.005009 -0.750189  0.429070  2.348878  \n",
       "44 -1.976481 -0.844589 -1.017864  1.170823 -0.074751 -0.227163  \n",
       "45  0.743467 -0.712448 -0.913097 -1.109096 -0.784516  1.263594  \n",
       "46 -0.428587  0.453427  1.948004  0.965837  0.709082 -1.514835  \n",
       "47 -1.220138 -1.191618 -1.252607 -0.144561 -0.297459 -1.693445  \n",
       "48 -0.487931  0.744031 -0.224342  0.475669  0.754459  0.394249  \n",
       "49 -1.289793  1.611939  0.694420  0.292373  1.451116  0.507385  \n",
       "\n",
       "[50 rows x 44 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_standardized\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f84acfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83c05428",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "803bfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9dc721ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Without Hyperparameter Tuning\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "292ec814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.5992428811395732\n",
      "Root_Mean_squared_error (Test) = 0.774107796847166\n",
      "R2_score (Test) = 0.5355878550460363\n",
      "Mean_squared_error (Train) = 0.007255017400607279\n",
      "Root_Mean_squared_error (Train) = 0.0851763899247161\n",
      "R2_score (Train) = 0.9918706030506397\n"
     ]
    }
   ],
   "source": [
    "# testing data evaluation \n",
    "y_predict_test  = ridge.predict(X_test)\n",
    "\n",
    "Mean_squared_error = mean_squared_error(y_test,y_predict_test)\n",
    "print('Mean_squared_error (Test) =',Mean_squared_error)\n",
    "\n",
    "Root_Mean_squared_error = np.sqrt(Mean_squared_error)\n",
    "print('Root_Mean_squared_error (Test) =',Root_Mean_squared_error)\n",
    "\n",
    "R2_score = r2_score(y_test,y_predict_test)\n",
    "print('R2_score (Test) =',R2_score)\n",
    "\n",
    "\n",
    "# training data evaluation \n",
    "y_predict_train = ridge.predict(X_train)\n",
    "\n",
    "Mean_squared_error = mean_squared_error(y_train,y_predict_train)\n",
    "print('Mean_squared_error (Train) =',Mean_squared_error)\n",
    "\n",
    "Root_Mean_squared_error = np.sqrt(Mean_squared_error)\n",
    "print('Root_Mean_squared_error (Train) =',Root_Mean_squared_error)\n",
    "\n",
    "R2_score = r2_score(y_train,y_predict_train)\n",
    "print('R2_score (Train) =',R2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da935fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ac010da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning for Ridge Regression\n",
    "ridge = Ridge()\n",
    "params = {\"alpha\": np.logspace(-3, 3, 50)}  # Searching across a range of alpha values\n",
    "ridge_cv = GridSearchCV(ridge, param_grid=params, cv=5, scoring=\"r2\")\n",
    "ridge_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c7af3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 19.306977288832496\n"
     ]
    }
   ],
   "source": [
    "# Best model from GridSearchCV\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "print(\"Best Alpha:\", ridge_cv.best_params_[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de20c900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.4298979346236863\n",
      "Root_Mean_squared_error (Test) = 0.655666023691701\n",
      "R2_score (Test) = 0.6668298811490372\n",
      "Mean_squared_error (Train) = 0.05790645330691358\n",
      "Root_Mean_squared_error (Train) = 0.2406375974508422\n",
      "R2_score (Train) = 0.935114622216882\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "y_predict_test = ridge_best.predict(X_test)\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = ridge_best.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ab93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd0576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa6f791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4ccaae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianRidge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianRidge</label><div class=\"sk-toggleable__content\"><pre>BayesianRidge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian Ridge Regression\n",
    "bayesian_ridge = BayesianRidge()\n",
    "bayesian_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f94ae1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.4056945596245111\n",
      "Root_Mean_squared_error (Test) = 0.6369415668838949\n",
      "R2_score (Test) = 0.6855874528320189\n",
      "Mean_squared_error (Train) = 0.04167143930517466\n",
      "Root_Mean_squared_error (Train) = 0.20413583542625402\n",
      "R2_score (Train) = 0.9533062909629157\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "y_predict_test = bayesian_ridge.predict(X_test)\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = bayesian_ridge.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6fbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5465746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha_1': 1e-12, 'alpha_2': 0.01, 'lambda_1': 0.01, 'lambda_2': 1e-12, 'n_iter': 50}\n",
      "Best Score: 0.28592437859849723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_bayes.py:53: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.3 and will be removed in 1.5\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "bayesian_ridge = BayesianRidge()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'alpha_1': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'alpha_2': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'lambda_1': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'lambda_2': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'n_iter': [50, 100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Define scoring metric\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bayesian_ridge,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters and corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", -grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_predict_test = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa433d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.40622787675614364\n",
      "Root_Mean_squared_error (Test) = 0.6373600840624895\n",
      "R2_score (Test) = 0.6851741330232444\n",
      "Mean_squared_error (Train) = 0.04217323726303375\n",
      "Root_Mean_squared_error (Train) = 0.20536123602820897\n",
      "R2_score (Train) = 0.9527440159796092\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = best_model.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c7e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd87b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dff629cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial VIF Values:\n",
      "    Feature  VIF\n",
      "0        X1  inf\n",
      "1        X2  inf\n",
      "2        X5  inf\n",
      "3       X23  inf\n",
      "4      X123  inf\n",
      "..      ...  ...\n",
      "195   X1974  inf\n",
      "196   X1977  inf\n",
      "197   X1982  inf\n",
      "198   X1989  inf\n",
      "199   X1997  inf\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "Removing feature: X1 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X2 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X5 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X23 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X123 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X140 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X142 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X233 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X238 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X252 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X272 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X273 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X290 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X305 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X339 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X360 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X381 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X430 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X453 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X472 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X543 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X559 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X561 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X562 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X564 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X575 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X597 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X671 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X714 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X715 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X728 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X757 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X776 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X782 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X785 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X786 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X812 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X827 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X830 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X863 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X873 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X875 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X878 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X881 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X886 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X889 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X899 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X905 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X918 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X922 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X926 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X931 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X937 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X968 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X982 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X999 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1005 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1011 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1012 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1017 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1022 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1026 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1032 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1042 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1043 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1044 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1046 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1055 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1061 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1067 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1069 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1087 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1092 (VIF: inf)\n",
      "Removing feature: X1098 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1103 (VIF: inf)\n",
      "Removing feature: X1124 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1133 (VIF: inf)\n",
      "Removing feature: X1135 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1157 (VIF: inf)\n",
      "Removing feature: X1158 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1183 (VIF: inf)\n",
      "Removing feature: X1188 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1195 (VIF: inf)\n",
      "Removing feature: X1198 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1200 (VIF: inf)\n",
      "Removing feature: X1211 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1228 (VIF: inf)\n",
      "Removing feature: X1233 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1237 (VIF: inf)\n",
      "Removing feature: X1241 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1243 (VIF: inf)\n",
      "Removing feature: X1244 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1248 (VIF: inf)\n",
      "Removing feature: X1249 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1250 (VIF: inf)\n",
      "Removing feature: X1255 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1259 (VIF: inf)\n",
      "Removing feature: X1264 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1266 (VIF: inf)\n",
      "Removing feature: X1304 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1307 (VIF: inf)\n",
      "Removing feature: X1312 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1314 (VIF: inf)\n",
      "Removing feature: X1318 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1350 (VIF: inf)\n",
      "Removing feature: X1354 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1366 (VIF: inf)\n",
      "Removing feature: X1377 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1382 (VIF: inf)\n",
      "Removing feature: X1405 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1407 (VIF: inf)\n",
      "Removing feature: X1409 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1412 (VIF: inf)\n",
      "Removing feature: X1420 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1434 (VIF: inf)\n",
      "Removing feature: X1436 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1437 (VIF: inf)\n",
      "Removing feature: X1440 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1446 (VIF: inf)\n",
      "Removing feature: X1455 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1460 (VIF: inf)\n",
      "Removing feature: X1461 (VIF: inf)\n",
      "Removing feature: X1462 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1464 (VIF: inf)\n",
      "Removing feature: X1470 (VIF: inf)\n",
      "Removing feature: X1481 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1490 (VIF: inf)\n",
      "Removing feature: X1494 (VIF: inf)\n",
      "Removing feature: X1496 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1505 (VIF: inf)\n",
      "Removing feature: X1521 (VIF: inf)\n",
      "Removing feature: X1528 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1533 (VIF: inf)\n",
      "Removing feature: X1536 (VIF: inf)\n",
      "Removing feature: X1539 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1542 (VIF: inf)\n",
      "Removing feature: X1551 (VIF: inf)\n",
      "Removing feature: X1557 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1562 (VIF: inf)\n",
      "Removing feature: X1570 (VIF: inf)\n",
      "Removing feature: X1571 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1572 (VIF: inf)\n",
      "Removing feature: X1591 (VIF: inf)\n",
      "Removing feature: X1600 (VIF: inf)\n",
      "Removing feature: X1609 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1610 (VIF: inf)\n",
      "Removing feature: X1611 (VIF: inf)\n",
      "Removing feature: X1614 (VIF: inf)\n",
      "Removing feature: X1623 (VIF: inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1628 (VIF: inf)\n",
      "Removing feature: X1634 (VIF: inf)\n",
      "Removing feature: X1989 (VIF: 53.862566948891434)\n",
      "Removing feature: X1766 (VIF: 40.302463002110684)\n",
      "Removing feature: X1982 (VIF: 20.72979394850459)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: X1666 (VIF: 15.243763698706411)\n",
      "Removing feature: X1874 (VIF: 12.035159881781059)\n",
      "Removing feature: X1904 (VIF: 10.832219609266026)\n",
      "Final VIF Values:\n",
      "   Feature       VIF\n",
      "0    X1638  5.342930\n",
      "1    X1639  4.190270\n",
      "2    X1671  5.814081\n",
      "3    X1673  4.778257\n",
      "4    X1698  3.999212\n",
      "5    X1704  4.273880\n",
      "6    X1717  6.892035\n",
      "7    X1727  4.375384\n",
      "8    X1730  4.354227\n",
      "9    X1731  6.231811\n",
      "10   X1733  5.020530\n",
      "11   X1738  5.115223\n",
      "12   X1741  6.965281\n",
      "13   X1745  4.641001\n",
      "14   X1749  3.722057\n",
      "15   X1772  3.791404\n",
      "16   X1778  3.129088\n",
      "17   X1795  5.502375\n",
      "18   X1800  6.059404\n",
      "19   X1801  3.075811\n",
      "20   X1804  6.504185\n",
      "21   X1805  3.335719\n",
      "22   X1810  7.289750\n",
      "23   X1820  6.827504\n",
      "24   X1824  5.815502\n",
      "25   X1833  3.761736\n",
      "26   X1864  7.105118\n",
      "27   X1871  6.927160\n",
      "28   X1877  6.233315\n",
      "29   X1882  4.952145\n",
      "30   X1888  6.118769\n",
      "31   X1889  6.906563\n",
      "32   X1905  3.953272\n",
      "33   X1909  2.868860\n",
      "34   X1916  4.650337\n",
      "35   X1918  4.239278\n",
      "36   X1920  6.388114\n",
      "37   X1927  7.318502\n",
      "38   X1930  8.591171\n",
      "39   X1963  4.155614\n",
      "40   X1974  8.750411\n",
      "41   X1977  4.020081\n",
      "42   X1997  2.930942\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace 'genotype.csv' with the actual path to your file\n",
    "genotype_data = pd.read_excel(\"k_feature_top_200_selected_features.xlsx\")\n",
    "phenotype_data = pd.read_csv(r\"C:\\Users\\Sandesh\\Desktop\\New folder\\phenotype.csv\")\n",
    "\n",
    "# Replace 'Phenotype' with the name of the target column if necessary\n",
    "X = data.drop(columns=[\"Phenotype\"])  # Independent variables\n",
    "y = phenotype_data  # Dependent variable (target)\n",
    "\n",
    "# Step 2: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for easier manipulation\n",
    "X_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "\n",
    "# Step 3: Define a function to calculate VIF\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Step 4: Calculate initial VIF\n",
    "vif_df = calculate_vif(X_standardized)\n",
    "print(\"Initial VIF Values:\")\n",
    "print(vif_df)\n",
    "\n",
    "# Step 5: Remove features with high VIF iteratively\n",
    "threshold = 10\n",
    "while vif_df[\"VIF\"].max() > threshold:\n",
    "    feature_to_remove = vif_df.loc[vif_df[\"VIF\"].idxmax(), \"Feature\"]\n",
    "    print(f\"Removing feature: {feature_to_remove} (VIF: {vif_df['VIF'].max()})\")\n",
    "    X_standardized = X_standardized.drop(columns=[feature_to_remove])\n",
    "    vif_df = calculate_vif(X_standardized)\n",
    "\n",
    "print(\"Final VIF Values:\")\n",
    "print(vif_df)\n",
    "\n",
    "# X_standardized now contains features with acceptable multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1bfc3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1638</th>\n",
       "      <th>X1639</th>\n",
       "      <th>X1671</th>\n",
       "      <th>X1673</th>\n",
       "      <th>X1698</th>\n",
       "      <th>X1704</th>\n",
       "      <th>X1717</th>\n",
       "      <th>X1727</th>\n",
       "      <th>X1730</th>\n",
       "      <th>X1731</th>\n",
       "      <th>...</th>\n",
       "      <th>X1909</th>\n",
       "      <th>X1916</th>\n",
       "      <th>X1918</th>\n",
       "      <th>X1920</th>\n",
       "      <th>X1927</th>\n",
       "      <th>X1930</th>\n",
       "      <th>X1963</th>\n",
       "      <th>X1974</th>\n",
       "      <th>X1977</th>\n",
       "      <th>X1997</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.040084</td>\n",
       "      <td>-0.408190</td>\n",
       "      <td>0.869120</td>\n",
       "      <td>0.842355</td>\n",
       "      <td>-0.774288</td>\n",
       "      <td>0.727681</td>\n",
       "      <td>-0.986518</td>\n",
       "      <td>-0.076969</td>\n",
       "      <td>0.997965</td>\n",
       "      <td>-1.697744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532695</td>\n",
       "      <td>-1.879965</td>\n",
       "      <td>1.423379</td>\n",
       "      <td>0.720419</td>\n",
       "      <td>2.037090</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>1.296570</td>\n",
       "      <td>-1.183504</td>\n",
       "      <td>0.442679</td>\n",
       "      <td>0.208378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.049329</td>\n",
       "      <td>-0.949435</td>\n",
       "      <td>-0.385058</td>\n",
       "      <td>-0.231628</td>\n",
       "      <td>0.932715</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>-0.966563</td>\n",
       "      <td>-1.318835</td>\n",
       "      <td>0.453841</td>\n",
       "      <td>0.809811</td>\n",
       "      <td>...</td>\n",
       "      <td>1.512906</td>\n",
       "      <td>-1.266179</td>\n",
       "      <td>-0.850299</td>\n",
       "      <td>-0.297017</td>\n",
       "      <td>-0.425125</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>-0.583040</td>\n",
       "      <td>0.045860</td>\n",
       "      <td>-1.100593</td>\n",
       "      <td>-0.474962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253905</td>\n",
       "      <td>0.821033</td>\n",
       "      <td>-2.057989</td>\n",
       "      <td>-1.627014</td>\n",
       "      <td>0.596324</td>\n",
       "      <td>0.345675</td>\n",
       "      <td>0.143718</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>0.026112</td>\n",
       "      <td>-0.623198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>0.359455</td>\n",
       "      <td>-1.620022</td>\n",
       "      <td>0.446556</td>\n",
       "      <td>0.982061</td>\n",
       "      <td>-0.775336</td>\n",
       "      <td>0.028276</td>\n",
       "      <td>-1.077046</td>\n",
       "      <td>0.522352</td>\n",
       "      <td>0.854413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511859</td>\n",
       "      <td>0.307253</td>\n",
       "      <td>-1.166390</td>\n",
       "      <td>-0.254052</td>\n",
       "      <td>-1.463750</td>\n",
       "      <td>-0.667686</td>\n",
       "      <td>0.545146</td>\n",
       "      <td>-0.864678</td>\n",
       "      <td>0.941409</td>\n",
       "      <td>-1.025084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.290897</td>\n",
       "      <td>0.943678</td>\n",
       "      <td>0.757219</td>\n",
       "      <td>0.752082</td>\n",
       "      <td>-0.810210</td>\n",
       "      <td>0.738596</td>\n",
       "      <td>-1.162766</td>\n",
       "      <td>1.510314</td>\n",
       "      <td>0.801964</td>\n",
       "      <td>-0.247326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.223206</td>\n",
       "      <td>-1.445167</td>\n",
       "      <td>0.231769</td>\n",
       "      <td>-0.133073</td>\n",
       "      <td>-0.021137</td>\n",
       "      <td>-1.236711</td>\n",
       "      <td>-1.076962</td>\n",
       "      <td>0.726791</td>\n",
       "      <td>-1.041844</td>\n",
       "      <td>-0.301082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819591</td>\n",
       "      <td>-0.940910</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>0.290557</td>\n",
       "      <td>-1.819871</td>\n",
       "      <td>-0.566678</td>\n",
       "      <td>0.182514</td>\n",
       "      <td>-0.100316</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.095650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.107686</td>\n",
       "      <td>0.577956</td>\n",
       "      <td>-0.097897</td>\n",
       "      <td>-0.237307</td>\n",
       "      <td>-0.597501</td>\n",
       "      <td>1.167223</td>\n",
       "      <td>0.360295</td>\n",
       "      <td>0.483479</td>\n",
       "      <td>0.813026</td>\n",
       "      <td>0.302284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206786</td>\n",
       "      <td>-1.788908</td>\n",
       "      <td>1.348671</td>\n",
       "      <td>1.195885</td>\n",
       "      <td>1.068708</td>\n",
       "      <td>0.291350</td>\n",
       "      <td>-0.797106</td>\n",
       "      <td>0.664587</td>\n",
       "      <td>1.230574</td>\n",
       "      <td>0.224586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.426598</td>\n",
       "      <td>-0.618675</td>\n",
       "      <td>-0.228590</td>\n",
       "      <td>1.764436</td>\n",
       "      <td>-0.163861</td>\n",
       "      <td>-1.754672</td>\n",
       "      <td>-0.126896</td>\n",
       "      <td>-1.710845</td>\n",
       "      <td>-0.739303</td>\n",
       "      <td>-1.155512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543484</td>\n",
       "      <td>-0.560342</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>1.079472</td>\n",
       "      <td>1.073554</td>\n",
       "      <td>0.157062</td>\n",
       "      <td>0.555005</td>\n",
       "      <td>0.225416</td>\n",
       "      <td>0.051247</td>\n",
       "      <td>0.660066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.065955</td>\n",
       "      <td>-1.083521</td>\n",
       "      <td>-0.924277</td>\n",
       "      <td>-1.362180</td>\n",
       "      <td>-2.008935</td>\n",
       "      <td>0.236058</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>-0.363772</td>\n",
       "      <td>-0.194588</td>\n",
       "      <td>2.085929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438548</td>\n",
       "      <td>1.670531</td>\n",
       "      <td>1.003838</td>\n",
       "      <td>-0.007859</td>\n",
       "      <td>0.373293</td>\n",
       "      <td>-0.286521</td>\n",
       "      <td>0.440929</td>\n",
       "      <td>-0.431658</td>\n",
       "      <td>-1.498035</td>\n",
       "      <td>0.026859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.716915</td>\n",
       "      <td>0.301172</td>\n",
       "      <td>1.187310</td>\n",
       "      <td>-0.718383</td>\n",
       "      <td>-0.286141</td>\n",
       "      <td>0.805148</td>\n",
       "      <td>-1.072214</td>\n",
       "      <td>1.578785</td>\n",
       "      <td>0.802313</td>\n",
       "      <td>0.368714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.578551</td>\n",
       "      <td>0.248645</td>\n",
       "      <td>-0.505517</td>\n",
       "      <td>-0.279675</td>\n",
       "      <td>-0.099817</td>\n",
       "      <td>-3.042619</td>\n",
       "      <td>-2.325575</td>\n",
       "      <td>-1.262790</td>\n",
       "      <td>-1.081312</td>\n",
       "      <td>0.170240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.033719</td>\n",
       "      <td>1.253592</td>\n",
       "      <td>-0.359919</td>\n",
       "      <td>0.649658</td>\n",
       "      <td>-0.703704</td>\n",
       "      <td>-0.841240</td>\n",
       "      <td>1.196830</td>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.229982</td>\n",
       "      <td>1.085838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.962120</td>\n",
       "      <td>-1.112452</td>\n",
       "      <td>-0.124618</td>\n",
       "      <td>-1.921436</td>\n",
       "      <td>-0.720714</td>\n",
       "      <td>0.189774</td>\n",
       "      <td>-0.044217</td>\n",
       "      <td>0.799435</td>\n",
       "      <td>1.467394</td>\n",
       "      <td>-0.906010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.533488</td>\n",
       "      <td>1.592304</td>\n",
       "      <td>-0.109498</td>\n",
       "      <td>0.522556</td>\n",
       "      <td>-0.931238</td>\n",
       "      <td>-1.929714</td>\n",
       "      <td>0.743865</td>\n",
       "      <td>0.328609</td>\n",
       "      <td>-0.871838</td>\n",
       "      <td>-0.439721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475092</td>\n",
       "      <td>0.694553</td>\n",
       "      <td>-0.920464</td>\n",
       "      <td>-0.357084</td>\n",
       "      <td>1.578427</td>\n",
       "      <td>-0.838316</td>\n",
       "      <td>1.967636</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.716688</td>\n",
       "      <td>1.143015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.466041</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>-0.574527</td>\n",
       "      <td>1.968521</td>\n",
       "      <td>0.076303</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>-0.181355</td>\n",
       "      <td>1.085179</td>\n",
       "      <td>-1.575431</td>\n",
       "      <td>-0.667294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891634</td>\n",
       "      <td>0.612002</td>\n",
       "      <td>1.039288</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>1.449060</td>\n",
       "      <td>0.704507</td>\n",
       "      <td>1.068064</td>\n",
       "      <td>-0.131405</td>\n",
       "      <td>1.497500</td>\n",
       "      <td>-0.824397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.599909</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.049336</td>\n",
       "      <td>-1.729568</td>\n",
       "      <td>2.687027</td>\n",
       "      <td>1.128001</td>\n",
       "      <td>-0.854030</td>\n",
       "      <td>0.143051</td>\n",
       "      <td>-0.645691</td>\n",
       "      <td>0.845272</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620152</td>\n",
       "      <td>1.136807</td>\n",
       "      <td>0.794146</td>\n",
       "      <td>-1.293356</td>\n",
       "      <td>-0.484442</td>\n",
       "      <td>-0.971084</td>\n",
       "      <td>-0.182139</td>\n",
       "      <td>-0.149555</td>\n",
       "      <td>-0.050912</td>\n",
       "      <td>-0.218351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.133300</td>\n",
       "      <td>1.259719</td>\n",
       "      <td>-0.423090</td>\n",
       "      <td>-0.765838</td>\n",
       "      <td>-0.395278</td>\n",
       "      <td>-0.955927</td>\n",
       "      <td>1.156016</td>\n",
       "      <td>1.209335</td>\n",
       "      <td>-0.911927</td>\n",
       "      <td>-1.214748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720094</td>\n",
       "      <td>0.989388</td>\n",
       "      <td>-0.714174</td>\n",
       "      <td>1.684125</td>\n",
       "      <td>-1.481380</td>\n",
       "      <td>1.242348</td>\n",
       "      <td>0.958660</td>\n",
       "      <td>-0.260164</td>\n",
       "      <td>-1.325648</td>\n",
       "      <td>-0.260365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.976666</td>\n",
       "      <td>1.617225</td>\n",
       "      <td>-0.305743</td>\n",
       "      <td>0.556866</td>\n",
       "      <td>1.305903</td>\n",
       "      <td>-0.252378</td>\n",
       "      <td>0.365666</td>\n",
       "      <td>-1.469297</td>\n",
       "      <td>-0.464905</td>\n",
       "      <td>-0.082102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079006</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>1.739279</td>\n",
       "      <td>0.982720</td>\n",
       "      <td>-0.511470</td>\n",
       "      <td>-1.102826</td>\n",
       "      <td>-0.008126</td>\n",
       "      <td>1.080792</td>\n",
       "      <td>1.598100</td>\n",
       "      <td>0.741283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.904247</td>\n",
       "      <td>-1.553634</td>\n",
       "      <td>0.129354</td>\n",
       "      <td>-0.722022</td>\n",
       "      <td>-0.874610</td>\n",
       "      <td>0.716854</td>\n",
       "      <td>-0.338508</td>\n",
       "      <td>1.172387</td>\n",
       "      <td>-2.637078</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.859654</td>\n",
       "      <td>-0.658106</td>\n",
       "      <td>1.067264</td>\n",
       "      <td>1.148934</td>\n",
       "      <td>0.693645</td>\n",
       "      <td>-2.046410</td>\n",
       "      <td>-0.206557</td>\n",
       "      <td>-1.175763</td>\n",
       "      <td>-1.472684</td>\n",
       "      <td>1.683353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.003622</td>\n",
       "      <td>-0.712809</td>\n",
       "      <td>1.353421</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>-0.695834</td>\n",
       "      <td>-1.095642</td>\n",
       "      <td>1.346286</td>\n",
       "      <td>1.000131</td>\n",
       "      <td>0.625495</td>\n",
       "      <td>0.476298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.685598</td>\n",
       "      <td>0.131120</td>\n",
       "      <td>-0.639155</td>\n",
       "      <td>1.145287</td>\n",
       "      <td>-1.057130</td>\n",
       "      <td>-0.460880</td>\n",
       "      <td>-0.591480</td>\n",
       "      <td>1.670157</td>\n",
       "      <td>0.776580</td>\n",
       "      <td>-1.039501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.065712</td>\n",
       "      <td>-1.565944</td>\n",
       "      <td>1.976907</td>\n",
       "      <td>-0.175125</td>\n",
       "      <td>-1.075409</td>\n",
       "      <td>1.564776</td>\n",
       "      <td>0.376879</td>\n",
       "      <td>-0.701148</td>\n",
       "      <td>-0.727732</td>\n",
       "      <td>-0.131757</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.300816</td>\n",
       "      <td>-0.623680</td>\n",
       "      <td>-1.035269</td>\n",
       "      <td>-0.682246</td>\n",
       "      <td>-1.056004</td>\n",
       "      <td>-0.944274</td>\n",
       "      <td>0.302170</td>\n",
       "      <td>0.153898</td>\n",
       "      <td>-0.321200</td>\n",
       "      <td>0.089635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.732235</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>-0.671488</td>\n",
       "      <td>-0.404960</td>\n",
       "      <td>-0.220752</td>\n",
       "      <td>2.009732</td>\n",
       "      <td>-0.046818</td>\n",
       "      <td>-0.407199</td>\n",
       "      <td>-0.519417</td>\n",
       "      <td>0.310670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660524</td>\n",
       "      <td>-0.614121</td>\n",
       "      <td>-0.885924</td>\n",
       "      <td>-0.744527</td>\n",
       "      <td>-0.537187</td>\n",
       "      <td>0.055031</td>\n",
       "      <td>0.334308</td>\n",
       "      <td>-2.241290</td>\n",
       "      <td>0.141496</td>\n",
       "      <td>0.935027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.502020</td>\n",
       "      <td>0.445061</td>\n",
       "      <td>-1.202374</td>\n",
       "      <td>1.124064</td>\n",
       "      <td>1.059872</td>\n",
       "      <td>1.617386</td>\n",
       "      <td>0.105873</td>\n",
       "      <td>0.430339</td>\n",
       "      <td>0.174823</td>\n",
       "      <td>2.012431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379312</td>\n",
       "      <td>0.301356</td>\n",
       "      <td>-0.588686</td>\n",
       "      <td>0.667331</td>\n",
       "      <td>-0.662564</td>\n",
       "      <td>0.238336</td>\n",
       "      <td>1.146608</td>\n",
       "      <td>0.450578</td>\n",
       "      <td>0.196783</td>\n",
       "      <td>1.553986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.308183</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>1.486346</td>\n",
       "      <td>0.067082</td>\n",
       "      <td>1.330389</td>\n",
       "      <td>-0.733801</td>\n",
       "      <td>-1.780722</td>\n",
       "      <td>-0.387161</td>\n",
       "      <td>0.420621</td>\n",
       "      <td>0.470746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136156</td>\n",
       "      <td>0.848983</td>\n",
       "      <td>-1.125725</td>\n",
       "      <td>-1.891475</td>\n",
       "      <td>-0.907006</td>\n",
       "      <td>0.924172</td>\n",
       "      <td>0.107247</td>\n",
       "      <td>-1.077563</td>\n",
       "      <td>1.528585</td>\n",
       "      <td>2.144166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.204145</td>\n",
       "      <td>-0.415863</td>\n",
       "      <td>-0.783912</td>\n",
       "      <td>1.183609</td>\n",
       "      <td>1.759927</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>1.788568</td>\n",
       "      <td>-1.177151</td>\n",
       "      <td>-0.652524</td>\n",
       "      <td>-0.601602</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.144401</td>\n",
       "      <td>0.390474</td>\n",
       "      <td>1.314715</td>\n",
       "      <td>0.655540</td>\n",
       "      <td>0.566043</td>\n",
       "      <td>0.547558</td>\n",
       "      <td>1.486743</td>\n",
       "      <td>0.226015</td>\n",
       "      <td>2.271476</td>\n",
       "      <td>-0.756880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-1.390247</td>\n",
       "      <td>1.067707</td>\n",
       "      <td>-1.292714</td>\n",
       "      <td>-0.639816</td>\n",
       "      <td>1.144579</td>\n",
       "      <td>0.877788</td>\n",
       "      <td>1.236851</td>\n",
       "      <td>-0.662164</td>\n",
       "      <td>0.063378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482344</td>\n",
       "      <td>0.886827</td>\n",
       "      <td>-0.469469</td>\n",
       "      <td>0.215446</td>\n",
       "      <td>1.370415</td>\n",
       "      <td>0.643803</td>\n",
       "      <td>-0.106244</td>\n",
       "      <td>0.177379</td>\n",
       "      <td>-0.026141</td>\n",
       "      <td>1.860768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.872717</td>\n",
       "      <td>1.714345</td>\n",
       "      <td>-0.272000</td>\n",
       "      <td>1.427442</td>\n",
       "      <td>0.262476</td>\n",
       "      <td>-0.965560</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>0.190461</td>\n",
       "      <td>1.036546</td>\n",
       "      <td>-0.828022</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.718431</td>\n",
       "      <td>-0.805885</td>\n",
       "      <td>0.895326</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>1.553949</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>1.903999</td>\n",
       "      <td>1.275072</td>\n",
       "      <td>-0.133573</td>\n",
       "      <td>-1.787580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.046192</td>\n",
       "      <td>1.216125</td>\n",
       "      <td>0.026609</td>\n",
       "      <td>0.116947</td>\n",
       "      <td>-0.910405</td>\n",
       "      <td>0.529271</td>\n",
       "      <td>0.241846</td>\n",
       "      <td>-0.807278</td>\n",
       "      <td>1.433524</td>\n",
       "      <td>0.078724</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.872257</td>\n",
       "      <td>-1.511267</td>\n",
       "      <td>-1.010318</td>\n",
       "      <td>-2.697706</td>\n",
       "      <td>-0.685876</td>\n",
       "      <td>0.417168</td>\n",
       "      <td>0.598251</td>\n",
       "      <td>0.947028</td>\n",
       "      <td>-0.139515</td>\n",
       "      <td>-1.489611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.837594</td>\n",
       "      <td>-0.544825</td>\n",
       "      <td>1.501950</td>\n",
       "      <td>-0.166935</td>\n",
       "      <td>-0.708642</td>\n",
       "      <td>1.079239</td>\n",
       "      <td>0.699630</td>\n",
       "      <td>1.785657</td>\n",
       "      <td>2.429137</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363345</td>\n",
       "      <td>-1.485647</td>\n",
       "      <td>-0.995995</td>\n",
       "      <td>-0.396163</td>\n",
       "      <td>-0.498807</td>\n",
       "      <td>-0.400018</td>\n",
       "      <td>-1.203314</td>\n",
       "      <td>-0.017729</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>1.271725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.159289</td>\n",
       "      <td>1.753428</td>\n",
       "      <td>0.161410</td>\n",
       "      <td>-0.007677</td>\n",
       "      <td>-0.349033</td>\n",
       "      <td>0.039871</td>\n",
       "      <td>1.371162</td>\n",
       "      <td>0.194887</td>\n",
       "      <td>-0.216508</td>\n",
       "      <td>0.336977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331242</td>\n",
       "      <td>0.827250</td>\n",
       "      <td>0.323125</td>\n",
       "      <td>0.061205</td>\n",
       "      <td>-1.994365</td>\n",
       "      <td>-0.609264</td>\n",
       "      <td>-0.050041</td>\n",
       "      <td>1.777841</td>\n",
       "      <td>0.649913</td>\n",
       "      <td>-0.933596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.517659</td>\n",
       "      <td>-0.276870</td>\n",
       "      <td>1.220029</td>\n",
       "      <td>2.656284</td>\n",
       "      <td>0.767603</td>\n",
       "      <td>0.299005</td>\n",
       "      <td>-0.585596</td>\n",
       "      <td>0.480661</td>\n",
       "      <td>-1.477450</td>\n",
       "      <td>-1.884909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.777633</td>\n",
       "      <td>1.924581</td>\n",
       "      <td>0.672435</td>\n",
       "      <td>0.825238</td>\n",
       "      <td>-0.116937</td>\n",
       "      <td>1.594673</td>\n",
       "      <td>-0.414783</td>\n",
       "      <td>0.873646</td>\n",
       "      <td>-0.448967</td>\n",
       "      <td>-1.091794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.301506</td>\n",
       "      <td>-0.770148</td>\n",
       "      <td>-0.732668</td>\n",
       "      <td>-1.054816</td>\n",
       "      <td>0.473959</td>\n",
       "      <td>-0.205811</td>\n",
       "      <td>0.239445</td>\n",
       "      <td>0.327314</td>\n",
       "      <td>1.599273</td>\n",
       "      <td>-0.152197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709103</td>\n",
       "      <td>0.695777</td>\n",
       "      <td>-0.385888</td>\n",
       "      <td>-0.253928</td>\n",
       "      <td>0.817745</td>\n",
       "      <td>-0.579766</td>\n",
       "      <td>0.130571</td>\n",
       "      <td>0.789455</td>\n",
       "      <td>-0.496947</td>\n",
       "      <td>-0.597803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.039249</td>\n",
       "      <td>-0.495205</td>\n",
       "      <td>0.298577</td>\n",
       "      <td>0.844570</td>\n",
       "      <td>0.331720</td>\n",
       "      <td>-0.292627</td>\n",
       "      <td>1.986816</td>\n",
       "      <td>-0.796596</td>\n",
       "      <td>0.620758</td>\n",
       "      <td>-2.700929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>1.791721</td>\n",
       "      <td>0.205765</td>\n",
       "      <td>1.416609</td>\n",
       "      <td>-0.408908</td>\n",
       "      <td>-0.845368</td>\n",
       "      <td>0.425277</td>\n",
       "      <td>1.475001</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-2.688837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1.189339</td>\n",
       "      <td>0.674929</td>\n",
       "      <td>0.082954</td>\n",
       "      <td>-0.958860</td>\n",
       "      <td>-1.101791</td>\n",
       "      <td>1.217417</td>\n",
       "      <td>-0.013935</td>\n",
       "      <td>-0.732121</td>\n",
       "      <td>-1.600537</td>\n",
       "      <td>0.275220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222862</td>\n",
       "      <td>2.299758</td>\n",
       "      <td>0.501602</td>\n",
       "      <td>-0.090121</td>\n",
       "      <td>0.180314</td>\n",
       "      <td>0.404224</td>\n",
       "      <td>-1.520539</td>\n",
       "      <td>-1.287324</td>\n",
       "      <td>1.245928</td>\n",
       "      <td>-0.140264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.278822</td>\n",
       "      <td>-0.108252</td>\n",
       "      <td>0.963961</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>0.549193</td>\n",
       "      <td>-0.620260</td>\n",
       "      <td>-1.722558</td>\n",
       "      <td>0.675883</td>\n",
       "      <td>2.003883</td>\n",
       "      <td>0.098212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.952869</td>\n",
       "      <td>-1.642118</td>\n",
       "      <td>1.740044</td>\n",
       "      <td>-1.008180</td>\n",
       "      <td>-1.172437</td>\n",
       "      <td>1.552020</td>\n",
       "      <td>-2.009500</td>\n",
       "      <td>-1.000896</td>\n",
       "      <td>0.042918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.582877</td>\n",
       "      <td>-0.453393</td>\n",
       "      <td>-0.303017</td>\n",
       "      <td>-0.913319</td>\n",
       "      <td>-1.074548</td>\n",
       "      <td>-1.993604</td>\n",
       "      <td>-0.882324</td>\n",
       "      <td>0.361714</td>\n",
       "      <td>-1.416039</td>\n",
       "      <td>1.038696</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.143877</td>\n",
       "      <td>0.706918</td>\n",
       "      <td>0.844709</td>\n",
       "      <td>-0.968511</td>\n",
       "      <td>0.924008</td>\n",
       "      <td>1.686469</td>\n",
       "      <td>-0.454102</td>\n",
       "      <td>-1.043698</td>\n",
       "      <td>-0.733435</td>\n",
       "      <td>-0.654330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.507080</td>\n",
       "      <td>-0.424719</td>\n",
       "      <td>-1.070128</td>\n",
       "      <td>-0.818944</td>\n",
       "      <td>1.153134</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.907464</td>\n",
       "      <td>-0.085014</td>\n",
       "      <td>0.229652</td>\n",
       "      <td>0.359660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350730</td>\n",
       "      <td>-0.513542</td>\n",
       "      <td>-0.424155</td>\n",
       "      <td>-1.184960</td>\n",
       "      <td>0.241192</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>-0.431860</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>-0.156006</td>\n",
       "      <td>-0.633626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.130662</td>\n",
       "      <td>0.344555</td>\n",
       "      <td>-0.298415</td>\n",
       "      <td>-0.389229</td>\n",
       "      <td>-0.093102</td>\n",
       "      <td>1.608260</td>\n",
       "      <td>0.866784</td>\n",
       "      <td>-1.527822</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>-0.440752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583254</td>\n",
       "      <td>-0.417028</td>\n",
       "      <td>-0.538699</td>\n",
       "      <td>1.430623</td>\n",
       "      <td>-0.788318</td>\n",
       "      <td>0.634445</td>\n",
       "      <td>-2.594910</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>-0.539154</td>\n",
       "      <td>0.255985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.573861</td>\n",
       "      <td>-0.825936</td>\n",
       "      <td>-0.929982</td>\n",
       "      <td>1.692834</td>\n",
       "      <td>0.211585</td>\n",
       "      <td>-0.216639</td>\n",
       "      <td>1.504213</td>\n",
       "      <td>1.425365</td>\n",
       "      <td>-0.086286</td>\n",
       "      <td>-1.031792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>1.254697</td>\n",
       "      <td>-0.312387</td>\n",
       "      <td>-0.334901</td>\n",
       "      <td>-0.587909</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>1.024247</td>\n",
       "      <td>-0.894338</td>\n",
       "      <td>1.371449</td>\n",
       "      <td>-0.344832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.684908</td>\n",
       "      <td>0.842934</td>\n",
       "      <td>0.331448</td>\n",
       "      <td>0.624237</td>\n",
       "      <td>-1.441589</td>\n",
       "      <td>-0.524214</td>\n",
       "      <td>-0.335162</td>\n",
       "      <td>-1.146385</td>\n",
       "      <td>0.241161</td>\n",
       "      <td>0.192106</td>\n",
       "      <td>...</td>\n",
       "      <td>1.487198</td>\n",
       "      <td>-0.591826</td>\n",
       "      <td>-1.710007</td>\n",
       "      <td>-0.287236</td>\n",
       "      <td>-0.599747</td>\n",
       "      <td>2.348089</td>\n",
       "      <td>0.914879</td>\n",
       "      <td>-0.462005</td>\n",
       "      <td>0.537240</td>\n",
       "      <td>0.620830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.676182</td>\n",
       "      <td>0.262473</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.486145</td>\n",
       "      <td>0.855596</td>\n",
       "      <td>0.563778</td>\n",
       "      <td>-0.508641</td>\n",
       "      <td>0.698289</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.704314</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.667233</td>\n",
       "      <td>-1.926329</td>\n",
       "      <td>0.275262</td>\n",
       "      <td>-0.600628</td>\n",
       "      <td>-0.145583</td>\n",
       "      <td>-0.221413</td>\n",
       "      <td>-0.174626</td>\n",
       "      <td>-0.659290</td>\n",
       "      <td>-0.814633</td>\n",
       "      <td>-1.471679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.046563</td>\n",
       "      <td>-0.943946</td>\n",
       "      <td>-0.616434</td>\n",
       "      <td>-0.232655</td>\n",
       "      <td>1.631695</td>\n",
       "      <td>0.796092</td>\n",
       "      <td>-0.005434</td>\n",
       "      <td>-1.230579</td>\n",
       "      <td>1.208137</td>\n",
       "      <td>0.678305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.435724</td>\n",
       "      <td>-2.219312</td>\n",
       "      <td>0.683460</td>\n",
       "      <td>-1.319656</td>\n",
       "      <td>-1.199850</td>\n",
       "      <td>-0.139398</td>\n",
       "      <td>1.216262</td>\n",
       "      <td>0.944782</td>\n",
       "      <td>-0.673663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.618705</td>\n",
       "      <td>-1.220003</td>\n",
       "      <td>-2.300432</td>\n",
       "      <td>-0.522573</td>\n",
       "      <td>-1.973490</td>\n",
       "      <td>0.824534</td>\n",
       "      <td>-1.042839</td>\n",
       "      <td>2.726594</td>\n",
       "      <td>1.644078</td>\n",
       "      <td>1.089473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470426</td>\n",
       "      <td>-0.715413</td>\n",
       "      <td>0.725394</td>\n",
       "      <td>0.710138</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>0.074109</td>\n",
       "      <td>0.217554</td>\n",
       "      <td>-2.298130</td>\n",
       "      <td>-1.503926</td>\n",
       "      <td>1.252476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.513182</td>\n",
       "      <td>-0.514677</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>0.901965</td>\n",
       "      <td>-0.943236</td>\n",
       "      <td>-0.769975</td>\n",
       "      <td>-1.342346</td>\n",
       "      <td>0.740285</td>\n",
       "      <td>-1.336900</td>\n",
       "      <td>0.775817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102890</td>\n",
       "      <td>-0.300806</td>\n",
       "      <td>0.650991</td>\n",
       "      <td>1.721899</td>\n",
       "      <td>0.842473</td>\n",
       "      <td>-0.452231</td>\n",
       "      <td>0.409829</td>\n",
       "      <td>0.145572</td>\n",
       "      <td>0.744398</td>\n",
       "      <td>-0.254216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-2.865430</td>\n",
       "      <td>-0.281949</td>\n",
       "      <td>-1.259862</td>\n",
       "      <td>-0.589958</td>\n",
       "      <td>1.466212</td>\n",
       "      <td>-1.677373</td>\n",
       "      <td>-1.621656</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.948976</td>\n",
       "      <td>-0.134048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459061</td>\n",
       "      <td>-0.487498</td>\n",
       "      <td>1.514347</td>\n",
       "      <td>-1.064561</td>\n",
       "      <td>-0.227792</td>\n",
       "      <td>1.542219</td>\n",
       "      <td>-1.284108</td>\n",
       "      <td>-1.074000</td>\n",
       "      <td>-1.001969</td>\n",
       "      <td>0.839134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.323943</td>\n",
       "      <td>1.308647</td>\n",
       "      <td>1.517564</td>\n",
       "      <td>0.651179</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>-0.874951</td>\n",
       "      <td>-1.402324</td>\n",
       "      <td>1.450881</td>\n",
       "      <td>0.255069</td>\n",
       "      <td>-0.299499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198156</td>\n",
       "      <td>-0.629251</td>\n",
       "      <td>1.776437</td>\n",
       "      <td>-0.343362</td>\n",
       "      <td>0.872284</td>\n",
       "      <td>-1.854268</td>\n",
       "      <td>-0.043292</td>\n",
       "      <td>-0.818812</td>\n",
       "      <td>-2.064929</td>\n",
       "      <td>1.074041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.491500</td>\n",
       "      <td>-0.208696</td>\n",
       "      <td>-1.000527</td>\n",
       "      <td>-0.174940</td>\n",
       "      <td>1.032413</td>\n",
       "      <td>-0.525215</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>-0.972338</td>\n",
       "      <td>-0.263510</td>\n",
       "      <td>0.327042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.063370</td>\n",
       "      <td>-0.750189</td>\n",
       "      <td>-0.301756</td>\n",
       "      <td>-0.378934</td>\n",
       "      <td>0.429070</td>\n",
       "      <td>-0.533991</td>\n",
       "      <td>1.596428</td>\n",
       "      <td>0.807820</td>\n",
       "      <td>-1.191084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.053290</td>\n",
       "      <td>-1.236611</td>\n",
       "      <td>0.961173</td>\n",
       "      <td>-1.260039</td>\n",
       "      <td>1.028215</td>\n",
       "      <td>0.787445</td>\n",
       "      <td>-1.193462</td>\n",
       "      <td>-0.944664</td>\n",
       "      <td>-1.956471</td>\n",
       "      <td>-0.487408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017864</td>\n",
       "      <td>-0.412649</td>\n",
       "      <td>1.170823</td>\n",
       "      <td>-0.618826</td>\n",
       "      <td>0.123815</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>-0.394953</td>\n",
       "      <td>0.268208</td>\n",
       "      <td>0.646819</td>\n",
       "      <td>-0.544326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.187917</td>\n",
       "      <td>2.364160</td>\n",
       "      <td>0.653730</td>\n",
       "      <td>-2.058150</td>\n",
       "      <td>0.110606</td>\n",
       "      <td>0.212754</td>\n",
       "      <td>-0.063558</td>\n",
       "      <td>0.202184</td>\n",
       "      <td>-0.537406</td>\n",
       "      <td>-0.506692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.913097</td>\n",
       "      <td>-0.043504</td>\n",
       "      <td>-1.109096</td>\n",
       "      <td>-0.305270</td>\n",
       "      <td>2.094238</td>\n",
       "      <td>-0.784516</td>\n",
       "      <td>1.813565</td>\n",
       "      <td>-0.143961</td>\n",
       "      <td>-0.528943</td>\n",
       "      <td>0.111035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.217857</td>\n",
       "      <td>-1.648086</td>\n",
       "      <td>1.665242</td>\n",
       "      <td>0.777491</td>\n",
       "      <td>-0.142250</td>\n",
       "      <td>-1.247090</td>\n",
       "      <td>-2.365054</td>\n",
       "      <td>-1.867524</td>\n",
       "      <td>-0.651763</td>\n",
       "      <td>1.023884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.948004</td>\n",
       "      <td>-1.245037</td>\n",
       "      <td>0.965837</td>\n",
       "      <td>-1.197484</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>0.709082</td>\n",
       "      <td>-1.882096</td>\n",
       "      <td>0.032151</td>\n",
       "      <td>-1.285250</td>\n",
       "      <td>-0.405716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.213294</td>\n",
       "      <td>-1.521362</td>\n",
       "      <td>1.805245</td>\n",
       "      <td>1.047289</td>\n",
       "      <td>-0.758578</td>\n",
       "      <td>0.933598</td>\n",
       "      <td>0.507345</td>\n",
       "      <td>-0.423135</td>\n",
       "      <td>-0.361689</td>\n",
       "      <td>1.921104</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.252607</td>\n",
       "      <td>-0.013381</td>\n",
       "      <td>-0.144561</td>\n",
       "      <td>0.074818</td>\n",
       "      <td>1.348282</td>\n",
       "      <td>-0.297459</td>\n",
       "      <td>-0.232222</td>\n",
       "      <td>0.114032</td>\n",
       "      <td>-1.530321</td>\n",
       "      <td>0.499164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.023588</td>\n",
       "      <td>-0.921639</td>\n",
       "      <td>0.438821</td>\n",
       "      <td>-1.098641</td>\n",
       "      <td>0.256214</td>\n",
       "      <td>0.785183</td>\n",
       "      <td>-0.291221</td>\n",
       "      <td>-1.168728</td>\n",
       "      <td>-1.180262</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224342</td>\n",
       "      <td>0.055171</td>\n",
       "      <td>0.475669</td>\n",
       "      <td>0.125149</td>\n",
       "      <td>-1.694160</td>\n",
       "      <td>0.754459</td>\n",
       "      <td>-0.868746</td>\n",
       "      <td>0.673855</td>\n",
       "      <td>0.644632</td>\n",
       "      <td>1.619471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.419549</td>\n",
       "      <td>0.620971</td>\n",
       "      <td>0.534831</td>\n",
       "      <td>-0.273555</td>\n",
       "      <td>-0.440097</td>\n",
       "      <td>-0.993090</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>0.168131</td>\n",
       "      <td>-0.656848</td>\n",
       "      <td>0.588255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694420</td>\n",
       "      <td>0.155836</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>-1.741601</td>\n",
       "      <td>0.262153</td>\n",
       "      <td>1.451116</td>\n",
       "      <td>-0.634688</td>\n",
       "      <td>0.822103</td>\n",
       "      <td>-0.896913</td>\n",
       "      <td>-0.347456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1638     X1639     X1671     X1673     X1698     X1704     X1717  \\\n",
       "0  -2.040084 -0.408190  0.869120  0.842355 -0.774288  0.727681 -0.986518   \n",
       "1  -1.049329 -0.949435 -0.385058 -0.231628  0.932715  0.044131 -0.966563   \n",
       "2   0.253905  0.821033 -2.057989 -1.627014  0.596324  0.345675  0.143718   \n",
       "3  -0.511859  0.307253 -1.166390 -0.254052 -1.463750 -0.667686  0.545146   \n",
       "4  -0.223206 -1.445167  0.231769 -0.133073 -0.021137 -1.236711 -1.076962   \n",
       "5  -0.107686  0.577956 -0.097897 -0.237307 -0.597501  1.167223  0.360295   \n",
       "6   1.426598 -0.618675 -0.228590  1.764436 -0.163861 -1.754672 -0.126896   \n",
       "7  -0.065955 -1.083521 -0.924277 -1.362180 -2.008935  0.236058  0.101090   \n",
       "8   1.716915  0.301172  1.187310 -0.718383 -0.286141  0.805148 -1.072214   \n",
       "9   1.033719  1.253592 -0.359919  0.649658 -0.703704 -0.841240  1.196830   \n",
       "10  1.533488  1.592304 -0.109498  0.522556 -0.931238 -1.929714  0.743865   \n",
       "11  0.466041  0.835914 -0.574527  1.968521  0.076303  0.000818 -0.181355   \n",
       "12 -0.599909  0.004876 -0.049336 -1.729568  2.687027  1.128001 -0.854030   \n",
       "13  1.133300  1.259719 -0.423090 -0.765838 -0.395278 -0.955927  1.156016   \n",
       "14  0.976666  1.617225 -0.305743  0.556866  1.305903 -0.252378  0.365666   \n",
       "15  0.091954  0.904247 -1.553634  0.129354 -0.722022 -0.874610  0.716854   \n",
       "16 -0.003622 -0.712809  1.353421  0.420600 -0.695834 -1.095642  1.346286   \n",
       "17 -0.065712 -1.565944  1.976907 -0.175125 -1.075409  1.564776  0.376879   \n",
       "18 -0.732235 -0.041223 -0.671488 -0.404960 -0.220752  2.009732 -0.046818   \n",
       "19  2.502020  0.445061 -1.202374  1.124064  1.059872  1.617386  0.105873   \n",
       "20  0.308183  0.004469  1.486346  0.067082  1.330389 -0.733801 -1.780722   \n",
       "21 -0.204145 -0.415863 -0.783912  1.183609  1.759927  0.710548  1.788568   \n",
       "22 -0.005346 -1.390247  1.067707 -1.292714 -0.639816  1.144579  0.877788   \n",
       "23  0.872717  1.714345 -0.272000  1.427442  0.262476 -0.965560  0.928726   \n",
       "24 -0.046192  1.216125  0.026609  0.116947 -0.910405  0.529271  0.241846   \n",
       "25 -0.837594 -0.544825  1.501950 -0.166935 -0.708642  1.079239  0.699630   \n",
       "26 -0.159289  1.753428  0.161410 -0.007677 -0.349033  0.039871  1.371162   \n",
       "27  0.517659 -0.276870  1.220029  2.656284  0.767603  0.299005 -0.585596   \n",
       "28 -1.301506 -0.770148 -0.732668 -1.054816  0.473959 -0.205811  0.239445   \n",
       "29  1.039249 -0.495205  0.298577  0.844570  0.331720 -0.292627  1.986816   \n",
       "30 -1.189339  0.674929  0.082954 -0.958860 -1.101791  1.217417 -0.013935   \n",
       "31  1.278822 -0.108252  0.963961 -0.031056  0.549193 -0.620260 -1.722558   \n",
       "32  0.582877 -0.453393 -0.303017 -0.913319 -1.074548 -1.993604 -0.882324   \n",
       "33  0.507080 -0.424719 -1.070128 -0.818944  1.153134  0.070588  0.907464   \n",
       "34 -0.130662  0.344555 -0.298415 -0.389229 -0.093102  1.608260  0.866784   \n",
       "35  0.573861 -0.825936 -0.929982  1.692834  0.211585 -0.216639  1.504213   \n",
       "36 -0.684908  0.842934  0.331448  0.624237 -1.441589 -0.524214 -0.335162   \n",
       "37 -1.676182  0.262473 -0.401676 -0.486145  0.855596  0.563778 -0.508641   \n",
       "38  0.046563 -0.943946 -0.616434 -0.232655  1.631695  0.796092 -0.005434   \n",
       "39 -0.618705 -1.220003 -2.300432 -0.522573 -1.973490  0.824534 -1.042839   \n",
       "40 -0.513182 -0.514677 -0.257263  0.901965 -0.943236 -0.769975 -1.342346   \n",
       "41 -2.865430 -0.281949 -1.259862 -0.589958  1.466212 -1.677373 -1.621656   \n",
       "42 -1.323943  1.308647  1.517564  0.651179  0.757344 -0.874951 -1.402324   \n",
       "43 -0.491500 -0.208696 -1.000527 -0.174940  1.032413 -0.525215  0.868667   \n",
       "44 -0.053290 -1.236611  0.961173 -1.260039  1.028215  0.787445 -1.193462   \n",
       "45 -1.187917  2.364160  0.653730 -2.058150  0.110606  0.212754 -0.063558   \n",
       "46  0.217857 -1.648086  1.665242  0.777491 -0.142250 -1.247090 -2.365054   \n",
       "47  0.213294 -1.521362  1.805245  1.047289 -0.758578  0.933598  0.507345   \n",
       "48 -0.023588 -0.921639  0.438821 -1.098641  0.256214  0.785183 -0.291221   \n",
       "49  1.419549  0.620971  0.534831 -0.273555 -0.440097 -0.993090  0.521217   \n",
       "\n",
       "       X1727     X1730     X1731  ...     X1909     X1916     X1918     X1920  \\\n",
       "0  -0.076969  0.997965 -1.697744  ...  0.532695 -1.879965  1.423379  0.720419   \n",
       "1  -1.318835  0.453841  0.809811  ...  1.512906 -1.266179 -0.850299 -0.297017   \n",
       "2  -0.024502  0.026112 -0.623198  ... -0.021718  0.359455 -1.620022  0.446556   \n",
       "3  -0.864678  0.941409 -1.025084  ...  1.290897  0.943678  0.757219  0.752082   \n",
       "4   0.726791 -1.041844 -0.301082  ...  0.819591 -0.940910  0.101769  0.290557   \n",
       "5   0.483479  0.813026  0.302284  ...  1.206786 -1.788908  1.348671  1.195885   \n",
       "6  -1.710845 -0.739303 -1.155512  ...  0.543484 -0.560342 -1.157614  1.079472   \n",
       "7  -0.363772 -0.194588  2.085929  ...  0.438548  1.670531  1.003838 -0.007859   \n",
       "8   1.578785  0.802313  0.368714  ...  1.578551  0.248645 -0.505517 -0.279675   \n",
       "9   0.688537  0.229982  1.085838  ... -0.962120 -1.112452 -0.124618 -1.921436   \n",
       "10  0.328609 -0.871838 -0.439721  ...  0.475092  0.694553 -0.920464 -0.357084   \n",
       "11  1.085179 -1.575431 -0.667294  ...  0.891634  0.612002  1.039288 -0.015237   \n",
       "12  0.143051 -0.645691  0.845272  ...  1.620152  1.136807  0.794146 -1.293356   \n",
       "13  1.209335 -0.911927 -1.214748  ... -0.720094  0.989388 -0.714174  1.684125   \n",
       "14 -1.469297 -0.464905 -0.082102  ...  0.079006  0.292977  1.739279  0.982720   \n",
       "15 -0.338508  1.172387 -2.637078  ... -1.859654 -0.658106  1.067264  1.148934   \n",
       "16  1.000131  0.625495  0.476298  ... -0.685598  0.131120 -0.639155  1.145287   \n",
       "17 -0.701148 -0.727732 -0.131757  ... -1.300816 -0.623680 -1.035269 -0.682246   \n",
       "18 -0.407199 -0.519417  0.310670  ...  0.660524 -0.614121 -0.885924 -0.744527   \n",
       "19  0.430339  0.174823  2.012431  ...  0.379312  0.301356 -0.588686  0.667331   \n",
       "20 -0.387161  0.420621  0.470746  ...  0.136156  0.848983 -1.125725 -1.891475   \n",
       "21 -1.177151 -0.652524 -0.601602  ... -2.144401  0.390474  1.314715  0.655540   \n",
       "22  1.236851 -0.662164  0.063378  ...  0.482344  0.886827 -0.469469  0.215446   \n",
       "23  0.190461  1.036546 -0.828022  ... -1.718431 -0.805885  0.895326  0.103389   \n",
       "24 -0.807278  1.433524  0.078724  ... -1.872257 -1.511267 -1.010318 -2.697706   \n",
       "25  1.785657  2.429137  0.410407  ...  0.363345 -1.485647 -0.995995 -0.396163   \n",
       "26  0.194887 -0.216508  0.336977  ...  0.331242  0.827250  0.323125  0.061205   \n",
       "27  0.480661 -1.477450 -1.884909  ... -0.777633  1.924581  0.672435  0.825238   \n",
       "28  0.327314  1.599273 -0.152197  ...  0.709103  0.695777 -0.385888 -0.253928   \n",
       "29 -0.796596  0.620758 -2.700929  ... -0.903352  1.791721  0.205765  1.416609   \n",
       "30 -0.732121 -1.600537  0.275220  ...  0.222862  2.299758  0.501602 -0.090121   \n",
       "31  0.675883  2.003883  0.098212  ...  0.174419  0.952869 -1.642118  1.740044   \n",
       "32  0.361714 -1.416039  1.038696  ... -1.143877  0.706918  0.844709 -0.968511   \n",
       "33 -0.085014  0.229652  0.359660  ...  0.350730 -0.513542 -0.424155 -1.184960   \n",
       "34 -1.527822  0.050679 -0.440752  ... -0.583254 -0.417028 -0.538699  1.430623   \n",
       "35  1.425365 -0.086286 -1.031792  ...  0.888196  1.254697 -0.312387 -0.334901   \n",
       "36 -1.146385  0.241161  0.192106  ...  1.487198 -0.591826 -1.710007 -0.287236   \n",
       "37  0.698289  0.390184  0.704314  ... -1.667233 -1.926329  0.275262 -0.600628   \n",
       "38 -1.230579  1.208137  0.678305  ...  0.052774  0.435724 -2.219312  0.683460   \n",
       "39  2.726594  1.644078  1.089473  ... -0.470426 -0.715413  0.725394  0.710138   \n",
       "40  0.740285 -1.336900  0.775817  ...  0.102890 -0.300806  0.650991  1.721899   \n",
       "41  0.202857  0.948976 -0.134048  ...  0.459061 -0.487498  1.514347 -1.064561   \n",
       "42  1.450881  0.255069 -0.299499  ... -0.198156 -0.629251  1.776437 -0.343362   \n",
       "43 -0.972338 -0.263510  0.327042  ...  0.005009 -0.063370 -0.750189 -0.301756   \n",
       "44 -0.944664 -1.956471 -0.487408  ... -1.017864 -0.412649  1.170823 -0.618826   \n",
       "45  0.202184 -0.537406 -0.506692  ... -0.913097 -0.043504 -1.109096 -0.305270   \n",
       "46 -1.867524 -0.651763  1.023884  ...  1.948004 -1.245037  0.965837 -1.197484   \n",
       "47 -0.423135 -0.361689  1.921104  ... -1.252607 -0.013381 -0.144561  0.074818   \n",
       "48 -1.168728 -1.180262  0.313600  ... -0.224342  0.055171  0.475669  0.125149   \n",
       "49  0.168131 -0.656848  0.588255  ...  0.694420  0.155836  0.292373 -1.741601   \n",
       "\n",
       "       X1927     X1930     X1963     X1974     X1977     X1997  \n",
       "0   2.037090  0.141332  1.296570 -1.183504  0.442679  0.208378  \n",
       "1  -0.425125  0.274113 -0.583040  0.045860 -1.100593 -0.474962  \n",
       "2   0.982061 -0.775336  0.028276 -1.077046  0.522352  0.854413  \n",
       "3  -0.810210  0.738596 -1.162766  1.510314  0.801964 -0.247326  \n",
       "4  -1.819871 -0.566678  0.182514 -0.100316 -0.033742  0.095650  \n",
       "5   1.068708  0.291350 -0.797106  0.664587  1.230574  0.224586  \n",
       "6   1.073554  0.157062  0.555005  0.225416  0.051247  0.660066  \n",
       "7   0.373293 -0.286521  0.440929 -0.431658 -1.498035  0.026859  \n",
       "8  -0.099817 -3.042619 -2.325575 -1.262790 -1.081312  0.170240  \n",
       "9  -0.720714  0.189774 -0.044217  0.799435  1.467394 -0.906010  \n",
       "10  1.578427 -0.838316  1.967636  0.018042  0.716688  1.143015  \n",
       "11  1.449060  0.704507  1.068064 -0.131405  1.497500 -0.824397  \n",
       "12 -0.484442 -0.971084 -0.182139 -0.149555 -0.050912 -0.218351  \n",
       "13 -1.481380  1.242348  0.958660 -0.260164 -1.325648 -0.260365  \n",
       "14 -0.511470 -1.102826 -0.008126  1.080792  1.598100  0.741283  \n",
       "15  0.693645 -2.046410 -0.206557 -1.175763 -1.472684  1.683353  \n",
       "16 -1.057130 -0.460880 -0.591480  1.670157  0.776580 -1.039501  \n",
       "17 -1.056004 -0.944274  0.302170  0.153898 -0.321200  0.089635  \n",
       "18 -0.537187  0.055031  0.334308 -2.241290  0.141496  0.935027  \n",
       "19 -0.662564  0.238336  1.146608  0.450578  0.196783  1.553986  \n",
       "20 -0.907006  0.924172  0.107247 -1.077563  1.528585  2.144166  \n",
       "21  0.566043  0.547558  1.486743  0.226015  2.271476 -0.756880  \n",
       "22  1.370415  0.643803 -0.106244  0.177379 -0.026141  1.860768  \n",
       "23  1.553949  0.810715  1.903999  1.275072 -0.133573 -1.787580  \n",
       "24 -0.685876  0.417168  0.598251  0.947028 -0.139515 -1.489611  \n",
       "25 -0.498807 -0.400018 -1.203314 -0.017729 -0.016872  1.271725  \n",
       "26 -1.994365 -0.609264 -0.050041  1.777841  0.649913 -0.933596  \n",
       "27 -0.116937  1.594673 -0.414783  0.873646 -0.448967 -1.091794  \n",
       "28  0.817745 -0.579766  0.130571  0.789455 -0.496947 -0.597803  \n",
       "29 -0.408908 -0.845368  0.425277  1.475001 -0.633881 -2.688837  \n",
       "30  0.180314  0.404224 -1.520539 -1.287324  1.245928 -0.140264  \n",
       "31 -1.008180 -1.172437  1.552020 -2.009500 -1.000896  0.042918  \n",
       "32  0.924008  1.686469 -0.454102 -1.043698 -0.733435 -0.654330  \n",
       "33  0.241192 -0.014714 -0.431860  0.636097 -0.156006 -0.633626  \n",
       "34 -0.788318  0.634445 -2.594910  0.134615 -0.539154  0.255985  \n",
       "35 -0.587909  0.537177  1.024247 -0.894338  1.371449 -0.344832  \n",
       "36 -0.599747  2.348089  0.914879 -0.462005  0.537240  0.620830  \n",
       "37 -0.145583 -0.221413 -0.174626 -0.659290 -0.814633 -1.471679  \n",
       "38 -1.319656 -1.199850 -0.139398  1.216262  0.944782 -0.673663  \n",
       "39  0.169631  0.074109  0.217554 -2.298130 -1.503926  1.252476  \n",
       "40  0.842473 -0.452231  0.409829  0.145572  0.744398 -0.254216  \n",
       "41 -0.227792  1.542219 -1.284108 -1.074000 -1.001969  0.839134  \n",
       "42  0.872284 -1.854268 -0.043292 -0.818812 -2.064929  1.074041  \n",
       "43 -0.378934  0.429070 -0.533991  1.596428  0.807820 -1.191084  \n",
       "44  0.123815 -0.074751 -0.394953  0.268208  0.646819 -0.544326  \n",
       "45  2.094238 -0.784516  1.813565 -0.143961 -0.528943  0.111035  \n",
       "46  0.405713  0.709082 -1.882096  0.032151 -1.285250 -0.405716  \n",
       "47  1.348282 -0.297459 -0.232222  0.114032 -1.530321  0.499164  \n",
       "48 -1.694160  0.754459 -0.868746  0.673855  0.644632  1.619471  \n",
       "49  0.262153  1.451116 -0.634688  0.822103 -0.896913 -0.347456  \n",
       "\n",
       "[50 rows x 43 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_standardized\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d0c6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ebd6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b7c7b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90e9fe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Without Hyperparameter Tuning\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c33fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.6053601779037608\n",
      "Root_Mean_squared_error (Test) = 0.7780489559814092\n",
      "R2_score (Test) = 0.5308469611597816\n",
      "Mean_squared_error (Train) = 0.001951060269041758\n",
      "Root_Mean_squared_error (Train) = 0.044170807883055045\n",
      "R2_score (Train) = 0.997813796642605\n"
     ]
    }
   ],
   "source": [
    "# testing data evaluation \n",
    "y_predict_test  = ridge.predict(X_test)\n",
    "\n",
    "Mean_squared_error = mean_squared_error(y_test,y_predict_test)\n",
    "print('Mean_squared_error (Test) =',Mean_squared_error)\n",
    "\n",
    "Root_Mean_squared_error = np.sqrt(Mean_squared_error)\n",
    "print('Root_Mean_squared_error (Test) =',Root_Mean_squared_error)\n",
    "\n",
    "R2_score = r2_score(y_test,y_predict_test)\n",
    "print('R2_score (Test) =',R2_score)\n",
    "\n",
    "\n",
    "# training data evaluation \n",
    "y_predict_train = ridge.predict(X_train)\n",
    "\n",
    "Mean_squared_error = mean_squared_error(y_train,y_predict_train)\n",
    "print('Mean_squared_error (Train) =',Mean_squared_error)\n",
    "\n",
    "Root_Mean_squared_error = np.sqrt(Mean_squared_error)\n",
    "print('Root_Mean_squared_error (Train) =',Root_Mean_squared_error)\n",
    "\n",
    "R2_score = r2_score(y_train,y_predict_train)\n",
    "print('R2_score (Train) =',R2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fd564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45800f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2....\n",
       "       8.68511374e-01, 1.15139540e+00, 1.52641797e+00, 2.02358965e+00,\n",
       "       2.68269580e+00, 3.55648031e+00, 4.71486636e+00, 6.25055193e+00,\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning for Ridge Regression\n",
    "ridge = Ridge()\n",
    "params = {\"alpha\": np.logspace(-3, 3, 50)}  # Searching across a range of alpha values\n",
    "ridge_cv = GridSearchCV(ridge, param_grid=params, cv=5, scoring=\"r2\")\n",
    "ridge_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31c828f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 14.563484775012444\n"
     ]
    }
   ],
   "source": [
    "# Best model from GridSearchCV\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "print(\"Best Alpha:\", ridge_cv.best_params_[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50af1b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.4026352313685135\n",
      "Root_Mean_squared_error (Test) = 0.6345354453208374\n",
      "R2_score (Test) = 0.6879584266761876\n",
      "Mean_squared_error (Train) = 0.04683978813349298\n",
      "Root_Mean_squared_error (Train) = 0.21642501734663896\n",
      "R2_score (Train) = 0.9475150492775899\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "y_predict_test = ridge_best.predict(X_test)\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = ridge_best.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcafc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e65a3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4c0e8a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianRidge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" checked><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianRidge</label><div class=\"sk-toggleable__content\"><pre>BayesianRidge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian Ridge Regression\n",
    "bayesian_ridge = BayesianRidge()\n",
    "bayesian_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "21420ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.4652686486759885\n",
      "Root_Mean_squared_error (Test) = 0.6821060391727877\n",
      "R2_score (Test) = 0.639417641974256\n",
      "Mean_squared_error (Train) = 0.009708217701723814\n",
      "Root_Mean_squared_error (Train) = 0.09853028824541119\n",
      "R2_score (Train) = 0.9891217414087093\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "y_predict_test = bayesian_ridge.predict(X_test)\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = bayesian_ridge.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1685fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "829ef966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha_1': 1e-12, 'alpha_2': 0.01, 'lambda_1': 0.01, 'lambda_2': 1e-12, 'n_iter': 50}\n",
      "Best Score: 0.33220014861116265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_bayes.py:53: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.3 and will be removed in 1.5\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sandesh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "bayesian_ridge = BayesianRidge()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'alpha_1': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'alpha_2': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'lambda_1': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'lambda_2': [1e-12, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2],\n",
    "    'n_iter': [50, 100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Define scoring metric\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bayesian_ridge,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters and corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", -grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_predict_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a28d560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error (Test) = 0.44325967650030407\n",
      "Root_Mean_squared_error (Test) = 0.6657774977425297\n",
      "R2_score (Test) = 0.6564745554529845\n",
      "Mean_squared_error (Train) = 0.013034420856875093\n",
      "Root_Mean_squared_error (Train) = 0.11416838816798236\n",
      "R2_score (Train) = 0.9853946620249747\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Evaluation\n",
    "\n",
    "Mean_squared_error_test = mean_squared_error(y_test, y_predict_test)\n",
    "print('Mean_squared_error (Test) =', Mean_squared_error_test)\n",
    "\n",
    "Root_Mean_squared_error_test = np.sqrt(Mean_squared_error_test)\n",
    "print('Root_Mean_squared_error (Test) =', Root_Mean_squared_error_test)\n",
    "\n",
    "R2_score_test = r2_score(y_test, y_predict_test)\n",
    "print('R2_score (Test) =', R2_score_test)\n",
    "\n",
    "\n",
    "# Training Data Evaluation\n",
    "y_predict_train = best_model.predict(X_train)\n",
    "\n",
    "Mean_squared_error_train = mean_squared_error(y_train, y_predict_train)\n",
    "print('Mean_squared_error (Train) =', Mean_squared_error_train)\n",
    "\n",
    "Root_Mean_squared_error_train = np.sqrt(Mean_squared_error_train)\n",
    "print('Root_Mean_squared_error (Train) =', Root_Mean_squared_error_train)\n",
    "\n",
    "R2_score_train = r2_score(y_train, y_predict_train)\n",
    "print('R2_score (Train) =', R2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e4e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
